import requests
import json
import pandas as pd
import time
from datetime import datetime
import os

class ExpandedCESMDCollector:
    def __init__(self):
        self.base_url = "https://strongmotioncenter.org/wserv"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
    def collect_events_by_magnitude_range(self, mag_ranges, max_per_range=200):
        """
        ì§„ë„ ë²”ìœ„ë³„ë¡œ ì´ë²¤íŠ¸ ìˆ˜ì§‘
        """
        print("ğŸš€ í™•ì¥ëœ CESMD ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        print("="*60)
        
        all_events = []
        total_collected = 0
        
        for min_mag, max_mag in mag_ranges:
            print(f"\nğŸ“Š ì§„ë„ {min_mag}-{max_mag} ë²”ìœ„ ìˆ˜ì§‘ ì¤‘...")
            
            params = {
                'minmag': min_mag,
                'maxmag': max_mag,
                'format': 'json',
                'nodata': '404'
            }
            
            url = f"{self.base_url}/events/query"
            
            try:
                response = self.session.get(url, params=params, timeout=60)
                response.raise_for_status()
                
                data = response.json()
                
                if data.get('type') == 'FeatureCollection':
                    features = data.get('features', [])
                    print(f"   ğŸ” ì´ {len(features)}ê°œ ì´ë²¤íŠ¸ ë°œê²¬")
                    
                    # ìµœëŒ€ ê°œìˆ˜ë§Œí¼ ì„ íƒ
                    selected_features = features[:max_per_range]
                    print(f"   ğŸ“‹ {len(selected_features)}ê°œ ì„ íƒ (ìµœëŒ€ {max_per_range}ê°œ)")
                    
                    # featuresë¥¼ events í˜•íƒœë¡œ ë³€í™˜
                    range_events = []
                    for i, feature in enumerate(selected_features):
                        properties = feature.get('properties', {})
                        geometry = feature.get('geometry', {})
                        
                        # ì¢Œí‘œ ì •ë³´ ì¶”ê°€
                        if geometry.get('coordinates'):
                            coords = geometry['coordinates']
                            properties['longitude'] = coords[0] if len(coords) > 0 else None
                            properties['latitude'] = coords[1] if len(coords) > 1 else None
                            properties['depth'] = coords[2] if len(coords) > 2 else None
                        
                        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
                        properties['cesmd_index'] = total_collected + i
                        properties['mag_range'] = f"{min_mag}-{max_mag}"
                        properties['collection_timestamp'] = datetime.now().isoformat()
                        
                        range_events.append(properties)
                    
                    all_events.extend(range_events)
                    total_collected += len(range_events)
                    
                    print(f"   âœ… {len(range_events)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
                    
                    # API ë¶€í•˜ ë°©ì§€
                    time.sleep(1)
                    
                else:
                    print(f"   âŒ ì˜ˆìƒê³¼ ë‹¤ë¥¸ ì‘ë‹µ í˜•íƒœ: {type(data)}")
                    
            except Exception as e:
                print(f"   âŒ ì§„ë„ {min_mag}-{max_mag} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                continue
        
        print(f"\nğŸ‰ ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ!")
        print(f"   ì´ ìˆ˜ì§‘: {total_collected}ê°œ ì´ë²¤íŠ¸")
        
        return all_events
    
    def analyze_collected_data(self, events):
        """
        ìˆ˜ì§‘ëœ ë°ì´í„° ë¶„ì„
        """
        if not events:
            print("âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"\nğŸ“ˆ ìˆ˜ì§‘ ë°ì´í„° ë¶„ì„")
        print("="*40)
        
        df = pd.DataFrame(events)
        
        # ê¸°ë³¸ í†µê³„
        print(f"ğŸ“Š ê¸°ë³¸ í†µê³„:")
        print(f"   ì´ ì´ë²¤íŠ¸: {len(df)}ê°œ")
        
        if 'mag' in df.columns:
            print(f"   ì§„ë„ ë²”ìœ„: {df['mag'].min():.1f} ~ {df['mag'].max():.1f}")
            print(f"   í‰ê·  ì§„ë„: {df['mag'].mean():.2f}")
            
            # ì§„ë„ë³„ ë¶„í¬
            mag_distribution = df['mag'].value_counts().sort_index()
            print(f"   ì§„ë„ë³„ ë¶„í¬:")
            for mag, count in mag_distribution.head(10).items():
                print(f"     ì§„ë„ {mag}: {count}ê°œ")
        
        # ì§€ì—­ë³„ ë¶„í¬
        if 'country' in df.columns:
            country_dist = df['country'].value_counts()
            print(f"\nğŸŒ êµ­ê°€ë³„ ë¶„í¬:")
            for country, count in country_dist.head(5).items():
                print(f"   {country}: {count}ê°œ")
        
        if 'net' in df.columns:
            network_dist = df['net'].value_counts()
            print(f"\nğŸŒ ë„¤íŠ¸ì›Œí¬ë³„ ë¶„í¬:")
            for network, count in network_dist.head(5).items():
                print(f"   {network}: {count}ê°œ")
        
        # ì‹œê°„ ë¶„í¬
        if 'time' in df.columns:
            try:
                df['datetime'] = pd.to_datetime(df['time'])
                year_dist = df['datetime'].dt.year.value_counts().sort_index()
                print(f"\nğŸ“… ì—°ë„ë³„ ë¶„í¬:")
                for year, count in year_dist.head(10).items():
                    print(f"   {year}: {count}ê°œ")
            except:
                print(f"\nğŸ“… ì‹œê°„ ë¶„ì„ ì‹¤íŒ¨")
        
        return df
    
    def save_expanded_dataset(self, events):
        """
        í™•ì¥ëœ ë°ì´í„°ì…‹ ì €ì¥
        """
        if not events:
            print("âŒ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None, None
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # DataFrame ìƒì„±
        df = pd.DataFrame(events)
        
        # CSV ì €ì¥
        csv_filename = f"cesmd_expanded_events_{timestamp}.csv"
        df.to_csv(csv_filename, index=False)
        print(f"ğŸ“ í™•ì¥ ì´ë²¤íŠ¸ ë°ì´í„° ì €ì¥: {csv_filename}")
        
        # JSON ë°±ì—… ì €ì¥
        json_filename = f"cesmd_expanded_backup_{timestamp}.json"
        backup_data = {
            'events': events,
            'collection_info': {
                'timestamp': timestamp,
                'total_events': len(events),
                'magnitude_range': f"{df['mag'].min():.1f}-{df['mag'].max():.1f}" if 'mag' in df.columns else "Unknown",
                'collection_method': 'expanded_magnitude_ranges'
            }
        }
        
        with open(json_filename, 'w') as f:
            json.dump(backup_data, f, indent=2, default=str)
        print(f"ğŸ“ JSON ë°±ì—… ì €ì¥: {json_filename}")
        
        # ìš”ì•½ ì •ë³´
        print(f"\nğŸ“‹ ì €ì¥ëœ ë°ì´í„° ìš”ì•½:")
        print(f"   íŒŒì¼ í¬ê¸°: {os.path.getsize(csv_filename)} bytes")
        print(f"   ë°ì´í„° í˜•íƒœ: {df.shape[0]}í–‰ Ã— {df.shape[1]}ì—´")
        
        return csv_filename, json_filename
    
    def create_earthquake_project_format(self, events):
        """
        ì§€ì§„ ê°ì§€ í”„ë¡œì íŠ¸ìš© í˜•íƒœë¡œ ë°ì´í„° ë³€í™˜
        """
        if not events:
            return None
        
        df = pd.DataFrame(events)
        
        # í•„ìš”í•œ ì»¬ëŸ¼ ì„ íƒ ë° ì •ë¦¬
        project_data = df.copy()
        
        # ì‹œê°„ ì •ë³´ ì¶”ê°€
        if 'time' in project_data.columns:
            try:
                project_data['datetime'] = pd.to_datetime(project_data['time'])
                project_data['year'] = project_data['datetime'].dt.year
                project_data['month'] = project_data['datetime'].dt.month
                project_data['day'] = project_data['datetime'].dt.day
                project_data['hour'] = project_data['datetime'].dt.hour
                project_data['day_of_week'] = project_data['datetime'].dt.dayofweek
            except:
                print("âš ï¸ ì‹œê°„ ì •ë³´ ë³€í™˜ ì‹¤íŒ¨")
        
        # ì •ê·œí™”ëœ íŠ¹ì„± ì¶”ê°€
        if 'mag' in project_data.columns:
            project_data['mag_normalized'] = (
                (project_data['mag'] - project_data['mag'].min()) / 
                (project_data['mag'].max() - project_data['mag'].min())
            )
            
            # ì§„ë„ ì¹´í…Œê³ ë¦¬ ì¶”ê°€
            project_data['mag_category'] = pd.cut(
                project_data['mag'], 
                bins=[0, 3.5, 4.5, 5.5, 10], 
                labels=['small', 'moderate', 'large', 'major']
            )
        
        # ì§€ì§„ í´ë˜ìŠ¤ ë¼ë²¨ (ê¸°ì¡´ í”„ë¡œì íŠ¸ í˜¸í™˜)
        project_data['event_type'] = 'earthquake'
        project_data['class_label'] = 0  # ì§€ì§„ = 0
        
        # ì§€ì—­ ì½”ë”©
        if 'country' in project_data.columns:
            country_map = {'US': 0, 'JP': 1, 'KR': 2}  # ê¸°ì¡´ í”„ë¡œì íŠ¸ ê¸°ì¤€
            project_data['country_code'] = project_data['country'].map(country_map).fillna(999)
        
        # íŒŒì¼ ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"earthquake_project_expanded_{timestamp}.csv"
        project_data.to_csv(filename, index=False)
        
        print(f"ğŸ¯ ì§€ì§„ í”„ë¡œì íŠ¸ìš© ë°ì´í„° ì €ì¥: {filename}")
        print(f"   ë°ì´í„° í¬ê¸°: {len(project_data)}ê°œ Ã— {len(project_data.columns)}ê°œ ì»¬ëŸ¼")
        
        return filename

# ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
def main():
    collector = ExpandedCESMDCollector()
    
    # ì§„ë„ ë²”ìœ„ ì„¤ì • (3.0-6.0ì„ ì„¸ë¶„í™”)
    magnitude_ranges = [
        (3.0, 3.5),  # ì†Œê·œëª¨ ì§€ì§„
        (3.5, 4.0),  # ì†Œ-ì¤‘ê°„ ê·œëª¨
        (4.0, 4.5),  # ì¤‘ê°„ ê·œëª¨
        (4.5, 5.0),  # ì¤‘-ëŒ€ ê·œëª¨
        (5.0, 5.5),  # ëŒ€ê·œëª¨
        (5.5, 6.0),  # ì£¼ìš” ì§€ì§„
    ]
    
    print(f"ğŸ¯ ëª©í‘œ: ì§„ë„ 3.0-6.0 ë²”ìœ„ ë°ì´í„° ìˆ˜ì§‘")
    print(f"ğŸ“‹ ë²”ìœ„: {len(magnitude_ranges)}ê°œ êµ¬ê°„")
    print(f"ğŸ”¢ ì˜ˆìƒ ìµœëŒ€ ìˆ˜ì§‘ëŸ‰: {len(magnitude_ranges) * 200}ê°œ ì´ë²¤íŠ¸")
    
    # ë°ì´í„° ìˆ˜ì§‘
    all_events = collector.collect_events_by_magnitude_range(
        magnitude_ranges, 
        max_per_range=200  # ê° ë²”ìœ„ë‹¹ ìµœëŒ€ 200ê°œ
    )
    
    if all_events:
        # ë°ì´í„° ë¶„ì„
        df = collector.analyze_collected_data(all_events)
        
        # ë°ì´í„° ì €ì¥
        csv_file, json_file = collector.save_expanded_dataset(all_events)
        
        # í”„ë¡œì íŠ¸ìš© í˜•íƒœë¡œ ë³€í™˜
        project_file = collector.create_earthquake_project_format(all_events)
        
        print(f"\nğŸ‰ ìˆ˜ì§‘ ì™„ë£Œ!")
        print(f"ğŸ“ ìƒì„±ëœ íŒŒì¼:")
        print(f"   - ì›ë³¸ ë°ì´í„°: {csv_file}")
        print(f"   - JSON ë°±ì—…: {json_file}")
        print(f"   - í”„ë¡œì íŠ¸ìš©: {project_file}")
        
        print(f"\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
        print(f"   1. ê¸°ì¡´ 3,430ê°œ + ìƒˆë¡œìš´ {len(all_events)}ê°œ = ì´ {3430 + len(all_events)}ê°œ")
        print(f"   2. í™•ì¥ëœ ë°ì´í„°ì…‹ìœ¼ë¡œ ConvLSTM ëª¨ë¸ ì¬í•™ìŠµ")
        print(f"   3. ì§„ë„ 3.0-6.0 ë²”ìœ„ì—ì„œ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦")
        
    else:
        print("âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")

if __name__ == "__main__":
    main()