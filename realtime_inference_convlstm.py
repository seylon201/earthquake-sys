import time
from datetime import datetime, timedelta
import requests
from influxdb_client import InfluxDBClient
from urllib.parse import quote
import os
import csv
import pandas as pd
import numpy as np
from tensorflow.keras.models import load_model

# âœ… 3í´ë˜ìŠ¤ ëª¨ë¸ ê²½ë¡œë¡œ ìˆ˜ì •
MODEL_PATH = 'convlstm_3class_model.h5'

# âœ… ì‹¤ì‹œê°„ CSV ì €ì¥ ìœ„ì¹˜
OUTPUT_DIR = "C:/earthquake_modeling/earthquake_project_v3/influxLogs"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# âœ… 3í´ë˜ìŠ¤ ConvLSTM ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
print("ğŸ”„ 3í´ë˜ìŠ¤ ConvLSTM ëª¨ë¸ ë¡œë”© ì¤‘...")
convlstm_model = load_model(MODEL_PATH)
print("âœ… 3í´ë˜ìŠ¤ ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

# âœ… 3í´ë˜ìŠ¤ ì •ì˜
CLASS_NAMES = {0: 'ì§€ì§„', 1: 'ë¶ˆê·œì¹™ìƒí™œì§„ë™', 2: 'ê·œì¹™ì ì‚°ì—…ì§„ë™'}
CLASS_COLORS = {0: 'ğŸ”´', 1: 'ğŸŸ¢', 2: 'ğŸŸ '}

# âœ… ì˜¬ë°”ë¥¸ ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_csv_for_3class_convlstm(csv_path):
    """í•™ìŠµê³¼ ë™ì¼í•œ ì „ì²˜ë¦¬ ë°©ì‹ ì ìš©"""
    try:
        df = pd.read_csv(csv_path)
        
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_cols = ['sensor1_x', 'sensor1_y', 'sensor1_z']
        if not all(col in df.columns for col in required_cols):
            print(f"âŒ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {required_cols}")
            return None, None
        
        # 3ì¶• ë°ì´í„° ì¶”ì¶œ
        sensor_x = df['sensor1_x'].astype(float).values
        sensor_y = df['sensor1_y'].astype(float).values
        sensor_z = df['sensor1_z'].astype(float).values
        
        # ë°ì´í„° ê²°í•©
        data = np.stack([sensor_x, sensor_y, sensor_z], axis=1)
        
        # 4000 ìƒ˜í”Œë¡œ ë§ì¶”ê¸° (í•™ìŠµê³¼ ë™ì¼)
        target_samples = 4000
        if data.shape[0] < target_samples:
            # ë¶€ì¡±í•˜ë©´ 0ìœ¼ë¡œ íŒ¨ë”©
            pad_width = ((0, target_samples - data.shape[0]), (0, 0))
            data = np.pad(data, pad_width, mode='constant')
        elif data.shape[0] > target_samples:
            # ë„˜ì¹˜ë©´ ìë¥´ê¸°
            data = data[:target_samples]
        
        # ConvLSTM ì…ë ¥ í˜•íƒœë¡œ ë³€í™˜ (í•™ìŠµê³¼ ë™ì¼)
        d = data.reshape(40, 100, 3)        # (40, 100, 3)
        d = np.transpose(d, (0, 2, 1))      # (40, 3, 100)
        d = np.expand_dims(d, axis=-1)      # (40, 3, 100, 1)
        d = np.expand_dims(d, axis=0)       # (1, 40, 3, 100, 1)
        
        # z-score ì •ê·œí™” (í•™ìŠµê³¼ ë™ì¼)
        mean = d.mean()
        std = d.std()
        if std > 0:
            d = (d - mean) / std
        
        return d, df
        
    except Exception as e:
        print(f"âŒ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return None, None

# âœ… ì˜ˆì¸¡ ê²°ê³¼ í•´ì„ ë° ì €ì¥
def predict_and_save_result(filepath):
    """3í´ë˜ìŠ¤ ì˜ˆì¸¡ ìˆ˜í–‰ ë° ê²°ê³¼ ì €ì¥"""
    try:
        # ì „ì²˜ë¦¬
        X, df = preprocess_csv_for_3class_convlstm(filepath)
        if X is None:
            return
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        start_time = time.time()
        predictions = convlstm_model.predict(X, verbose=0)
        inference_time = time.time() - start_time
        
        # ê²°ê³¼ í•´ì„
        predicted_class = int(np.argmax(predictions[0]))
        confidence = float(predictions[0][predicted_class])
        class_name = CLASS_NAMES[predicted_class]
        class_icon = CLASS_COLORS[predicted_class]
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ§  === 3í´ë˜ìŠ¤ ì˜ˆì¸¡ ê²°ê³¼ ===")
        print(f"{class_icon} ì˜ˆì¸¡ í´ë˜ìŠ¤: {class_name}")
        print(f"ğŸ¯ ì‹ ë¢°ë„: {confidence:.4f} ({confidence*100:.2f}%)")
        print(f"âš¡ ì¶”ë¡  ì‹œê°„: {inference_time:.3f}ì´ˆ")
        
        # ëª¨ë“  í´ë˜ìŠ¤ í™•ë¥  ì¶œë ¥
        print(f"ğŸ“Š í´ë˜ìŠ¤ë³„ í™•ë¥ :")
        for i, (class_id, name) in enumerate(CLASS_NAMES.items()):
            prob = predictions[0][i]
            icon = CLASS_COLORS[class_id]
            print(f"  {icon} {name}: {prob:.4f} ({prob*100:.2f}%)")
        
        # ê²½ë³´ íŒë³„
        if predicted_class == 0:  # ì§€ì§„
            print(f"ğŸš¨ ì§€ì§„ ê°ì§€! ì¦‰ì‹œ ê²½ë³´ ë°œë ¹!")
        else:
            print(f"âœ… ë¹„ì§€ì§„ ì§„ë™ ({class_name}) - ê²½ë³´ ì–µì œ")
        
        # CSVì— ì˜ˆì¸¡ ê²°ê³¼ ì¶”ê°€
        if df is not None:
            df['predicted_class'] = predicted_class
            df['predicted_class_name'] = class_name
            df['confidence'] = confidence
            df['inference_time'] = inference_time
            
            # ì €ì¥
            df.to_csv(filepath, index=False, encoding='utf-8-sig')
            print(f"ğŸ“ ì˜ˆì¸¡ ê²°ê³¼ í¬í•¨ ì €ì¥ ì™„ë£Œ: {filepath}")
        
    except Exception as e:
        print(f"âŒ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")

# InfluxDB A (ì§„ë„ ê°ì§€ìš©)
INFLUX_TOKEN = "ZyegXlVhIdA26zFakbWjgVX863_pAtfXJPfsLGlA0wtfTxl7BHZJlMNLT5HHudXk58VzVScGnugA36w_buC4Zg=="
INFLUX_ORG = "kds"
INFLUX_BUCKET = "Lasung_3sensor of Max"
INFLUX_URL = "http://118.129.145.82:8086"
PORTS = [6060, 7001, 7053, 7060, 7070, 8010, 8080]
CHECK_INTERVAL = 1

NODERED_BASE_URL = "http://118.129.145.82:8081/nodered/1min_event_lasung"
SAVE_DIR = "C:/earthquake_modeling/earthquake_project_v3/influxLogs/base"

client = InfluxDBClient(url=INFLUX_URL, token=INFLUX_TOKEN, org=INFLUX_ORG)
query_api = client.query_api()


print("\nğŸš€ 3í´ë˜ìŠ¤ ConvLSTM ì‹¤ì‹œê°„ ì§€ì§„ ê°ì§€ ì‹œì‘!")
print(f"ğŸ“Š ë¶„ë¥˜ í´ë˜ìŠ¤: {list(CLASS_NAMES.values())}")
print(f"ğŸ” ê°ì‹œ ëŒ€ìƒ í¬íŠ¸: {PORTS}")
print("="*60)

# âœ… ì‹¤ì‹œê°„ ê°ì‹œ ë£¨í”„
try:
    while True:
        now = datetime.utcnow()
        start = now - timedelta(seconds=CHECK_INTERVAL)

        for port in PORTS:
            query = f'''
            from(bucket: "{INFLUX_BUCKET}")
              |> range(start: {start.isoformat()}Z, stop: {now.isoformat()}Z)
              |> filter(fn: (r) => r._field == "intensity" and r._measurement == "{port}")
              |> sort(columns: ["_time"], desc: true)
              |> limit(n:1)
            '''

            result = query_api.query(org=INFLUX_ORG, query=query)

            for table in result:
                for record in table.records:
                    intensity = record.get_value()
                    event_time = record.get_time().astimezone()

                    if intensity >= 3.0:
                        kst_time = event_time.strftime("%Y-%m-%d %H:%M:%S")
                        print(f"\nğŸ”¥ ì§„ë„ 3 ì´ìƒ ê°ì§€: {kst_time} (í¬íŠ¸: {port}, ì§„ë„: {intensity:.2f})")
                        print("â³ 40ì´ˆ ë°ì´í„° ìˆ˜ì§‘ ëŒ€ê¸° ì¤‘...")
                        time.sleep(40)

                        encoded_time = quote(kst_time)
                        url = f"http://118.129.145.82:8081/nodered/1min_event_lasung/{encoded_time}/{port}"

                        try:
                            res = requests.get(url)
                            print(f"ğŸŒ API í˜¸ì¶œ ê²°ê³¼: {res.status_code}")

                            if res.status_code == 200:
                                # CSV ì €ì¥
                                file_time = kst_time.replace(":", "-").replace(" ", "_")
                                filename = f"event_{port}_{file_time}.csv"
                                filepath = os.path.join(OUTPUT_DIR, filename)

                                try:
                                    data = res.json()
                                    for row in data:
                                        row["timestamp"] = "'" + row["timestamp"]

                                    with open(filepath, "w", newline="", encoding="utf-8") as f:
                                        writer = csv.DictWriter(f, fieldnames=data[0].keys())
                                        writer.writeheader()
                                        writer.writerows(data)

                                    print(f"ğŸ“ ì›ë³¸ íŒŒì¼ ì €ì¥: {filename}")

                                    # 3í´ë˜ìŠ¤ ì˜ˆì¸¡ ìˆ˜í–‰
                                    predict_and_save_result(filepath)

                                except Exception as e:
                                    print(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

                        except Exception as e:
                            print(f"âŒ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")

        time.sleep(CHECK_INTERVAL)

except KeyboardInterrupt:
    print("\n\nğŸ›‘ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    print("ğŸ‘‹ 3í´ë˜ìŠ¤ ì‹¤ì‹œê°„ ì§€ì§„ ê°ì§€ ì‹œìŠ¤í…œ ì¢…ë£Œ")