#!/usr/bin/env python3
"""
influx_base.pyë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ NEW2 ConvLSTM ì‹¤ì‹œê°„ ì§€ì§„ ë¶„ì„ ì‹œìŠ¤í…œ
ê¸°ì¡´ influx_base.pyì˜ ê°„ê²°í•œ êµ¬ì¡° + NEW2 ëª¨ë¸ì˜ 98.46% ì •í™•ë„ í™œìš©
"""

import time
from datetime import datetime, timedelta
import requests
from influxdb_client import InfluxDBClient
from urllib.parse import quote
import os
import csv
import numpy as np
import pandas as pd
import json
import warnings
warnings.filterwarnings('ignore')

# í™˜ê²½ ì„¤ì •
os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# TensorFlow ì•ˆì „ ë¡œë”©
def load_tensorflow():
    """TensorFlow ì•ˆì „ ë¡œë”©"""
    try:
        import tensorflow as tf
        tf.get_logger().setLevel('ERROR')
        from tensorflow.keras.models import load_model
        print(f"âœ… TensorFlow ë¡œë”© ì™„ë£Œ: {tf.__version__}")
        return tf, load_model, True
    except Exception as e:
        print(f"âŒ TensorFlow ë¡œë”© ì‹¤íŒ¨: {e}")
        return None, None, False

# TensorFlow ë¡œë”©
tf, load_model, tf_available = load_tensorflow()

# =========================== ê¸°ë³¸ ì„¤ì • (influx_base.py ê¸°ë°˜) ===========================

# InfluxDB ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼)
INFLUX_TOKEN = "ZyegXlVhIdA26zFakbWjgVX863_pAtfXJPfsLGlA0wtfTxl7BHZJlMNLT5HHudXk58VzVScGnugA36w_buC4Zg=="
INFLUX_ORG = "kds"
INFLUX_BUCKET = "Lasung_3sensor of Max"
INFLUX_URL = "http://118.129.145.82:8086"
PORTS = [6060, 7001, 7053, 7060, 7070, 8010, 8080]
CHECK_INTERVAL = 1

# Node-RED ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼)
NODERED_BASE_URL = "http://118.129.145.82:8081/nodered/1min_event_lasung"

# ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì •
BASE_SAVE_DIR = "C:/earthquake_project/influxLogs"
RAW_SAVE_DIR = os.path.join(BASE_SAVE_DIR, "base")          # ì›ì‹œ ë°ì´í„° (ê¸°ì¡´ê³¼ ë™ì¼)
AI_SAVE_DIR = os.path.join(BASE_SAVE_DIR, "new2_analysis")  # NEW2 AI ë¶„ì„ ê²°ê³¼
ALERT_SAVE_DIR = os.path.join(BASE_SAVE_DIR, "alerts")      # ì§€ì§„ ê²½ë³´ ë¡œê·¸

# ë””ë ‰í† ë¦¬ ìƒì„±
for save_dir in [RAW_SAVE_DIR, AI_SAVE_DIR, ALERT_SAVE_DIR]:
    os.makedirs(save_dir, exist_ok=True)

# InfluxDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = InfluxDBClient(url=INFLUX_URL, token=INFLUX_TOKEN, org=INFLUX_ORG)
query_api = client.query_api()

# =========================== NEW2 ëª¨ë¸ ì„¤ì • ===========================

# NEW2 ëª¨ë¸ ì„¤ì •
NEW2_CONFIG = {
    'model_paths': [
        'new2_convlstm_3class_best.h5',
        'new2_convlstm_3class_final.h5',
        'convlstm_3class_model.h5'  # ë°±ì—…
    ],
    'classes': {0: 'ì§€ì§„', 1: 'ê·œì¹™ì ì‚°ì—…ì§„ë™', 2: 'ë¶ˆê·œì¹™ìƒí™œì§„ë™'},
    'accuracy': 0.9846,
    'earthquake_threshold': 0.90,  # ì§€ì§„ ì‹ ë¢°ë„ ì„ê³„ê°’ 90%
    'confidence_gap_min': 0.20     # ì‹ ë¢°ë„ ì°¨ì´ ìµœì†Œ 20%
}

# NEW2 ëª¨ë¸ ë¡œë”©
new2_model = None
if tf_available:
    print("ğŸ”„ NEW2 ConvLSTM ëª¨ë¸ ë¡œë”© ì¤‘...")
    for model_path in NEW2_CONFIG['model_paths']:
        if os.path.exists(model_path):
            try:
                new2_model = load_model(model_path)
                print(f"âœ… NEW2 ëª¨ë¸ ë¡œë”© ì„±ê³µ: {model_path}")
                print(f"ğŸ¯ ëª¨ë¸ ì •í™•ë„: {NEW2_CONFIG['accuracy']*100:.2f}%")
                break
            except Exception as e:
                print(f"âš ï¸ {model_path} ë¡œë”© ì‹¤íŒ¨: {e}")
                continue
    
    if new2_model is None:
        print("âŒ ëª¨ë“  NEW2 ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ - ë°ì´í„° ìˆ˜ì§‘ë§Œ ìˆ˜í–‰")
else:
    print("âš ï¸ TensorFlow ì—†ìŒ - ë°ì´í„° ìˆ˜ì§‘ë§Œ ìˆ˜í–‰")

# =========================== ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ (ê¸°ì¡´ + NEW2 í™•ì¥) ===========================

def flatten_row(row):
    """ê¸°ì¡´ influx_base.pyì˜ ë°ì´í„° í‰ë©´í™” í•¨ìˆ˜ (ë™ì¼)"""
    flat = {
        "timestamp": "'" + row.get("timestamp"),
        "counter": row.get("counter")
    }
    for i in range(1, 4):  # sensor_1, sensor_2, sensor_3
        sensor_key = f"sensor_{i}"
        sensor_data = row.get(sensor_key, {})
        for key, value in sensor_data.items():
            flat[f"{sensor_key}_{key}"] = value
    return flat

def preprocess_for_new2(csv_path):
    """NEW2 ëª¨ë¸ìš© ì „ì²˜ë¦¬ (ê°„ë‹¨ ë²„ì „)"""
    try:
        df = pd.read_csv(csv_path)
        
        # ì„¼ì„œ ì„ íƒ (sensor_1 ìš°ì„ )
        sensor_cols = None
        for i in range(1, 4):
            x_col, y_col, z_col = f'sensor_{i}_x', f'sensor_{i}_y', f'sensor_{i}_z'
            if all(col in df.columns for col in [x_col, y_col, z_col]):
                sensor_cols = [x_col, y_col, z_col]
                break
        
        if not sensor_cols:
            return None, "ì„¼ì„œ ë°ì´í„° ì—†ìŒ"
        
        # 3ì¶• ë°ì´í„° ì¶”ì¶œ
        x_data = df[sensor_cols[0]].astype(float).values
        y_data = df[sensor_cols[1]].astype(float).values
        z_data = df[sensor_cols[2]].astype(float).values
        raw_data = np.stack([x_data, y_data, z_data], axis=1)
        
        # íŠ¸ë¦¬ê±° í¬ì¸íŠ¸ ì°¾ê¸° (ê°„ë‹¨ ë²„ì „)
        magnitude = np.sqrt(np.sum(raw_data**2, axis=1))
        trigger_idx = np.argmax(magnitude)  # ìµœëŒ€ ì§„í­ ì§€ì 
        
        # 40ì´ˆ ìŠ¬ë¼ì´ì‹± (4000 ìƒ˜í”Œ)
        PRE_SAMPLES = 1500   # ì „ 15ì´ˆ
        POST_SAMPLES = 2500  # í›„ 25ì´ˆ
        TOTAL_SAMPLES = 4000
        
        start_idx = max(0, trigger_idx - PRE_SAMPLES)
        end_idx = min(len(raw_data), trigger_idx + POST_SAMPLES)
        
        # ë°ì´í„° ì¶”ì¶œ ë° íŒ¨ë”©
        if end_idx - start_idx >= TOTAL_SAMPLES:
            sliced_data = raw_data[start_idx:start_idx + TOTAL_SAMPLES]
        else:
            available_data = raw_data[start_idx:end_idx]
            pad_length = TOTAL_SAMPLES - len(available_data)
            padding = np.zeros((pad_length, 3))
            sliced_data = np.vstack([available_data, padding])
        
        # NEW2 ì…ë ¥ í˜•íƒœë¡œ ë³€í™˜: (1, 40, 3, 100, 1)
        reshaped = sliced_data.reshape(40, 100, 3)
        reshaped = np.transpose(reshaped, (0, 2, 1))  # (40, 3, 100)
        reshaped = np.expand_dims(reshaped, axis=-1)  # (40, 3, 100, 1)
        reshaped = np.expand_dims(reshaped, axis=0)   # (1, 40, 3, 100, 1)
        
        # z-score ì •ê·œí™”
        mean = reshaped.mean()
        std = reshaped.std()
        if std > 0:
            normalized = (reshaped - mean) / std
        else:
            normalized = reshaped
        
        return normalized, f"ì „ì²˜ë¦¬ ì™„ë£Œ: {normalized.shape}"
        
    except Exception as e:
        return None, f"ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}"

def analyze_with_new2(X):
    """NEW2 ëª¨ë¸ë¡œ ì§€ì§„ ë¶„ì„"""
    if new2_model is None:
        return None, "ëª¨ë¸ ì—†ìŒ"
    
    try:
        # ì˜ˆì¸¡ ìˆ˜í–‰
        predictions = new2_model.predict(X, verbose=0)
        
        # ê²°ê³¼ ë¶„ì„
        earthquake_prob = predictions[0][0]    # ì§€ì§„ í™•ë¥ 
        industrial_prob = predictions[0][1]    # ê·œì¹™ì ì‚°ì—…ì§„ë™ í™•ë¥ 
        living_prob = predictions[0][2]        # ë¶ˆê·œì¹™ìƒí™œì§„ë™ í™•ë¥ 
        
        predicted_class = int(np.argmax(predictions[0]))
        confidence = float(predictions[0][predicted_class])
        
        # ì§€ì§„ ê°ì§€ ë¡œì§ (ê°„ë‹¨ ë²„ì „)
        is_earthquake = False
        alert_status = "NO_ALERT"
        
        if predicted_class == 0:  # ì§€ì§„ìœ¼ë¡œ ì˜ˆì¸¡ë¨
            # ì‹ ë¢°ë„ ê²€ì‚¬
            if earthquake_prob >= NEW2_CONFIG['earthquake_threshold']:
                # ë‹¤ë¥¸ í´ë˜ìŠ¤ì™€ ì°¨ì´ ê²€ì‚¬
                max_other_prob = max(industrial_prob, living_prob)
                if earthquake_prob - max_other_prob >= NEW2_CONFIG['confidence_gap_min']:
                    is_earthquake = True
                    alert_status = "EARTHQUAKE_ALERT"
                else:
                    alert_status = "LOW_CONFIDENCE_GAP"
            else:
                alert_status = "LOW_CONFIDENCE"
        
        result = {
            'predicted_class': predicted_class,
            'class_name': NEW2_CONFIG['classes'][predicted_class],
            'confidence': confidence,
            'earthquake_prob': earthquake_prob,
            'industrial_prob': industrial_prob,
            'living_prob': living_prob,
            'is_earthquake': is_earthquake,
            'alert_status': alert_status
        }
        
        return result, "ë¶„ì„ ì™„ë£Œ"
        
    except Exception as e:
        return None, f"ë¶„ì„ ì‹¤íŒ¨: {e}"

def save_ai_result(raw_filepath, ai_result, event_info=None):
    """AI ë¶„ì„ ê²°ê³¼ ì €ì¥"""
    try:
        # ì›ë³¸ CSV ì½ê¸°
        df = pd.read_csv(raw_filepath)
        
        # AI ê²°ê³¼ ì¶”ê°€
        for key, value in ai_result.items():
            df[f'ai_{key}'] = value
        
        df['ai_model'] = 'NEW2_ConvLSTM_3Class'
        df['ai_accuracy'] = NEW2_CONFIG['accuracy']
        df['analysis_time'] = datetime.now().isoformat()
        
        # event_infoê°€ ìˆìœ¼ë©´ intensity ê°’ ì¶”ê°€ (ëŒ€ì‹œë³´ë“œì—ì„œ ì‚¬ìš©)
        if event_info and 'intensity' in event_info:
            df['intensity'] = event_info['intensity']
            df['event_port'] = event_info['port']
            df['event_time'] = event_info['time']
        
        # AI ê²°ê³¼ íŒŒì¼ ì €ì¥
        filename = os.path.basename(raw_filepath).replace('event_', 'new2_ai_')
        ai_filepath = os.path.join(AI_SAVE_DIR, filename)
        df.to_csv(ai_filepath, index=False, encoding='utf-8-sig')
        
        print(f"ğŸ’¾ AI ë¶„ì„ ê²°ê³¼ ì €ì¥: {filename}")
        return ai_filepath
        
    except Exception as e:
        print(f"âŒ AI ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        return None

def save_earthquake_alert(ai_result, event_info):
    """ì§€ì§„ ê²½ë³´ ì •ë³´ ì €ì¥"""
    try:
        alert_data = {
            'timestamp': datetime.now().isoformat(),
            'event_time': event_info['time'],
            'port': event_info['port'],
            'intensity': event_info['intensity'],
            'ai_analysis': ai_result,
            'model_info': {
                'name': 'NEW2_ConvLSTM_3Class',
                'accuracy': NEW2_CONFIG['accuracy']
            }
        }
        
        alert_filename = f"earthquake_alert_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        alert_filepath = os.path.join(ALERT_SAVE_DIR, alert_filename)
        
        with open(alert_filepath, 'w', encoding='utf-8') as f:
            json.dump(alert_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸš¨ ì§€ì§„ ê²½ë³´ ë¡œê·¸ ì €ì¥: {alert_filename}")
        return alert_filepath
        
    except Exception as e:
        print(f"âŒ ê²½ë³´ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")
        return None

# =========================== í†µê³„ ì¶”ì  ===========================

stats = {
    'total_events': 0,
    'earthquake_alerts': 0,
    'class_counts': {name: 0 for name in NEW2_CONFIG['classes'].values()},
    'start_time': datetime.now()
}

def update_stats(ai_result):
    """í†µê³„ ì—…ë°ì´íŠ¸"""
    if ai_result:
        stats['total_events'] += 1
        stats['class_counts'][ai_result['class_name']] += 1
        
        if ai_result['is_earthquake']:
            stats['earthquake_alerts'] += 1

def print_stats():
    """í†µê³„ ì¶œë ¥"""
    if stats['total_events'] == 0:
        return
    
    runtime = datetime.now() - stats['start_time']
    alert_rate = stats['earthquake_alerts'] / stats['total_events'] * 100
    
    print(f"\\nğŸ“Š === NEW2 ì‹œìŠ¤í…œ í†µê³„ ===")
    print(f"ğŸ•’ ì‹¤í–‰ ì‹œê°„: {runtime}")
    print(f"ğŸ“ˆ ì´ ì´ë²¤íŠ¸: {stats['total_events']}ê±´")
    print(f"ğŸš¨ ì§€ì§„ ê²½ë³´: {stats['earthquake_alerts']}ê±´ ({alert_rate:.1f}%)")
    print(f"ğŸ“Š í´ë˜ìŠ¤ë³„ ë¶„í¬:")
    for class_name, count in stats['class_counts'].items():
        if count > 0:
            percentage = count / stats['total_events'] * 100
            icon = 'ğŸ”´' if class_name == 'ì§€ì§„' else 'ğŸŸ ' if class_name == 'ê·œì¹™ì ì‚°ì—…ì§„ë™' else 'ğŸŸ¢'
            print(f"   {icon} {class_name}: {count}ê±´ ({percentage:.1f}%)")

# =========================== ë©”ì¸ ë£¨í”„ (influx_base.py ìŠ¤íƒ€ì¼) ===========================

print("\\nğŸš€ === influx_base.py + NEW2 ì‹¤ì‹œê°„ ì§€ì§„ ë¶„ì„ ì‹œìŠ¤í…œ ì‹œì‘! ===")
print(f"ğŸ§  NEW2 ëª¨ë¸: {'ë¡œë”©ë¨' if new2_model else 'ì—†ìŒ'}")
print(f"ğŸ“Š ë¶„ë¥˜ í´ë˜ìŠ¤: {list(NEW2_CONFIG['classes'].values())}")
print(f"ğŸ” ê°ì‹œ í¬íŠ¸: {PORTS}")
print(f"â±ï¸ ì²´í¬ ì£¼ê¸°: {CHECK_INTERVAL}ì´ˆ")
print(f"ğŸ’¾ ì €ì¥ ìœ„ì¹˜:")
print(f"   ì›ì‹œ ë°ì´í„°: {RAW_SAVE_DIR}")
print(f"   AI ë¶„ì„: {AI_SAVE_DIR}")
print(f"   ì§€ì§„ ê²½ë³´: {ALERT_SAVE_DIR}")
print("="*60)

try:
    # influx_base.pyì™€ ë™ì¼í•œ ë©”ì¸ ë£¨í”„ êµ¬ì¡°
    while True:
        now = datetime.utcnow()
        start = now - timedelta(seconds=CHECK_INTERVAL)

        for port in PORTS:
            # InfluxDB ì¿¼ë¦¬ (ê¸°ì¡´ê³¼ ë™ì¼)
            query = f'''
            from(bucket: "{INFLUX_BUCKET}")
              |> range(start: {start.isoformat()}Z, stop: {now.isoformat()}Z)
              |> filter(fn: (r) => r._field == "intensity" and r._measurement == "{port}")
              |> sort(columns: ["_time"], desc: true)
              |> limit(n:1)
            '''

            result = query_api.query(org=INFLUX_ORG, query=query)

            for table in result:
                for record in table.records:
                    intensity = record.get_value()
                    if not isinstance(intensity, (int, float)):
                        continue

                    if intensity >= 3.0:
                        event_time = record.get_time().astimezone()
                        kst_time = event_time.strftime("%Y-%m-%d %H:%M:%S")
                        
                        print(f"\\nğŸ”¥ === ì§„ë„ {intensity:.2f} ê°ì§€ ===")
                        print(f"ğŸ“… ì‹œê°„: {kst_time}")
                        print(f"ğŸŒ í¬íŠ¸: {port}")

                        # ì´ë²¤íŠ¸ ì •ë³´ ì €ì¥ (NEW2 ë¶„ì„ìš©)
                        event_info = {
                            'time': kst_time,
                            'port': port,
                            'intensity': intensity
                        }

                        print("â³ 40ì´ˆ ë°ì´í„° ìˆ˜ì§‘ ëŒ€ê¸°...")
                        time.sleep(40)  # ê¸°ì¡´ê³¼ ë™ì¼í•œ ëŒ€ê¸° ì‹œê°„

                        # Node-RED í˜¸ì¶œ (ê¸°ì¡´ê³¼ ë™ì¼)
                        encoded_time = quote(kst_time)
                        url = f"{NODERED_BASE_URL}/{encoded_time}/{port}"
                        print(f"ğŸ”— Node-RED í˜¸ì¶œ: {url}")

                        try:
                            res = requests.get(url, timeout=30)
                            if res.status_code == 200:
                                data = res.json()
                                if not data:
                                    print("âš ï¸ ì‘ë‹µ ë°ì´í„° ì—†ìŒ (ì €ì¥ ìƒëµ)")
                                    continue

                                # ê¸°ì¡´ ë°©ì‹ëŒ€ë¡œ CSV ì €ì¥
                                flattened_data = [flatten_row(row) for row in data]
                                
                                file_time = kst_time.replace(":", "-").replace(" ", "_")
                                filename = f"event_{port}_{file_time}.csv"
                                raw_filepath = os.path.join(RAW_SAVE_DIR, filename)

                                with open(raw_filepath, "w", newline="", encoding="utf-8") as f:
                                    writer = csv.DictWriter(f, fieldnames=flattened_data[0].keys())
                                    writer.writeheader()
                                    writer.writerows(flattened_data)

                                print(f"ğŸ“ ì›ì‹œ ë°ì´í„° ì €ì¥: {filename}")

                                # === NEW2 AI ë¶„ì„ ì¶”ê°€ ===
                                if new2_model is not None:
                                    print(f"\\nğŸ§  === NEW2 AI ë¶„ì„ ì‹œì‘ ===")
                                    
                                    # ì „ì²˜ë¦¬
                                    X, preprocess_msg = preprocess_for_new2(raw_filepath)
                                    print(f"ğŸ”„ ì „ì²˜ë¦¬: {preprocess_msg}")
                                    
                                    if X is not None:
                                        # AI ë¶„ì„
                                        ai_result, analysis_msg = analyze_with_new2(X)
                                        print(f"ğŸ¯ ë¶„ì„: {analysis_msg}")
                                        
                                        if ai_result:
                                            # ê²°ê³¼ ì¶œë ¥
                                            print(f"\\nğŸ“Š === NEW2 ë¶„ì„ ê²°ê³¼ ===")
                                            print(f"ğŸ”´ ì§€ì§„: {ai_result['earthquake_prob']:.4f} ({ai_result['earthquake_prob']*100:.1f}%)")
                                            print(f"ğŸŸ  ê·œì¹™ì ì‚°ì—…ì§„ë™: {ai_result['industrial_prob']:.4f} ({ai_result['industrial_prob']*100:.1f}%)")
                                            print(f"ğŸŸ¢ ë¶ˆê·œì¹™ìƒí™œì§„ë™: {ai_result['living_prob']:.4f} ({ai_result['living_prob']*100:.1f}%)")
                                            print(f"ğŸ¯ ìµœì¢… ë¶„ë¥˜: {ai_result['class_name']} (ì‹ ë¢°ë„: {ai_result['confidence']:.4f})")
                                            
                                            # ì§€ì§„ ê²½ë³´ ì²˜ë¦¬
                                            if ai_result['is_earthquake']:
                                                print(f"\\nğŸš¨ğŸš¨ğŸš¨ ì§€ì§„ ê²½ë³´ ë°œë ¹! ğŸš¨ğŸš¨ğŸš¨")
                                                print(f"ğŸ”´ ì§€ì§„ í™•ë¥ : {ai_result['earthquake_prob']*100:.1f}%")
                                                print(f"ğŸ“Š ì‹ ë¢°ë„: {ai_result['confidence']*100:.1f}%")
                                                
                                                # ì§€ì§„ ê²½ë³´ ë¡œê·¸ ì €ì¥
                                                save_earthquake_alert(ai_result, event_info)
                                                
                                            else:
                                                status_msg = {
                                                    'NO_ALERT': 'ì •ìƒ - ë¹„ì§€ì§„ ì§„ë™',
                                                    'LOW_CONFIDENCE': 'ì‹ ë¢°ë„ ë¶€ì¡±ìœ¼ë¡œ ê²½ë³´ ì–µì œ',
                                                    'LOW_CONFIDENCE_GAP': 'ì‹ ë¢°ë„ ì°¨ì´ ë¶€ì¡±ìœ¼ë¡œ ê²½ë³´ ì–µì œ'
                                                }.get(ai_result['alert_status'], 'ì•Œ ìˆ˜ ì—†ëŠ” ìƒíƒœ')
                                                
                                                print(f"\\nâœ… {status_msg}")
                                                print(f"ğŸ“Š ë¶„ë¥˜: {ai_result['class_name']}")
                                                print(f"ğŸ“Š ì‹ ë¢°ë„: {ai_result['confidence']*100:.1f}%")
                                            
                                            # AI ê²°ê³¼ ì €ì¥ (event_info í¬í•¨)
                                            save_ai_result(raw_filepath, ai_result, event_info)
                                            
                                            # í†µê³„ ì—…ë°ì´íŠ¸
                                            update_stats(ai_result)
                                            
                                            # ì£¼ê¸°ì  í†µê³„ ì¶œë ¥ (5íšŒë§ˆë‹¤)
                                            if stats['total_events'] % 5 == 0:
                                                print_stats()
                                        
                                    else:
                                        print("âŒ NEW2 ì „ì²˜ë¦¬ ì‹¤íŒ¨")
                                else:
                                    print("âš ï¸ NEW2 ëª¨ë¸ ì—†ìŒ - ë°ì´í„° ìˆ˜ì§‘ë§Œ ìˆ˜í–‰")

                            else:
                                print("âŒ Node-RED ì‘ë‹µ ì˜¤ë¥˜:", res.status_code)
                                
                        except requests.exceptions.Timeout:
                            print("âŒ Node-RED ìš”ì²­ íƒ€ì„ì•„ì›ƒ")
                        except Exception as e:
                            print("âŒ ìš”ì²­ ì‹¤íŒ¨:", e)

        time.sleep(CHECK_INTERVAL)

except KeyboardInterrupt:
    print(f"\\n\\nğŸ›‘ === ì‚¬ìš©ì ì¤‘ë‹¨ ===")
    print_stats()
    
    print(f"\\nğŸ’¾ ë°ì´í„° ì €ì¥ ìœ„ì¹˜:")
    print(f"   ì›ì‹œ ë°ì´í„°: {RAW_SAVE_DIR}")
    print(f"   AI ë¶„ì„ ê²°ê³¼: {AI_SAVE_DIR}")
    print(f"   ì§€ì§„ ê²½ë³´ ë¡œê·¸: {ALERT_SAVE_DIR}")
    
    print(f"\\nğŸ‰ influx_base.py + NEW2 ì‹œìŠ¤í…œì´ ì•ˆì „í•˜ê²Œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

except Exception as e:
    print(f"\\nâŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
    import traceback
    traceback.print_exc()
    print_stats()