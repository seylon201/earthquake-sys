#!/usr/bin/env python3
"""
NEW2 3í´ë˜ìŠ¤ ìˆ˜ì • ê³„íš - industry ë°ì´í„° ì œì™¸ ë¶„ì„
í¸í–¥ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ìƒˆë¡œìš´ í´ë˜ìŠ¤ êµ¬ì„±
"""

import os
import json
from datetime import datetime

def analyze_current_data_files():
    """í˜„ì¬ NEW2 ë°ì´í„° íŒŒì¼ ë¶„ì„"""
    
    print("ğŸ“Š === NEW2 ë°ì´í„° íŒŒì¼ í˜„í™© ë¶„ì„ ===\n")
    
    # NEW2 ë°ì´í„° íŒŒì¼ ëª©ë¡
    data_files = {
        'kor_quake': ('new2_kor_quake_data.npy', 'new2_kor_quake_labels.npy'),
        'jpn_quake': ('new2_jpn_quake_data.npy', 'new2_jpn_quake_labels.npy'),
        'industry': ('new2_industry_data.npy', 'new2_industry_labels.npy'),
        'motor': ('new2_motor_data.npy', 'new2_motor_labels.npy'),
        'live': ('new2_live_data.npy', 'new2_live_labels.npy'),
        'irregular': ('new2_irregular_data.npy', 'new2_irregular_labels.npy')
    }
    
    file_status = {}
    
    for source, (data_file, label_file) in data_files.items():
        data_exists = os.path.exists(data_file)
        label_exists = os.path.exists(label_file)
        
        status = "âœ…" if (data_exists and label_exists) else "âŒ"
        file_status[source] = {
            'data_file': data_file,
            'label_file': label_file,
            'data_exists': data_exists,
            'label_exists': label_exists,
            'both_exist': data_exists and label_exists
        }
        
        if data_exists and label_exists:
            data_size = os.path.getsize(data_file) / (1024*1024)  # MB
            label_size = os.path.getsize(label_file) / (1024*1024)  # MB
            print(f"{status} {source}: ë°ì´í„°({data_size:.1f}MB) + ë¼ë²¨({label_size:.1f}MB)")
        else:
            print(f"{status} {source}: íŒŒì¼ ëˆ„ë½ (data: {data_exists}, label: {label_exists})")
    
    return file_status

def plan_revised_3class():
    """ìˆ˜ì •ëœ 3í´ë˜ìŠ¤ êµ¬ì„± ê³„íš"""
    
    print("\nğŸ¯ === ìˆ˜ì •ëœ NEW2 3í´ë˜ìŠ¤ êµ¬ì„± ê³„íš ===\n")
    
    # ê¸°ì¡´ ë¬¸ì œì 
    print("âŒ ê¸°ì¡´ ë¬¸ì œì :")
    print("   - industry ë°ì´í„°ë¡œ ì¸í•œ í´ë˜ìŠ¤ 1(ê·œì¹™ì ì‚°ì—…ì§„ë™) í¸í–¥")
    print("   - ëª¨ë“  ì‹¤ì‹œê°„ ë¶„ì„ì´ 99.7% ì‹ ë¢°ë„ë¡œ ê·œì¹™ì ì‚°ì—…ì§„ë™ ì˜ˆì¸¡")
    print("   - ì§€ì§„ê³¼ ë¶ˆê·œì¹™ìƒí™œì§„ë™ í´ë˜ìŠ¤ ì¸ì‹ë¥  ì €í•˜")
    
    # ìˆ˜ì • ë°©ì•ˆ
    print("\nâœ… ìˆ˜ì • ë°©ì•ˆ:")
    print("   - industry ë°ì´í„° ì™„ì „ ì œì™¸")
    print("   - ê·œì¹™ì ì‚°ì—…ì§„ë™ì€ motor ë°ì´í„°ë§Œ ì‚¬ìš©")
    print("   - ë” ê· í˜•ì¡íŒ 3í´ë˜ìŠ¤ êµ¬ì„±")
    
    # ìƒˆë¡œìš´ í´ë˜ìŠ¤ êµ¬ì„±
    revised_mapping = {
        0: {
            'name': 'ì§€ì§„',
            'sources': ['kor_quake', 'jpn_quake'],
            'description': 'í•œêµ­ ì§€ì§„ + ì¼ë³¸ ì§€ì§„ ë°ì´í„°'
        },
        1: {
            'name': 'ê·œì¹™ì ì‚°ì—…ì§„ë™',
            'sources': ['motor'],
            'description': 'ëª¨í„° ì§„ë™ ë°ì´í„°ë§Œ (industry ì œì™¸)'
        },
        2: {
            'name': 'ë¶ˆê·œì¹™ìƒí™œì§„ë™',
            'sources': ['live', 'irregular'],
            'description': 'ìƒí™œ ì§„ë™ + ë¶ˆê·œì¹™ ì§„ë™ ë°ì´í„°'
        }
    }
    
    print("\nğŸ“Š ìƒˆë¡œìš´ 3í´ë˜ìŠ¤ êµ¬ì„±:")
    for class_id, info in revised_mapping.items():
        icon = 'ğŸ”´' if class_id == 0 else 'ğŸŸ ' if class_id == 1 else 'ğŸŸ¢'
        print(f"   {icon} í´ë˜ìŠ¤ {class_id}: {info['name']}")
        print(f"      ì†ŒìŠ¤: {', '.join(info['sources'])}")
        print(f"      ì„¤ëª…: {info['description']}")
    
    return revised_mapping

def estimate_dataset_balance(file_status, revised_mapping):
    """ìˆ˜ì •ëœ ë°ì´í„°ì…‹ ê· í˜•ì„± ì¶”ì •"""
    
    print("\nâš–ï¸ === ìˆ˜ì •ëœ ë°ì´í„°ì…‹ ê· í˜•ì„± ì¶”ì • ===\n")
    
    # ê¸°ì¡´ ë°ì´í„°ì…‹ì˜ ëŒ€ëµì ì¸ ìƒ˜í”Œ ìˆ˜ (ë¬¸ì„œ ê¸°ë°˜)
    estimated_counts = {
        'kor_quake': 2308,    # í•œêµ­ ì§€ì§„
        'jpn_quake': 1564,    # ì¼ë³¸ ì§€ì§„
        'industry': 1110,     # ì‚°ì—… ì§„ë™ (ì œì™¸ë¨)
        'motor': 1604,        # ëª¨í„° ì§„ë™
        'live': 2135,         # ìƒí™œ ì§„ë™
        'irregular': 700      # ë¶ˆê·œì¹™ ì§„ë™
    }
    
    print("ğŸ“ˆ ì˜ˆìƒ í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜:")
    
    total_samples = 0
    class_counts = {}
    
    for class_id, info in revised_mapping.items():
        class_total = 0
        sources_detail = []
        
        for source in info['sources']:
            if source in estimated_counts:
                count = estimated_counts[source]
                class_total += count
                sources_detail.append(f"{source}({count:,}ê°œ)")
            else:
                sources_detail.append(f"{source}(íŒŒì¼ì—†ìŒ)")
        
        class_counts[class_id] = class_total
        total_samples += class_total
        
        icon = 'ğŸ”´' if class_id == 0 else 'ğŸŸ ' if class_id == 1 else 'ğŸŸ¢'
        print(f"   {icon} í´ë˜ìŠ¤ {class_id} ({info['name']}): {class_total:,}ê°œ")
        print(f"      â””â”€â”€ {' + '.join(sources_detail)}")
    
    print(f"\nğŸ“Š ì „ì²´ ë°ì´í„°ì…‹ ìš”ì•½:")
    print(f"   ì´ ìƒ˜í”Œ: {total_samples:,}ê°œ (industry {estimated_counts['industry']:,}ê°œ ì œì™¸)")
    print(f"   ì œì™¸ëœ ìƒ˜í”Œ: {estimated_counts['industry']:,}ê°œ")
    
    # ê· í˜•ì„± ë¶„ì„
    if class_counts:
        min_count = min(class_counts.values())
        max_count = max(class_counts.values())
        balance_ratio = max_count / min_count if min_count > 0 else float('inf')
        
        print(f"\nâš–ï¸ í´ë˜ìŠ¤ ê· í˜•ì„±:")
        print(f"   ìµœì†Œ: {min_count:,}ê°œ, ìµœëŒ€: {max_count:,}ê°œ")
        print(f"   ê· í˜• ë¹„ìœ¨: {balance_ratio:.1f}:1")
        
        if balance_ratio <= 2.0:
            print("   âœ… ì–‘í˜¸í•œ ê· í˜• (2:1 ì´í•˜)")
        elif balance_ratio <= 3.0:
            print("   âš ï¸ ë³´í†µ ê· í˜• (3:1 ì´í•˜)")
        else:
            print("   âŒ ë¶ˆê· í˜• (ê· í˜• ì¡°ì • í•„ìš”)")
    
    return class_counts, total_samples

def create_implementation_plan():
    """êµ¬í˜„ ê³„íš ìƒì„±"""
    
    print("\nğŸš€ === êµ¬í˜„ ê³„íš ===\n")
    
    steps = [
        {
            'step': 1,
            'title': 'ìˆ˜ì •ëœ 3í´ë˜ìŠ¤ ë°ì´í„°ì…‹ ìƒì„±',
            'tasks': [
                'industry ë°ì´í„° ì œì™¸í•œ 3class_balanced_dataset.py ì‹¤í–‰',
                'ìƒˆë¡œìš´ ê· í˜• ë°ì´í„°ì…‹ ìƒì„± (motorë§Œ í´ë˜ìŠ¤ 1ë¡œ)',
                '6:2:2 ë¶„í• ë¡œ í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ìƒì„±'
            ]
        },
        {
            'step': 2,
            'title': 'NEW2 ëª¨ë¸ ì¬í›ˆë ¨',
            'tasks': [
                'train_new2_convlstm.pyë¡œ ìƒˆ ë°ì´í„°ì…‹ í›ˆë ¨',
                'ì„±ëŠ¥ ì§€í‘œ ë¶„ì„ ë° í´ë˜ìŠ¤ë³„ ì •í™•ë„ í™•ì¸',
                'í˜¼ë™í–‰ë ¬ ë¶„ì„ìœ¼ë¡œ í¸í–¥ í•´ê²° ì—¬ë¶€ ê²€ì¦'
            ]
        },
        {
            'step': 3,
            'title': 'ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸',
            'tasks': [
                'ìƒˆ ëª¨ë¸ë¡œ influx_new2_realtime.py í…ŒìŠ¤íŠ¸',
                'ë‹¤ì–‘í•œ ì§„ë™ ìœ í˜•ì— ëŒ€í•œ ë¶„ë¥˜ ì •í™•ë„ ê²€ì¦',
                'ì˜¤ê²½ë³´ìœ¨ ê°ì†Œ íš¨ê³¼ ì¸¡ì •'
            ]
        },
        {
            'step': 4,
            'title': 'ì„±ëŠ¥ ë¹„êµ ë° ë¬¸ì„œí™”',
            'tasks': [
                'ê¸°ì¡´ vs ìˆ˜ì •ëœ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ',
                'ì‹¤ì œ í™˜ê²½ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì—…ë°ì´íŠ¸',
                'PROJECT_PLAN.md ì—…ë°ì´íŠ¸'
            ]
        }
    ]
    
    for step_info in steps:
        print(f"ğŸ“‹ Step {step_info['step']}: {step_info['title']}")
        for task in step_info['tasks']:
            print(f"   âœ“ {task}")
        print()
    
    return steps

def save_revision_plan(file_status, revised_mapping, class_counts, steps):
    """ìˆ˜ì • ê³„íš ì €ì¥"""
    
    revision_plan = {
        'timestamp': datetime.now().isoformat(),
        'revision_info': {
            'title': 'NEW2 3í´ë˜ìŠ¤ ìˆ˜ì • ê³„íš',
            'version': 'v2.1',
            'reason': 'ê·œì¹™ì ì‚°ì—…ì§„ë™ í´ë˜ìŠ¤ í¸í–¥ ë¬¸ì œ í•´ê²°',
            'excluded_data': 'industry ë°ì´í„° (1,110ê°œ ìƒ˜í”Œ)'
        },
        'file_analysis': file_status,
        'revised_class_mapping': revised_mapping,
        'estimated_balance': {
            'class_counts': class_counts,
            'total_samples': sum(class_counts.values()) if class_counts else 0
        },
        'implementation_steps': steps,
        'expected_improvements': {
            'reduced_bias': 'ê·œì¹™ì ì‚°ì—…ì§„ë™ í´ë˜ìŠ¤ í¸í–¥ í•´ê²°',
            'better_balance': '3í´ë˜ìŠ¤ ê°„ ë” ë‚˜ì€ ê· í˜•',
            'improved_accuracy': 'ì§€ì§„ ë° ë¶ˆê·œì¹™ìƒí™œì§„ë™ ì¸ì‹ë¥  í–¥ìƒ',
            'reduced_false_alarms': 'ì˜¤ê²½ë³´ìœ¨ ê°ì†Œ ê¸°ëŒ€'
        }
    }
    
    with open('NEW2_revision_plan.json', 'w', encoding='utf-8') as f:
        json.dump(revision_plan, f, ensure_ascii=False, indent=2)
    
    print("ğŸ’¾ ìˆ˜ì • ê³„íš ì €ì¥: NEW2_revision_plan.json")
    
    return revision_plan

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    
    print("ğŸ”§ NEW2 3í´ë˜ìŠ¤ ìˆ˜ì • ê³„íš ìˆ˜ë¦½\n")
    print("=" * 60)
    
    try:
        # 1. í˜„ì¬ ë°ì´í„° íŒŒì¼ ë¶„ì„
        file_status = analyze_current_data_files()
        
        # 2. ìˆ˜ì •ëœ 3í´ë˜ìŠ¤ êµ¬ì„± ê³„íš
        revised_mapping = plan_revised_3class()
        
        # 3. ë°ì´í„°ì…‹ ê· í˜•ì„± ì¶”ì •
        class_counts, total_samples = estimate_dataset_balance(file_status, revised_mapping)
        
        # 4. êµ¬í˜„ ê³„íš ìƒì„±
        steps = create_implementation_plan()
        
        # 5. ê³„íš ì €ì¥
        plan = save_revision_plan(file_status, revised_mapping, class_counts, steps)
        
        print(f"\nğŸ‰ NEW2 3í´ë˜ìŠ¤ ìˆ˜ì • ê³„íš ì™„ë£Œ!")
        print(f"ğŸ“Š ì˜ˆìƒ ê°œì„  íš¨ê³¼:")
        print(f"   ğŸ¯ í¸í–¥ í•´ê²°: industry ë°ì´í„° ì œì™¸")
        print(f"   âš–ï¸ ê· í˜• ê°œì„ : 3í´ë˜ìŠ¤ ê°„ ë” ë‚˜ì€ ë¶„í¬")
        print(f"   ğŸ” ì •í™•ë„ í–¥ìƒ: ì§€ì§„ íƒì§€ ì„±ëŠ¥ ê°œì„  ê¸°ëŒ€")
        
        return True
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    print(f"\n{'âœ…' if success else 'âŒ'} ê³„íš ìˆ˜ë¦½ {'ì™„ë£Œ' if success else 'ì‹¤íŒ¨'}!")