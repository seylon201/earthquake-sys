#!/usr/bin/env python3
"""
ì§€ì§„ ì˜¤ë³´ ë¶„ì„ ì‹œìŠ¤í…œ ConvLSTM ê¸°ë°˜ ì›¹ ëŒ€ì‹œë³´ë“œ
ê¸°ì¡´ streamlit_seismic_app.py + ì§€ì§„ ì˜¤ë³´ ë¶„ì„ ì‹œìŠ¤í…œ í†µí•© + ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ê°•í™”
"""

import streamlit as st
st.set_page_config(layout="wide", page_title="ì§€ì§„ ì˜¤ë³´ ë¶„ì„ ì‹œìŠ¤í…œ", page_icon="ğŸŒ")

# ëª¨ë“ˆ import
from dashboard_utils import CONFIG, SYSTEM_CLASS_NAMES, SYSTEM_CLASS_COLORS, SYSTEM_CLASS_COLOR_HEX, get_system_event_files, get_earthquake_alerts, parse_filename_info, get_time_diff_text
from retraining_manager import count_retraining_status, get_retraining_status_for_file, mark_all_files_as_retrained, render_retraining_sidebar
from chart_renderer import render_waveform_charts, render_class_distribution_charts

# Streamlit ë²„ì „ í˜¸í™˜ì„± ì²˜ë¦¬
def safe_rerun():
    """Streamlit ë²„ì „ì— ë”°ë¥¸ ì•ˆì „í•œ rerun í•¨ìˆ˜"""
    try:
        st.rerun()
    except AttributeError:
        try:
            st.experimental_rerun()
        except AttributeError:
            # ë§¤ìš° êµ¬ë²„ì „ì˜ ê²½ìš° - ì•„ë¬´ê²ƒë„ í•˜ì§€ ì•ŠìŒ (ë¬´í•œ ì¬ê·€ ë°©ì§€)
            pass

# ê¸°ë³¸ ìŠ¤íƒ€ì¼ë§ (ìë™ ìƒˆë¡œê³ ì¹¨ í—ˆìš©)
st.markdown("""
<style>
    /* ê¸°ë³¸ ìŠ¤íƒ€ì¼ë§Œ ì ìš© */
    .stApp {
        background-color: #ffffff;
    }
</style>
""", unsafe_allow_html=True)

# ê¹œë¹¡ì„ ìµœì†Œí™”ë¥¼ ìœ„í•œ Streamlit ì„¤ì •
if 'initialized' not in st.session_state:
    st.session_state.initialized = True

import pandas as pd
import numpy as np
import os
import time
import json
from datetime import datetime, timedelta
from tensorflow.keras.models import load_model
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings
warnings.filterwarnings('ignore')

# ì¬í•™ìŠµ ì‹œìŠ¤í…œ import
try:
    from retraining_system import NEW2RetrainingSystem
    RETRAINING_AVAILABLE = True
except ImportError:
    RETRAINING_AVAILABLE = False
    print("ì¬í•™ìŠµ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. retraining_system.pyë¥¼ í™•ì¸í•˜ì„¸ìš”.")

# =========================== ì„¤ì • ===========================

# CONFIGì™€ ìƒìˆ˜ë“¤ì€ dashboard_utils.pyì—ì„œ importë¨
SYSTEM_ALERT_STATUS = {0: 'EARTHQUAKE_ALERT', 1: 'NO_ALERT', 2: 'NO_ALERT'}

# ë””ë ‰í† ë¦¬ ìƒì„±
for dir_path in [CONFIG['RAW_DATA_DIR'], CONFIG['ANALYSIS_DIR'], CONFIG['ALERTS_DIR'], CONFIG['PROCESSED_DATA_DIR']]:
    os.makedirs(dir_path, exist_ok=True)

# =========================== ëª¨ë¸ ë¡œë”© ===========================

@st.cache_resource
def load_new2_model():
    """ì§€ì§„ ì˜¤ë³´ ë¶„ì„ ì‹œìŠ¤í…œ ConvLSTM ëª¨ë¸ ë¡œë”©"""
    
    for model_path in CONFIG['MODEL_PATHS']:
        possible_paths = [
            model_path,
            f"C:/earthquake_project/{model_path}",
            f"./earthquake_project/{model_path}"
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                try:
                    # st.info(f"ğŸ”„ ì§€ì§„ ì˜¤ë³´ ë¶„ì„ ì‹œìŠ¤í…œ ëª¨ë¸ ë¡œë”© ì¤‘: {os.path.basename(path)}")
                    
                    import tensorflow as tf
                    tf.get_logger().setLevel('ERROR')
                    
                    model = load_model(path, compile=False)
                    st.success(f"âœ… ì§€ì§„ ì˜¤ë³´ ë¶„ì„ ì‹œìŠ¤í…œ ëª¨ë¸ ë¡œë”© ì™„ë£Œ! (98.46% ì •í™•ë„)")
                    # st.info(f"ğŸ“Š ì…ë ¥ í˜•íƒœ: {model.input_shape}")
                    # st.info(f"ğŸ“Š ì¶œë ¥ í˜•íƒœ: {model.output_shape}")
                    return model, os.path.basename(path)
                    
                except Exception as e:
                    st.warning(f"âš ï¸ {path} ë¡œë”© ì‹¤íŒ¨: {e}")
                    continue
    
    st.error("âŒ ì§€ì§„ ì˜¤ë³´ ë¶„ì„ ì‹œìŠ¤í…œ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.write("**í™•ì¸í•  ê²½ë¡œë“¤:**")
    for model_path in CONFIG['MODEL_PATHS']:
        st.write(f"- {model_path}")
    return None, None

# =========================== ì˜¤ë³´ ìˆ˜ì • ê´€ë ¨ í•¨ìˆ˜ë“¤ ===========================

def save_correction(file_info, corrected_class, corrected_class_name):
    """ì˜¤ë¶„ë¥˜ ìˆ˜ì • ë‚´ìš©ì„ ì €ì¥í•˜ê³  ì¬í•™ìŠµìš© ë°ì´í„°ë¡œ ìˆ˜ì§‘"""
    try:
        filepath = file_info.get('filepath', '')
        filename = file_info.get('filename', '')
        
        if not os.path.exists(filepath):
            st.error(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filepath}")
            return False
        
        # ìˆ˜ì •ëœ ë°ì´í„° ì €ì¥í•  ë””ë ‰í† ë¦¬ ìƒì„±
        corrections_dir = os.path.join(CONFIG['BASE_OUTPUT_DIR'], 'corrections')
        os.makedirs(corrections_dir, exist_ok=True)
        
        # ì¬í•™ìŠµìš© ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±
        retraining_dir = os.path.join(CONFIG['BASE_OUTPUT_DIR'], 'retraining_data')
        os.makedirs(retraining_dir, exist_ok=True)
        
        # í˜„ì¬ ì‹œê°„
        correction_time = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
        
        # ì›ë³¸ ë°ì´í„° ë¡œë“œ
        df_original = pd.read_csv(filepath)
        
        # ìˆ˜ì • ë‚´ì—­ ê¸°ë¡
        correction_log = {
            'timestamp': correction_time,
            'original_file': filename,
            'original_filepath': filepath,
            'original_analysis': file_info.get('current_result', 'Unknown'),
            'original_confidence': file_info.get('current_confidence', 'Unknown'),
            'corrected_class': corrected_class,
            'corrected_class_name': corrected_class_name,
            'corrected_by': 'expert_manual',  # ì „ë¬¸ê°€ ìˆ˜ë™ ìˆ˜ì •
            'data_shape': df_original.shape,
            'file_size_kb': round(os.path.getsize(filepath) / 1024, 2)
        }
        
        # ì›ë³¸ íŒŒì¼ ìˆ˜ì • ë° ì¬í•™ìŠµìš© ë°ì´í„° ìƒì„±
        try:
            # ì›ë³¸ íŒŒì¼ì— ì „ë¬¸ê°€ ìˆ˜ì • ì •ë³´ ì¶”ê°€
            df_original['expert_corrected'] = True
            df_original['expert_corrected_class'] = corrected_class
            df_original['expert_corrected_class_name'] = corrected_class_name
            df_original['expert_corrected_timestamp'] = correction_time
            
            # ê¸°ì¡´ AI ë¶„ì„ ê²°ê³¼ ë®ì–´ì“°ê¸° (ì™„ì „ êµì²´)
            if 'ai_class_name' in df_original.columns:
                df_original['ai_class_name'] = corrected_class_name  # í•µì‹¬: ì´ ì»¬ëŸ¼ ì—…ë°ì´íŠ¸
            if 'ai_predicted_class' in df_original.columns:
                df_original['ai_predicted_class'] = corrected_class
            if 'ai_final_class' in df_original.columns:
                df_original['ai_final_class'] = corrected_class
            if 'ai_final_class_name' in df_original.columns:
                df_original['ai_final_class_name'] = corrected_class_name
            if 'ai_final_confidence' in df_original.columns:
                df_original['ai_final_confidence'] = 1.0  # ì „ë¬¸ê°€ ìˆ˜ì •ì€ 100% ì‹ ë¢°ë„
            
            # ì›ë³¸ íŒŒì¼ ë®ì–´ì“°ê¸° (Windows í˜¸í™˜ ì¸ì½”ë”©, CSV í˜•ì‹ ë³´ì¥)
            import csv
            df_original.to_csv(filepath, index=False, encoding='utf-8-sig', quoting=csv.QUOTE_MINIMAL, escapechar='\\')
            
            # ì¬í•™ìŠµìš© ë°ì´í„°ë¡œ new2_analysis í´ë”ì—ë„ ë³µì‚¬
            analysis_filename = filename
            if not analysis_filename.startswith('new2_ai_'):
                # íŒŒì¼ëª…ì´ event_ë¡œ ì‹œì‘í•˜ë©´ new2_ai_ë¡œ ë³€ê²½
                if analysis_filename.startswith('event_'):
                    analysis_filename = analysis_filename.replace('event_', 'new2_ai_', 1)
                else:
                    analysis_filename = f"new2_ai_{analysis_filename}"
            
            analysis_filepath = os.path.join(CONFIG['ANALYSIS_DIR'], analysis_filename)
            df_original.to_csv(analysis_filepath, index=False, encoding='utf-8-sig', quoting=csv.QUOTE_MINIMAL, escapechar='\\')
            
            st.success(f"âœ… ì „ë¬¸ê°€ ìˆ˜ì • ì™„ë£Œ: {os.path.basename(filepath)}")
            # st.info(f"ğŸ“ ì¬í•™ìŠµ ë°ì´í„° ì €ì¥: {os.path.basename(analysis_filepath)}")
            
        except Exception as update_error:
            st.error(f"âŒ íŒŒì¼ ìˆ˜ì • ì‹¤íŒ¨: {update_error}")
            return False
        
        return True
        
    except Exception as e:
        st.error(f"âŒ ìˆ˜ì • ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        st.code(traceback.format_exc())
        return False

# =========================== ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ë“¤ ===========================

def get_system_event_files():
    """ì§€ì§„ ì˜¤ë³´ ë¶„ì„ ì‹œìŠ¤í…œìœ¼ë¡œ ë¶„ì„ëœ ì´ë²¤íŠ¸ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
    all_files = []
    
    # ë””ë²„ê¹…: ë””ë ‰í† ë¦¬ ì¡´ì¬ ì—¬ë¶€ì™€ íŒŒì¼ ëª©ë¡ í™•ì¸
    analysis_dir = CONFIG['ANALYSIS_DIR']
    if os.path.exists(analysis_dir):
        all_filenames = os.listdir(analysis_dir)
        csv_files = [f for f in all_filenames if f.endswith('.csv')]
        new2_ai_files = [f for f in csv_files if f.startswith('new2_ai_')]
        
        # ë””ë²„ê¹… ì •ë³´ ì €ì¥
        st.session_state.debug_file_scan = f"ğŸ“‚ ë””ë ‰í† ë¦¬: {len(all_filenames)}ê°œ íŒŒì¼, CSV: {len(csv_files)}ê°œ, new2_ai: {len(new2_ai_files)}ê°œ"
        
        # 1. ì§€ì§„ ì˜¤ë³´ ë¶„ì„ ì‹œìŠ¤í…œ AI ë¶„ì„ ê²°ê³¼ (ìš°ì„ ìˆœìœ„ 1)
        for filename in new2_ai_files:
            filepath = os.path.join(analysis_dir, filename)
            try:
                modified_time = datetime.fromtimestamp(os.path.getmtime(filepath))
                all_files.append({
                    'filename': filename,
                    'filepath': filepath,
                    'modified_datetime': modified_time,
                    'type': 'SYSTEM_ANALYSIS',
                    'original_filename': filename.replace('new2_ai_', 'event_')
                })
            except:
                continue
    else:
        st.session_state.debug_file_scan = f"âŒ ë””ë ‰í† ë¦¬ ì—†ìŒ: {analysis_dir}"
    
    # 2. ê¸°ì¡´ AI ì²˜ë¦¬ ê²°ê³¼ (í˜¸í™˜ì„±)
    if os.path.exists(CONFIG['PROCESSED_DATA_DIR']):
        processed_files = {f['original_filename'] for f in all_files}
        
        for filename in os.listdir(CONFIG['PROCESSED_DATA_DIR']):
            if filename.endswith('.csv') and filename.startswith('ai_'):
                original_name = filename.replace('ai_', 'event_')
                if original_name not in processed_files:  # ì§€ì§„ ì˜¤ë³´ ë¶„ì„ ì‹œìŠ¤í…œ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°ë§Œ
                    filepath = os.path.join(CONFIG['PROCESSED_DATA_DIR'], filename)
                    try:
                        modified_time = datetime.fromtimestamp(os.path.getmtime(filepath))
                        all_files.append({
                            'filename': filename,
                            'filepath': filepath,
                            'modified_datetime': modified_time,
                            'type': 'LEGACY_AI',
                            'original_filename': original_name
                        })
                    except:
                        continue
    
    # 3. ì›ì‹œ ë°ì´í„° (AI ì²˜ë¦¬ë˜ì§€ ì•Šì€ ê²½ìš°)
    if os.path.exists(CONFIG['RAW_DATA_DIR']):
        processed_files = {f['original_filename'] for f in all_files}
        
        for filename in os.listdir(CONFIG['RAW_DATA_DIR']):
            if filename.endswith('.csv') and filename.startswith('event_'):
                if filename not in processed_files:
                    filepath = os.path.join(CONFIG['RAW_DATA_DIR'], filename)
                    try:
                        modified_time = datetime.fromtimestamp(os.path.getmtime(filepath))
                        all_files.append({
                            'filename': filename,
                            'filepath': filepath,
                            'modified_datetime': modified_time,
                            'type': 'RAW_DATA',
                            'original_filename': filename
                        })
                    except:
                        continue
    
    # ì¤‘ë³µ ì œê±° - ê°™ì€ original_filenameì„ ê°€ì§„ íŒŒì¼ë“¤ ì¤‘ ìµœì‹  ê²ƒë§Œ ìœ ì§€
    unique_files = {}
    for file_info in all_files:
        original_name = file_info['original_filename']
        if original_name not in unique_files:
            unique_files[original_name] = file_info
        else:
            # ë” ìµœì‹  íŒŒì¼ë¡œ êµì²´ (ìˆ˜ì • ì‹œê°„ ê¸°ì¤€)
            if file_info['modified_datetime'] > unique_files[original_name]['modified_datetime']:
                unique_files[original_name] = file_info
    
    # ë°œìƒì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ìµœì‹  ì´ë²¤íŠ¸ê°€ ìœ„ë¡œ)
    def get_event_datetime(file_info):
        try:
            parsed_info = parse_filename_info(file_info['filename'])
            # ë°œìƒì‹œê°„ì„ datetime ê°ì²´ë¡œ ë³€í™˜
            return datetime.strptime(parsed_info['datetime_str'], '%Y-%m-%d %H:%M:%S')
        except:
            # íŒŒì‹± ì‹¤íŒ¨ì‹œ ìˆ˜ì • ì‹œê°„ìœ¼ë¡œ ëŒ€ì²´
            return file_info['modified_datetime']
    
    final_files = list(unique_files.values())
    final_files.sort(key=get_event_datetime, reverse=True)
    return final_files

@st.cache_data(ttl=10)  # 10ì´ˆ ìºì‹œ
def get_earthquake_alerts():
    """ì§€ì§„ ê²½ë³´ ë¡œê·¸ ê°€ì ¸ì˜¤ê¸°"""
    alerts = []
    
    if os.path.exists(CONFIG['ALERTS_DIR']):
        for filename in os.listdir(CONFIG['ALERTS_DIR']):
            if filename.endswith('.json') and filename.startswith('earthquake_alert_'):
                filepath = os.path.join(CONFIG['ALERTS_DIR'], filename)
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        alert_data = json.load(f)
                    
                    alert_data['filename'] = filename
                    alert_data['filepath'] = filepath
                    alerts.append(alert_data)
                except:
                    continue
    
    # ì‹œê°„ìˆœ ì •ë ¬ (ìµœì‹  ìˆœ)
    alerts.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
    return alerts

def parse_filename_info(filename):
    """ì§€ì§„ ì˜¤ë³´ ë¶„ì„ ì‹œìŠ¤í…œ íŒŒì¼ëª…ì—ì„œ ì •ë³´ ì¶”ì¶œ"""
    try:
        # new2_ai_6060_2025-06-28_20-49-01.csv ë˜ëŠ” event_6060_2025-06-28_20-49-01.csv
        parts = filename.replace('.csv', '').split('_')
        
        if filename.startswith('new2_ai_'):
            port = parts[2]
            date_str = parts[3]
            time_str = parts[4]
        elif filename.startswith('ai_'):
            port = parts[1]
            date_str = parts[2]
            time_str = parts[3]
        else:  # event_
            port = parts[1]
            date_str = parts[2]
            time_str = parts[3]
        
        datetime_str = f"{date_str} {time_str.replace('-', ':')}"
        
        return {
            'port': port,
            'datetime_str': datetime_str,
            'location': f"ì„¼ì„œ_{port}"
        }
    except:
        return {
            'port': 'Unknown',
            'datetime_str': 'Unknown',
            'location': 'Unknown'
        }



# =========================== ì‚¬ì´ë“œë°” ===========================

def render_system_sidebar():
    """ì§€ì§„ ì˜¤ë³´ ë¶„ì„ ì‹œìŠ¤í…œ ì‚¬ì´ë“œë°”"""
    st.sidebar.title("ğŸŒ ì§€ì§„ ì˜¤ë³´ ë¶„ì„")
    st.sidebar.markdown("*ì§€ì§„ ì˜¤ë³´ ë¶„ì„ ì‹œìŠ¤í…œ*")
    
    # ì‚­ì œ í™•ì¸ íŒì—… ì²˜ë¦¬ (ì‚¬ì´ë“œë°”ì—ì„œ)
    delete_modal_active = False
    for idx in range(100):  # ìµœëŒ€ 100ê°œ í™•ì¸
        delete_modal_key = f'show_delete_modal_{idx}'
        if st.session_state.get(delete_modal_key, False):
            delete_modal_active = True
            delete_file_info_key = f'delete_file_info_{idx}'
            file_info = st.session_state.get(delete_file_info_key, {})
            
            st.sidebar.markdown("---")
            st.sidebar.error("ğŸš¨ **ì‚­ì œ í™•ì¸ í•„ìš”**")
            
            # ì‚­ì œ í™•ì¸ íŒì—…ì„ ì‚¬ì´ë“œë°”ì—ì„œ ì²˜ë¦¬
            with st.sidebar.container():
                st.markdown("### ğŸ—‘ï¸ íŒŒì¼ ì‚­ì œ")
                st.error("âš ï¸ **ì´ íŒŒì¼ì„ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?**")
                
                # íŒŒì¼ ì •ë³´ í‘œì‹œ
                st.info(f"**ğŸ“ íŒŒì¼:** `{file_info.get('filename', 'Unknown')}`")
                st.info(f"**ğŸ“ ìœ„ì¹˜:** {file_info.get('location', 'Unknown')}")
                st.info(f"**ğŸ” ê²°ê³¼:** {file_info.get('analysis_result', 'Unknown')}")
                
                filepath = file_info.get('filepath', '')
                if os.path.exists(filepath):
                    try:
                        file_size_kb = os.path.getsize(filepath) / 1024
                        st.info(f"**ğŸ“Š í¬ê¸°:** {file_size_kb:.1f}KB")
                    except:
                        st.info(f"**ğŸ“Š í¬ê¸°:** Unknown")
                else:
                    st.warning("**âš ï¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ**")
                
                st.error("**âš ï¸ ë˜ëŒë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!**")
                
                # ì‚­ì œ í™•ì¸ ë²„íŠ¼ë“¤
                col1, col2 = st.columns(2)
                
                with col1:
                    if st.button("ğŸ—‘ï¸ ì‚­ì œ", key=f"sidebar_confirm_delete_{idx}", use_container_width=True, type="primary"):
                        if os.path.exists(filepath):
                            try:
                                # íŒŒì¼ ì‚­ì œ ì‹¤í–‰
                                os.remove(filepath)
                                st.session_state[delete_modal_key] = False
                                st.session_state[f'delete_success_{idx}'] = f"âœ… {file_info.get('filename', '')} íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."
                                st.cache_data.clear()
                                safe_rerun()
                            except Exception as e:
                                st.error(f"âŒ ì‚­ì œ ì‹¤íŒ¨: {str(e)}")
                                st.session_state[delete_modal_key] = False
                                safe_rerun()
                        else:
                            st.warning("âš ï¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                            st.session_state[delete_modal_key] = False
                            safe_rerun()
                
                with col2:
                    if st.button("âŒ ì·¨ì†Œ", key=f"sidebar_cancel_delete_{idx}", use_container_width=True):
                        st.session_state[delete_modal_key] = False
                        safe_rerun()
            
            st.sidebar.markdown("---")
            break  # í•˜ë‚˜ì˜ ì‚­ì œ íŒì—…ë§Œ ì²˜ë¦¬
    
    # ìˆ˜ì • í™•ì¸ íŒì—… ì²˜ë¦¬ (ì‚¬ì´ë“œë°”ì—ì„œ)
    modify_modal_active = False
    if not delete_modal_active:  # ì‚­ì œ íŒì—…ì´ ì—†ì„ ë•Œë§Œ ìˆ˜ì • íŒì—… ì²˜ë¦¬
        for idx in range(100):  # ìµœëŒ€ 100ê°œ í™•ì¸
            modify_modal_key = f'show_modify_modal_{idx}'
            if st.session_state.get(modify_modal_key, False):
                modify_modal_active = True
                modify_file_info_key = f'modify_file_info_{idx}'
                file_info = st.session_state.get(modify_file_info_key, {})
                
                st.sidebar.markdown("---")
                st.sidebar.warning("âœï¸ **ë¶„ì„ ê²°ê³¼ ìˆ˜ì •**")
                
                # ìˆ˜ì • íŒì—…ì„ ì‚¬ì´ë“œë°”ì—ì„œ ì²˜ë¦¬
                with st.sidebar.container():
                    st.markdown("### âœï¸ ê²°ê³¼ ìˆ˜ì •")
                    st.info("**ì˜¬ë°”ë¥¸ ë¶„ë¥˜ë¥¼ ì„ íƒí•˜ì„¸ìš”**")
                    
                    # íŒŒì¼ ì •ë³´ í‘œì‹œ
                    st.info(f"**ğŸ“ íŒŒì¼:** `{file_info.get('filename', 'Unknown')}`")
                    current_result = file_info.get('current_result', 'Unknown')
                    st.info(f"**í˜„ì¬:** {current_result}")
                    
                    # í˜„ì¬ ì„ íƒëœ í´ë˜ìŠ¤ í™•ì¸ (ê¸°ë³¸ê°’ ì„¤ì •)
                    if 'ğŸ”´' in current_result or 'ì§€ì§„' in current_result:
                        default_selection = 0
                    elif 'ğŸŸ ' in current_result or 'ì‚°ì—…ì§„ë™' in current_result:
                        default_selection = 1
                    elif 'ğŸŸ¢' in current_result or 'ìƒí™œì§„ë™' in current_result:
                        default_selection = 2
                    else:
                        default_selection = 0
                    
                    # ë¼ë””ì˜¤ ë²„íŠ¼ìœ¼ë¡œ í´ë˜ìŠ¤ ì„ íƒ (ì‚¬ì´ë“œë°”ìš© ê°„ë‹¨ ë²„ì „)
                    selected_class = st.radio(
                        "ë¶„ë¥˜ ì„ íƒ:",
                        options=[0, 1, 2],
                        format_func=lambda x: "ğŸ”´ ì§€ì§„" if x == 0 else "ğŸŸ  ê·œì¹™ì ì‚°ì—…ì§„ë™" if x == 1 else "ğŸŸ¢ ë¶ˆê·œì¹™ìƒí™œì§„ë™",
                        index=default_selection,
                        key=f"sidebar_radio_class_{idx}"
                    )
                    
                    st.warning("**ì „ë¬¸ê°€ ìˆ˜ì •ìœ¼ë¡œ ê¸°ë¡ë©ë‹ˆë‹¤**")
                    
                    # ì €ì¥ ë° ì·¨ì†Œ ë²„íŠ¼
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        if st.button("ğŸ’¾ ì €ì¥", key=f"sidebar_save_correction_{idx}", use_container_width=True, type="primary"):
                            class_names = {0: "ì§€ì§„", 1: "ê·œì¹™ì ì‚°ì—…ì§„ë™", 2: "ë¶ˆê·œì¹™ìƒí™œì§„ë™"}
                            class_name = class_names[selected_class]
                            
                            # ìˆ˜ì • ì‚¬í•­ ì €ì¥
                            if save_correction(file_info, selected_class, class_name):
                                # ëª¨ë‹¬ ë‹«ê¸°
                                st.session_state[modify_modal_key] = False
                                # ì„±ê³µ ë©”ì‹œì§€ ì„¤ì •
                                st.session_state[f'correction_success_{idx}'] = f"âœ… {class_name}ìœ¼ë¡œ ìˆ˜ì • ì™„ë£Œ!"
                                # ìºì‹œ í´ë¦¬ì–´í•˜ê³  ì¦‰ì‹œ ìƒˆë¡œê³ ì¹¨
                                st.cache_data.clear()
                                safe_rerun()
                    
                    with col2:
                        if st.button("âŒ ì·¨ì†Œ", key=f"sidebar_cancel_modify_{idx}", use_container_width=True):
                            st.session_state[modify_modal_key] = False
                            safe_rerun()
                
                st.sidebar.markdown("---")
                break  # í•˜ë‚˜ì˜ ìˆ˜ì • íŒì—…ë§Œ ì²˜ë¦¬
    
    # ì‚­ì œ ë˜ëŠ” ìˆ˜ì • íŒì—…ì´ í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ ë‹¤ë¥¸ ì‚¬ì´ë“œë°” ë‚´ìš©ì€ ìˆ¨ê¹€
    if delete_modal_active or modify_modal_active:
        return
    
    # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
    st.sidebar.subheader("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨")
    if st.sidebar.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨", use_container_width=True, type="primary"):
        st.cache_data.clear()
        safe_rerun()
    
    # í˜„ì¬ ìƒíƒœ í‘œì‹œ
    try:
        analysis_dir = CONFIG['ANALYSIS_DIR']
        if os.path.exists(analysis_dir):
            total_files = len([f for f in os.listdir(analysis_dir) if f.endswith('.csv') and f.startswith('new2_ai_')])
            st.sidebar.success(f"ğŸ“Š ì´ ì´ë²¤íŠ¸: {total_files}ê°œ")
        else:
            st.sidebar.warning("ğŸ“‚ ë¶„ì„ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤")
    except Exception as e:
        st.sidebar.error(f"âŒ ìƒíƒœ í™•ì¸ ì˜¤ë¥˜: {e}")
    
    # ë§ˆì§€ë§‰ ìƒˆë¡œê³ ì¹¨ ì‹œê°„
    current_time = datetime.now().strftime('%H:%M:%S')
    st.sidebar.caption(f"ë§ˆì§€ë§‰ ìƒˆë¡œê³ ì¹¨: {current_time}")
    
    st.sidebar.markdown("---")
    
    # ì‹œìŠ¤í…œ í†µê³„
    st.sidebar.subheader("ğŸ“Š ì‹œìŠ¤í…œ í†µê³„")
    
    current_files = get_system_event_files()
    current_alerts = get_earthquake_alerts()
    
    # í´ë˜ìŠ¤ë³„ ì¹´ìš´íŠ¸ ê³„ì‚°
    class_counts = {'ì§€ì§„': 0, 'ê·œì¹™ì ì‚°ì—…ì§„ë™': 0, 'ë¶ˆê·œì¹™ìƒí™œì§„ë™': 0}
    
    for file_info in current_files:
        if file_info['type'] in ['SYSTEM_ANALYSIS', 'LEGACY_AI']:
            try:
                df = pd.read_csv(file_info['filepath'])
                
                # ì „ë¬¸ê°€ ìˆ˜ì •ì´ ìˆìœ¼ë©´ ìˆ˜ì •ëœ í´ë˜ìŠ¤ ì‚¬ìš©
                if 'expert_corrected' in df.columns and df['expert_corrected'].iloc[0]:
                    corrected_class_name = df['expert_corrected_class_name'].iloc[0]
                    if corrected_class_name in class_counts:
                        class_counts[corrected_class_name] += 1
                # ì•„ë‹ˆë©´ AI ë¶„ì„ ê²°ê³¼ ì‚¬ìš©
                else:
                    # AI ë¶„ì„ ê²°ê³¼ ì‚¬ìš© (ì»´ëŸ¼ëª…ì— ë”°ë¼ ë‹¤ë¥¸ ì²˜ë¦¬)
                    if 'ai_predicted_class' in df.columns:
                        # NEW2 ë¶„ì„ ê²°ê³¼: ìˆ˜ì¹˜ í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©
                        pred_class = int(float(df['ai_predicted_class'].iloc[0]))
                        if pred_class in SYSTEM_CLASS_NAMES:
                            class_counts[SYSTEM_CLASS_NAMES[pred_class]] += 1
                    elif 'predicted_class_name' in df.columns:
                        # ê¸°ì¡´ processed ê²°ê³¼: í´ë˜ìŠ¤ëª…ì„ ì§ì ‘ ì‚¬ìš©
                        class_name = df['predicted_class_name'].iloc[0]
                        # ê¸°ì¡´ í´ë˜ìŠ¤ëª…ì„ ì‹ ê·œ ì²´ê³„ë¡œ ë§¤í•‘
                        if class_name == 'ì§€ì§„':
                            class_counts['ì§€ì§„'] += 1
                        elif class_name == 'ë¶ˆê·œì¹™ìƒí™œ' or class_name == 'ë¶ˆê·œì¹™ìƒí™œì§„ë™':
                            class_counts['ë¶ˆê·œì¹™ìƒí™œì§„ë™'] += 1
                        elif class_name == 'ëª¨í„°ì§„ë™' or class_name == 'ê·œì¹™ì ì‚°ì—…ì§„ë™':
                            class_counts['ê·œì¹™ì ì‚°ì—…ì§„ë™'] += 1
                    elif 'ai_final_class' in df.columns:
                        pred_class = int(float(df['ai_final_class'].iloc[0]))
                        if pred_class in SYSTEM_CLASS_NAMES:
                            class_counts[SYSTEM_CLASS_NAMES[pred_class]] += 1
                    elif 'predicted_class' in df.columns:
                        pred_class = int(float(df['predicted_class'].iloc[0]))
                        if pred_class in SYSTEM_CLASS_NAMES:
                            class_counts[SYSTEM_CLASS_NAMES[pred_class]] += 1
            except Exception as e:
                # ë””ë²„ê¹…ì„ ìœ„í•´ ì˜¤ë¥˜ ì •ë³´ ì¶”ê°€ (í•„ìš”ì‹œ ì‚¬ìš©)
                # st.sidebar.error(f"ë°ì´í„° ì½ê¸° ì˜¤ë¥˜: {file_info['filename']} - {str(e)}")
                continue
    
    st.sidebar.metric("ì´ ì´ë²¤íŠ¸", len(current_files))
    st.sidebar.metric("ğŸ”´ ì§€ì§„", class_counts['ì§€ì§„'])
    st.sidebar.metric("ğŸŸ  ê·œì¹™ì  ì‚°ì—…ì§„ë™", class_counts['ê·œì¹™ì ì‚°ì—…ì§„ë™'])
    st.sidebar.metric("ğŸŸ¢ ë¶ˆê·œì¹™ ìƒí™œì§„ë™", class_counts['ë¶ˆê·œì¹™ìƒí™œì§„ë™'])
    
    # ìµœê·¼ ì´ë²¤íŠ¸
    if current_files:
        latest_file = current_files[0]
        time_diff = datetime.now() - latest_file['modified_datetime']
        
        if time_diff.total_seconds() < 60:
            st.sidebar.metric("ìµœê·¼ ì´ë²¤íŠ¸", f"{int(time_diff.total_seconds())}ì´ˆ ì „")
        elif time_diff.total_seconds() < 3600:
            st.sidebar.metric("ìµœê·¼ ì´ë²¤íŠ¸", f"{int(time_diff.total_seconds()//60)}ë¶„ ì „")
        else:
            st.sidebar.metric("ìµœê·¼ ì´ë²¤íŠ¸", f"{int(time_diff.total_seconds()//3600)}ì‹œê°„ ì „")
    
    # ì¬í•™ìŠµ ê´€ë¦¬ ì„¹ì…˜
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ§  AI ëª¨ë¸ ì¬í•™ìŠµ")
    
    if RETRAINING_AVAILABLE:
        render_retraining_sidebar()
    else:
        st.sidebar.warning("âš ï¸ ì¬í•™ìŠµ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

# =========================== ì¬í•™ìŠµ ê´€ë¦¬ ===========================

@st.cache_resource
def get_retraining_system():
    """ì¬í•™ìŠµ ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
    if not RETRAINING_AVAILABLE:
        return None
    
    # Windows í™˜ê²½ìš© ê²½ë¡œ ì •ê·œí™”
    def normalize_path_for_retraining(path):
        """Windows í™˜ê²½ì—ì„œ ì¬í•™ìŠµ ì‹œìŠ¤í…œìš© ê²½ë¡œ ì •ê·œí™”"""
        import platform
        
        if platform.system() == "Windows":
            # Windows í™˜ê²½ì—ì„œëŠ” Windows ê²½ë¡œ ìŠ¤íƒ€ì¼ ìœ ì§€
            if path.startswith('/mnt/c/'):
                # WSL ê²½ë¡œë¥¼ Windows ê²½ë¡œë¡œ ë³€í™˜
                normalized = path.replace('/mnt/c/', 'C:/')
                normalized = normalized.replace('/', '\\')
                return normalized
            elif path.startswith('C:/'):
                # ìŠ¬ë˜ì‹œë¥¼ ë°±ìŠ¬ë˜ì‹œë¡œ ë³€í™˜
                return path.replace('/', '\\')
            return path
        else:
            # Linux/WSL í™˜ê²½ì—ì„œëŠ” ì›ë˜ ë¡œì§
            if path.startswith('C:\\') or path.startswith('C:/'):
                normalized = path.replace('C:\\', '/mnt/c/').replace('C:/', '/mnt/c/')
                normalized = normalized.replace('\\', '/')
                return normalized
            return path
    
    config = {
        'base_model_path': 'new2_convlstm_3class_best.h5',
        'retraining_data_dir': 'retraining_data',
        'retrained_models_dir': 'retrained_models',
        'analysis_dirs': [
            normalize_path_for_retraining(CONFIG['ANALYSIS_DIR']),
            normalize_path_for_retraining(CONFIG['RAW_DATA_DIR']),
            normalize_path_for_retraining(CONFIG['PROCESSED_DATA_DIR']),
            normalize_path_for_retraining("/mnt/c/earthquake_project"),  # í˜„ì¬ í”„ë¡œì íŠ¸ í´ë”ë„ í¬í•¨
            # Windows í™˜ê²½ì—ì„œ ì§ì ‘ ê²½ë¡œë„ ì¶”ê°€
            "C:\\earthquake_project\\influxLogs\\new2_analysis",
            "C:\\earthquake_project\\influxLogs\\base"
        ]
    }
    
    return NEW2RetrainingSystem(config)

def count_retraining_status():
    """ì¬í•™ìŠµ ì™„ë£Œ/ë¯¸ì™„ë£Œ íŒŒì¼ ì¹´ìš´íŒ…"""
    completed_count = 0
    pending_count = 0
    
    try:
        analysis_dir = CONFIG['ANALYSIS_DIR']
        if os.path.exists(analysis_dir):
            for filename in os.listdir(analysis_dir):
                if filename.endswith('.csv') and filename.startswith('new2_ai_'):
                    filepath = os.path.join(analysis_dir, filename)
                    try:
                        df = pd.read_csv(filepath)
                        
                        # ì¬í•™ìŠµ ì™„ë£Œ ì—¬ë¶€ í™•ì¸ (retraining_completed ì»¬ëŸ¼ ê¸°ì¤€)
                        if 'retraining_completed' in df.columns:
                            # ë‹¤ì–‘í•œ í˜•íƒœì˜ True ê°’ ì²˜ë¦¬ (ë¶ˆë¦°, ë¬¸ìì—´, ìˆ«ì)
                            retraining_value = df['retraining_completed'].iloc[0]
                            
                            # ë””ë²„ê¹…ìš© ì¶œë ¥
                            # print(f"íŒŒì¼ {filename}: retraining_value = {repr(retraining_value)} (íƒ€ì…: {type(retraining_value)})")
                            
                            # Trueë¡œ ê°„ì£¼í•  ì¡°ê±´ë“¤
                            is_completed = (
                                retraining_value is True or  # ë¶ˆë¦° True
                                retraining_value == 'True' or  # ë¬¸ìì—´ 'True'
                                str(retraining_value).lower() == 'true' or  # ëŒ€ì†Œë¬¸ì ë¬´ê´€ 'true'
                                (isinstance(retraining_value, (int, float)) and retraining_value == 1)  # ìˆ«ì 1
                            )
                            
                            if is_completed:
                                completed_count += 1
                            else:
                                pending_count += 1
                                # ì˜ëª»ëœ ê°’ì´ ìˆëŠ” íŒŒì¼ í™•ì¸ìš©
                                print(f"ë¯¸ì™„ë£Œë¡œ ë¶„ë¥˜: {filename} - ê°’: {repr(retraining_value)}")
                        else:
                            pending_count += 1
                            print(f"ì»¬ëŸ¼ ì—†ìŒ: {filename}")
                            
                    except Exception as e:
                        print(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ {filename}: {e}")
                        pending_count += 1  # ì½ê¸° ì‹¤íŒ¨í•œ íŒŒì¼ì€ ë¯¸ì™„ë£Œë¡œ ê°„ì£¼
                        
    except Exception as e:
        print(f"ì¬í•™ìŠµ ìƒíƒœ ì¹´ìš´íŒ… ì˜¤ë¥˜: {e}")
    
    return completed_count, pending_count

def get_retraining_status_for_file(filepath):
    """ê°œë³„ íŒŒì¼ì˜ ì¬í•™ìŠµ ìƒíƒœ í™•ì¸"""
    try:
        df = pd.read_csv(filepath)
        
        # ì¬í•™ìŠµ ì™„ë£Œ ì—¬ë¶€ í™•ì¸
        if 'retraining_completed' in df.columns:
            # ë‹¤ì–‘í•œ í˜•íƒœì˜ True ê°’ ì²˜ë¦¬ (ë¶ˆë¦°, ë¬¸ìì—´, ìˆ«ì)
            retraining_value = df['retraining_completed'].iloc[0]
            
            # Trueë¡œ ê°„ì£¼í•  ì¡°ê±´ë“¤
            is_completed = (
                retraining_value is True or  # ë¶ˆë¦° True
                retraining_value == 'True' or  # ë¬¸ìì—´ 'True'
                str(retraining_value).lower() == 'true' or  # ëŒ€ì†Œë¬¸ì ë¬´ê´€ 'true'
                (isinstance(retraining_value, (int, float)) and retraining_value == 1)  # ìˆ«ì 1
            )
            
            return "ì™„ë£Œ" if is_completed else "ë¯¸ì™„ë£Œ"
        else:
            return "ë¯¸ì™„ë£Œ"
            
    except Exception:
        return "ë¯¸ì™„ë£Œ"

def mark_all_files_as_retrained():
    """ëª¨ë“  ë¶„ì„ íŒŒì¼ì„ ì¬í•™ìŠµ ì™„ë£Œ ìƒíƒœë¡œ ì—…ë°ì´íŠ¸"""
    try:
        analysis_dir = CONFIG['ANALYSIS_DIR']
        if os.path.exists(analysis_dir):
            updated_count = 0
            
            for filename in os.listdir(analysis_dir):
                if filename.endswith('.csv') and filename.startswith('new2_ai_'):
                    filepath = os.path.join(analysis_dir, filename)
                    try:
                        df = pd.read_csv(filepath)
                        
                        # retraining_completed ì»¬ëŸ¼ ê°•ì œë¡œ Trueë¡œ ì„¤ì • (ê¸°ì¡´ ì˜ëª»ëœ ê°’ ë®ì–´ì“°ê¸°)
                        df['retraining_completed'] = True
                        
                        # ì¬í•™ìŠµ ì™„ë£Œ ì‹œê°„ ê¸°ë¡
                        df['retraining_timestamp'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        
                        # íŒŒì¼ ì €ì¥ (UTF-8 ì¸ì½”ë”©, CSV í¬ë§· ë³´ì¥)
                        df.to_csv(filepath, index=False, encoding='utf-8-sig', 
                                quoting=1, escapechar='\\')  # QUOTE_ALL ì‚¬ìš©
                        updated_count += 1
                        print(f"ì—…ë°ì´íŠ¸ ì™„ë£Œ: {filename}")
                        
                    except Exception as e:
                        print(f"íŒŒì¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ {filename}: {e}")
                        continue
            
            print(f"ì¬í•™ìŠµ ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸: {updated_count}ê°œ íŒŒì¼")
            return updated_count
            
    except Exception as e:
        print(f"ì¬í•™ìŠµ ìƒíƒœ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
        return 0

def render_retraining_sidebar():
    """ì¬í•™ìŠµ ê´€ë¦¬ ì‚¬ì´ë“œë°”"""
    # ì¬í•™ìŠµ ì™„ë£Œ/ë¯¸ì™„ë£Œ ì¹´ìš´íŒ…
    completed_count, pending_count = count_retraining_status()
    
    # ìƒíƒœ í‘œì‹œ
    col1, col2 = st.sidebar.columns(2)
    with col1:
        st.metric("ì™„ë£Œ", f"{completed_count}ê°œ", delta="ìˆ˜ì •ë¨")
    with col2:
        st.metric("ë¯¸ì™„ë£Œ", f"{pending_count}ê°œ", delta="ëŒ€ê¸°ì¤‘")
    
    # ì¬í•™ìŠµ ë²„íŠ¼
    st.sidebar.markdown("---")
    
    # ì¬í•™ìŠµ ì§„í–‰ ìƒíƒœ í™•ì¸
    if 'retraining_in_progress' not in st.session_state:
        st.session_state.retraining_in_progress = False
    
    if st.session_state.retraining_in_progress:
        st.sidebar.warning("ğŸ§  ì¬í•™ìŠµ ì§„í–‰ ì¤‘...")
        st.sidebar.info("ì¬í•™ìŠµì´ ì™„ë£Œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.")
        
        # ì¬í•™ìŠµ ì™„ë£Œ ì²´í¬ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ìƒíƒœ í™•ì¸)
        if st.sidebar.button("âœ… ì¬í•™ìŠµ ì™„ë£Œ", use_container_width=True):
            st.session_state.retraining_in_progress = False
            st.sidebar.success("ğŸ‰ ì¬í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            safe_rerun()
    
    else:
        if pending_count > 0:
            if st.sidebar.button(f"ğŸ§  ì¬í•™ìŠµ ì‹œì‘ ({pending_count}ê°œ)", 
                               type="primary", 
                               use_container_width=True,
                               help=f"ë¯¸ì™„ë£Œ {pending_count}ê°œ íŒŒì¼ë¡œ ëª¨ë¸ ì¬í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤"):
                
                # ì¬í•™ìŠµ ì‹œì‘
                st.session_state.retraining_in_progress = True
                st.sidebar.success("ğŸš€ ì¬í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤!")
                
                # ì‹¤ì œ ì¬í•™ìŠµ ë¡œì§ í˜¸ì¶œ (ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰)
                try:
                    retraining_system = get_retraining_system()
                    if retraining_system:
                        # ì—¬ê¸°ì„œ ì‹¤ì œ ì¬í•™ìŠµ ì‹¤í–‰
                        result = retraining_system.run_full_retraining_pipeline(min_corrections=1)
                        
                        if result['success']:
                            st.sidebar.success(f"âœ… {result['message']}")
                            if result.get('new_model_path'):
                                st.sidebar.info(f"ğŸ“ ìƒˆ ëª¨ë¸: {os.path.basename(result['new_model_path'])}")
                            # ì¬í•™ìŠµ ì‹œìŠ¤í…œì—ì„œ ìë™ìœ¼ë¡œ íŒŒì¼ ìƒíƒœ ì—…ë°ì´íŠ¸ë¨
                            
                        else:
                            st.sidebar.error(f"âŒ {result['message']}")
                        
                        st.session_state.retraining_in_progress = False
                    
                except Exception as e:
                    st.sidebar.error(f"âŒ ì¬í•™ìŠµ ì˜¤ë¥˜: {str(e)}")
                    st.session_state.retraining_in_progress = False
                
                safe_rerun()
        else:
            st.sidebar.info("ğŸ“‹ ì¬í•™ìŠµí•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            st.sidebar.caption("ì „ë¬¸ê°€ ìˆ˜ì •ì´ í•„ìš”í•©ë‹ˆë‹¤")
    
    # ì¬í•™ìŠµ ì‹œìŠ¤í…œ ì •ë³´
    retraining_system = get_retraining_system()
    if retraining_system:
        try:
            status = retraining_system.get_retraining_status()
            
            st.sidebar.markdown("---")
            st.sidebar.caption("ğŸ“Š ì¬í•™ìŠµ ì´ë ¥")
            st.sidebar.caption(f"â€¢ ì´ ì¬í•™ìŠµ íšŸìˆ˜: {status.get('retraining_count', 0)}íšŒ")
            
            if status.get('last_retraining'):
                try:
                    last_time = datetime.strptime(status['last_retraining'], '%Y%m%d_%H%M%S')
                    time_diff = datetime.now() - last_time
                    if time_diff.days > 0:
                        time_text = f"{time_diff.days}ì¼ ì „"
                    else:
                        time_text = f"{int(time_diff.total_seconds()//3600)}ì‹œê°„ ì „"
                    st.sidebar.caption(f"â€¢ ë§ˆì§€ë§‰ ì¬í•™ìŠµ: {time_text}")
                except:
                    st.sidebar.caption("â€¢ ë§ˆì§€ë§‰ ì¬í•™ìŠµ: ì˜¤ë¥˜")
            else:
                st.sidebar.caption("â€¢ ë§ˆì§€ë§‰ ì¬í•™ìŠµ: ì—†ìŒ")
                
        except Exception as e:
            st.sidebar.caption(f"ì¬í•™ìŠµ ì •ë³´ ì˜¤ë¥˜: {str(e)}")
    
    # ë””ë²„ê¹… ì •ë³´ ì¶”ê°€
    st.sidebar.markdown("---")
    st.sidebar.caption("ğŸ” ë””ë²„ê¹… ì •ë³´")
    st.sidebar.caption(f"â€¢ ì™„ë£Œ íŒŒì¼: {completed_count}ê°œ")
    st.sidebar.caption(f"â€¢ ë¯¸ì™„ë£Œ íŒŒì¼: {pending_count}ê°œ")
    if pending_count > 0:
        st.sidebar.caption(f"â€¢ ì¬í•™ìŠµ ê°€ëŠ¥: âœ… ì˜ˆ")
    else:
        st.sidebar.caption(f"â€¢ ì¬í•™ìŠµ ê°€ëŠ¥: âŒ ì•„ë‹ˆì˜¤")
    
    # ìˆ˜ë™ ìƒíƒœ ì—…ë°ì´íŠ¸ ë²„íŠ¼ (ì¬í•™ìŠµì€ í–ˆì§€ë§Œ ìƒíƒœê°€ ì—…ë°ì´íŠ¸ ì•ˆëœ ê²½ìš°)
    if pending_count > 0:
        st.sidebar.markdown("---")
        st.sidebar.warning("âš ï¸ ì¼ë¶€ íŒŒì¼ì˜ ì¬í•™ìŠµ ìƒíƒœê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        if st.sidebar.button("ğŸ”„ ì¬í•™ìŠµ ì™„ë£Œ ìƒíƒœë¡œ ì—…ë°ì´íŠ¸", 
                           use_container_width=True, 
                           type="secondary",
                           help="ëª¨ë“  íŒŒì¼ì„ ì¬í•™ìŠµ ì™„ë£Œ ìƒíƒœë¡œ ìˆ˜ë™ ì—…ë°ì´íŠ¸"):
            updated_count = mark_all_files_as_retrained()
            if updated_count > 0:
                st.sidebar.success(f"âœ… {updated_count}ê°œ íŒŒì¼ì´ ì™„ë£Œ ìƒíƒœë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!")
                safe_rerun()
            else:
                st.sidebar.error("âŒ íŒŒì¼ ì—…ë°ì´íŠ¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

# =========================== ê²½ë³´ ëŒ€ì‹œë³´ë“œ ===========================

def render_alert_dashboard():
    """ì§€ì§„ ê²½ë³´ ì „ìš© ëŒ€ì‹œë³´ë“œ"""
    alerts = get_earthquake_alerts()
    
    if not alerts:
        st.info("ğŸŸ¢ í˜„ì¬ ì§€ì§„ ê²½ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.")
        return
    
    st.subheader(f"ğŸš¨ ì§€ì§„ ê²½ë³´ í˜„í™© ({len(alerts)}ê±´)")
    
    # ìµœê·¼ ê²½ë³´ í•˜ì´ë¼ì´íŠ¸
    latest_alert = alerts[0]
    alert_time = datetime.fromisoformat(latest_alert['timestamp'])
    time_since = datetime.now() - alert_time
    
    if time_since.total_seconds() < 300:  # 5ë¶„ ì´ë‚´
        st.error(f"ğŸš¨ **ìµœì‹  ì§€ì§„ ê²½ë³´!** {time_since.seconds//60}ë¶„ {time_since.seconds%60}ì´ˆ ì „")
    
    # ê²½ë³´ ëª©ë¡
    for i, alert in enumerate(alerts[:5]):  # ìµœê·¼ 5ê°œë§Œ í‘œì‹œ
        with st.expander(f"ğŸš¨ ê²½ë³´ #{i+1} - {alert.get('event_time', 'Unknown')}"):
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.write(f"**ê²½ë³´ ì‹œê°„:** {alert.get('timestamp', 'Unknown')}")
                st.write(f"**ì´ë²¤íŠ¸ ì‹œê°„:** {alert.get('event_time', 'Unknown')}")
                st.write(f"**ì„¼ì„œ í¬íŠ¸:** {alert.get('port', 'Unknown')}")
                
            with col2:
                if 'ai_analysis' in alert:
                    ai_data = alert['ai_analysis']
                    st.write(f"**ì§€ì§„ í™•ë¥ :** {ai_data.get('earthquake_prob', 0)*100:.1f}%")
                    st.write(f"**ìµœì¢… ì‹ ë¢°ë„:** {ai_data.get('final_confidence', 0)*100:.1f}%")
                    st.write(f"**ë¶„ë¥˜:** {ai_data.get('final_class_name', 'Unknown')}")
                
            with col3:
                if 'model_info' in alert:
                    model_info = alert['model_info']
                    st.write(f"**ëª¨ë¸:** {model_info.get('name', 'Unknown')}")
                    st.write(f"**ëª¨ë¸ ì •í™•ë„:** {model_info.get('accuracy', 0)*100:.2f}%")
                
                st.write(f"**ì§„ë„:** {alert.get('intensity', 'Unknown')}")

# =========================== ë©”ì¸ ëŒ€ì‹œë³´ë“œ ===========================

def render_waveform_charts(file_info):
    """ì„ íƒëœ íŒŒì¼ì˜ 3ì¶• ê°€ì†ë„ íŒŒí˜• ì°¨íŠ¸ í‘œì‹œ"""
    try:
        df = pd.read_csv(file_info['filepath'])
        parsed_info = parse_filename_info(file_info['filename'])
        
        # ì„¼ì„œ ë°ì´í„° ì°¾ê¸°
        sensor_found = False
        sensor_patterns = [
            ('sensor_1_x', 'sensor_1_y', 'sensor_1_z'),
            ('x', 'y', 'z'),
            ('X', 'Y', 'Z'),
            ('acc_x', 'acc_y', 'acc_z')
        ]
        
        x_col = y_col = z_col = None
        
        for pattern in sensor_patterns:
            x_test, y_test, z_test = pattern
            if all(col in df.columns for col in [x_test, y_test, z_test]):
                x_col, y_col, z_col = x_test, y_test, z_test
                sensor_found = True
                break
        
        if sensor_found:
            # ë°ì´í„° ìƒ˜í”Œë§ (ì„±ëŠ¥ ìµœì í™”)
            data_length = len(df)
            if data_length > 4000:
                sample_step = max(1, data_length // 4000)
                sampled_data = df.iloc[::sample_step]
            else:
                sampled_data = df
            
            time_axis = range(len(sampled_data))
            
            # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
            x_data = pd.to_numeric(sampled_data[x_col], errors='coerce').fillna(0)
            y_data = pd.to_numeric(sampled_data[y_col], errors='coerce').fillna(0)
            z_data = pd.to_numeric(sampled_data[z_col], errors='coerce').fillna(0)
            
            # ê°€ì†ë„ í¬ê¸° ê³„ì‚°
            acceleration_magnitude = np.sqrt(x_data**2 + y_data**2 + z_data**2)
            
            # ì§„ë„ ë³€í™˜ (0.00~10.00 ë²”ìœ„)
            # ì´ë²¤íŠ¸ì˜ ì‹¤ì œ ì§„ë„ì™€ ë§ì¶”ì–´ ë™ì  ìŠ¤ì¼€ì¼ë§
            magnitude_data = np.zeros_like(acceleration_magnitude)
            
            # ì´ë²¤íŠ¸ì˜ ì‹¤ì œ ì§„ë„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            actual_intensity = 5.0  # ê¸°ë³¸ê°’
            try:
                if 'intensity' in df.columns:
                    actual_intensity = float(df['intensity'].iloc[0])
                elif hasattr(file_info, 'intensity'):
                    actual_intensity = float(file_info['intensity'])
            except:
                pass
            
            # ê°€ì†ë„ì˜ ìµœëŒ€ê°’ì— ë§ì¶° ì§„ë„ ìŠ¤ì¼€ì¼ë§
            max_acc = np.max(acceleration_magnitude) if len(acceleration_magnitude) > 0 else 1.0
            
            for i, acc_val in enumerate(acceleration_magnitude):
                if max_acc > 0:
                    # ì‹¤ì œ ì§„ë„ì— ë§ì¶° ì •ê·œí™”ëœ ì§„ë„ ê³„ì‚°
                    normalized_acc = acc_val / max_acc  # 0~1 ì •ê·œí™”
                    intensity = normalized_acc * actual_intensity  # ì‹¤ì œ ì§„ë„ë¡œ ìŠ¤ì¼€ì¼ë§
                    magnitude_data[i] = np.clip(intensity, 0.0, 15.0)
                else:
                    magnitude_data[i] = 0.0
            
            # ë¶„ì„ ê²°ê³¼ ì •ë³´
            analysis_info = ""
            if file_info['type'] == 'SYSTEM_ANALYSIS':
                if 'ai_class_name' in df.columns:
                    class_name = df['ai_class_name'].iloc[0]
                    analysis_info = f" | AI ë¶„ì„: {class_name}"
                elif 'predicted_class_name' in df.columns:
                    class_name = df['predicted_class_name'].iloc[0]
                    analysis_info = f" | AI ë¶„ì„: {class_name}"
            
            # ì§„ë„ ì •ë³´
            intensity_text = ""
            if 'intensity' in df.columns:
                try:
                    intensity = float(df['intensity'].iloc[0])
                    intensity_text = f" | ì§„ë„: {intensity:.2f}"
                except:
                    pass
            
            # íŒŒì¼ ì •ë³´ í‘œì‹œ
            time_diff = datetime.now() - file_info['modified_datetime']
            time_text = f"{int(time_diff.total_seconds())}ì´ˆ ì „" if time_diff.total_seconds() < 60 else f"{int(time_diff.total_seconds()//60)}ë¶„ ì „"
            
            st.info(f"ğŸ“Š **ì„ íƒëœ ì´ë²¤íŠ¸:** {parsed_info['location']} | **ë°ì´í„°:** {len(df):,}í–‰{analysis_info}{intensity_text} | **ì‹œê°„:** {time_text}")
            
            # 4ê°œ ì°¨íŠ¸ ìƒì„± (2x2 ë ˆì´ì•„ì›ƒ)
            col1, col2 = st.columns(2)
            
            with col1:
                # Xì¶• ì°¨íŠ¸
                fig_x = go.Figure()
                fig_x.add_trace(go.Scatter(
                    x=list(time_axis),
                    y=x_data.tolist(),
                    name='Xì¶•',
                    line=dict(color='#FF4B4B', width=2),
                    mode='lines'
                ))
                fig_x.update_layout(
                    title=f"ì„¼ì„œ - Xì¶• ê°€ì†ë„{intensity_text}",
                    xaxis_title="ì‹œê°„ (ìƒ˜í”Œ)",
                    yaxis_title="ê°€ì†ë„",
                    height=300,
                    margin=dict(t=60, b=40, l=60, r=40),
                    xaxis=dict(range=[0, 4000])
                )
                st.plotly_chart(fig_x, use_container_width=True)
                
                # Zì¶• ì°¨íŠ¸
                fig_z = go.Figure()
                fig_z.add_trace(go.Scatter(
                    x=list(time_axis),
                    y=z_data.tolist(),
                    name='Zì¶•',
                    line=dict(color='#1E88E5', width=2),
                    mode='lines'
                ))
                fig_z.update_layout(
                    title="ì„¼ì„œ - Zì¶• ê°€ì†ë„",
                    xaxis_title="ì‹œê°„ (ìƒ˜í”Œ)",
                    yaxis_title="ê°€ì†ë„",
                    height=300,
                    margin=dict(t=60, b=40, l=60, r=40),
                    xaxis=dict(range=[0, 4000])
                )
                st.plotly_chart(fig_z, use_container_width=True)
            
            with col2:
                # Yì¶• ì°¨íŠ¸
                fig_y = go.Figure()
                fig_y.add_trace(go.Scatter(
                    x=list(time_axis),
                    y=y_data.tolist(),
                    name='Yì¶•',
                    line=dict(color='#00D084', width=2),
                    mode='lines'
                ))
                fig_y.update_layout(
                    title="ì„¼ì„œ - Yì¶• ê°€ì†ë„",
                    xaxis_title="ì‹œê°„ (ìƒ˜í”Œ)",
                    yaxis_title="ê°€ì†ë„",
                    height=300,
                    margin=dict(t=60, b=40, l=60, r=40),
                    xaxis=dict(range=[0, 4000])
                )
                st.plotly_chart(fig_y, use_container_width=True)
                
                # ì§„ë„ ì°¨íŠ¸
                fig_mag = go.Figure()
                fig_mag.add_trace(go.Scatter(
                    x=list(time_axis),
                    y=magnitude_data.tolist(),
                    name='ì§„ë„',
                    line=dict(color='#9C27B0', width=2),
                    mode='lines'
                ))
                fig_mag.update_layout(
                    title="ì„¼ì„œ - ì§„ë„ (0.00~10.00)",
                    xaxis_title="ì‹œê°„ (ìƒ˜í”Œ)",
                    yaxis_title="ì§„ë„",
                    yaxis=dict(range=[0, 10]),  # Yì¶• ë²”ìœ„ 0~10 ê³ ì •
                    xaxis=dict(range=[0, 4000]),  # Xì¶• ë²”ìœ„ 0~4000 ê³ ì •
                    height=300,
                    margin=dict(t=60, b=40, l=60, r=40)
                )
                st.plotly_chart(fig_mag, use_container_width=True)
            
            return True
        else:
            # ì„¼ì„œ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°
            st.warning("ğŸ“Š í‘œì‹œí•  ì„¼ì„œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ì¹¼ëŸ¼ë“¤ ì¼ë¶€ í‘œì‹œ
            numeric_columns = [col for col in df.columns if df[col].dtype in ['int64', 'float64'] or col.lower() in ['x', 'y', 'z']]
            if numeric_columns:
                st.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ìˆ«ì ì¹¼ëŸ¼ë“¤: {', '.join(numeric_columns[:10])}")
            return False
            
    except Exception as e:
        st.error(f"âŒ íŒŒí˜• ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {str(e)}")
        return False

def render_system_dashboard():
    """ì§€ì§„ ì˜¤ë³´ ë¶„ì„ ì‹œìŠ¤í…œ ë©”ì¸ ëŒ€ì‹œë³´ë“œ"""
    st.title("ğŸŒ ì§€ì§„ ì˜¤ë³´ ë¶„ì„ ì‹œìŠ¤í…œ")
    st.markdown("### ConvLSTM ê¸°ë°˜ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§")
    
    # ìˆ˜ë™ ìƒˆë¡œê³ ì¹¨ ì•ˆë‚´
    st.info("ğŸ”„ ìƒˆë¡œìš´ ì´ë²¤íŠ¸ í™•ì¸ì„ ìœ„í•´ ì‚¬ì´ë“œë°”ì˜ **ìƒˆë¡œê³ ì¹¨** ë²„íŠ¼ì„ í´ë¦­í•´ì£¼ì„¸ìš”.")
    
    # ì¬í•™ìŠµ ì™„ë£Œ ì•Œë¦¼ ì²˜ë¦¬
    if st.session_state.get('retraining_success', False):
        result = st.session_state.get('retraining_result', {})
        st.success(f"ğŸ§  **AI ëª¨ë¸ ì¬í•™ìŠµ ì™„ë£Œ!** {result.get('message', '')}")
        if result.get('new_model_path'):
            model_name = os.path.basename(result['new_model_path'])
            performance = result.get('performance', {})
            # ì¬í•™ìŠµ ì™„ë£Œ ì •ë³´ëŠ” ì‚¬ì´ë“œë°”ì—ì„œë§Œ í‘œì‹œí•˜ë¯€ë¡œ ë©”ì¸ í™”ë©´ì—ì„œëŠ” ìˆ¨ê¹€
            # col_success1, col_success2 = st.columns(2)
            # with col_success1:
            #     st.info(f"ğŸ“ **ìƒˆ ëª¨ë¸:** {model_name}")
            # with col_success2:
            #     if performance:
            #         accuracy = performance.get('val_accuracy', 0)
            #         samples = performance.get('samples_count', 0)
            #         st.info(f"ğŸ“Š **ì„±ëŠ¥:** ì •í™•ë„ {accuracy:.1%}, ìƒ˜í”Œ {samples}ê°œ")
        
        # ì•Œë¦¼ í‘œì‹œ í›„ ì œê±°
        del st.session_state['retraining_success']
        if 'retraining_result' in st.session_state:
            del st.session_state['retraining_result']
    
    # ì¬í•™ìŠµ ì˜¤ë¥˜ ì•Œë¦¼ ì²˜ë¦¬
    if st.session_state.get('retraining_error'):
        st.error(f"âŒ **ì¬í•™ìŠµ ì‹¤íŒ¨:** {st.session_state['retraining_error']}")
        del st.session_state['retraining_error']
    
    # ì„ íƒëœ íŒŒì¼ ìƒíƒœ ì´ˆê¸°í™”
    if 'selected_file_for_waveform' not in st.session_state:
        st.session_state.selected_file_for_waveform = None
    
    # ê²½ë³´ ìƒíƒœ í‘œì‹œ
    alerts = get_earthquake_alerts()
    if alerts:
        latest_alert = alerts[0]
        alert_time = datetime.fromisoformat(latest_alert['timestamp'])
        time_since = datetime.now() - alert_time
        
        if time_since.total_seconds() < 600:  # 10ë¶„ ì´ë‚´
            st.error(f"ğŸš¨ **í™œì„± ì§€ì§„ ê²½ë³´** - {time_since.seconds//60}ë¶„ {time_since.seconds%60}ì´ˆ ì „ ë°œë ¹")
            render_alert_dashboard()
            st.markdown("---")
    
    # ì´ë²¤íŠ¸ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
    files = get_system_event_files()
    
    if not files:
        st.info("ğŸ“ ì•„ì§ ì €ì¥ëœ ì´ë²¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.info("influx_new2_realtime.pyê°€ ì‹¤í–‰ë˜ë©´ ìë™ìœ¼ë¡œ ë°ì´í„°ê°€ ìˆ˜ì§‘ë©ë‹ˆë‹¤.")
        
        # ë””ë²„ê¹… ì •ë³´ ì¶”ê°€
        with st.expander("ğŸ” ë””ë²„ê¹… ì •ë³´ (ê²½ë¡œ í™•ì¸)", expanded=False):
            import platform
            st.write(f"**ì‹¤í–‰ í™˜ê²½:** {platform.system()}")
            st.write(f"**í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬:** {os.getcwd()}")
            st.write(f"**ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜:** {os.path.dirname(os.path.abspath(__file__))}")
            st.write(f"**BASE_PATH:** {BASE_PATH}")
            st.write(f"**ANALYSIS_DIR:** {CONFIG['ANALYSIS_DIR']}")
            st.write(f"**ANALYSIS_DIR ì¡´ì¬:** {os.path.exists(CONFIG['ANALYSIS_DIR'])}")
            
            if os.path.exists(CONFIG['ANALYSIS_DIR']):
                analysis_files = [f for f in os.listdir(CONFIG['ANALYSIS_DIR']) if f.endswith('.csv')]
                st.write(f"**ë¶„ì„ ë””ë ‰í† ë¦¬ íŒŒì¼ ìˆ˜:** {len(analysis_files)}ê°œ")
                new2_files = [f for f in analysis_files if f.startswith('new2_ai_')]
                st.write(f"**new2_ai_ íŒŒì¼ ìˆ˜:** {len(new2_files)}ê°œ")
                if new2_files:
                    st.write("**new2_ai_ íŒŒì¼ë“¤:**")
                    for f in new2_files[:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                        st.write(f"  - {f}")
        
        # í´ë” ìƒíƒœ í™•ì¸
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.write("**ğŸ“‚ ì›ì‹œ ë°ì´í„°:**")
            if os.path.exists(CONFIG['RAW_DATA_DIR']):
                raw_files = [f for f in os.listdir(CONFIG['RAW_DATA_DIR']) if f.endswith('.csv')]
                st.write(f"âœ… {len(raw_files)}ê°œ íŒŒì¼")
            else:
                st.write("âŒ í´ë” ì—†ìŒ")
        
        with col2:
            st.write("**ğŸ§  ì§€ì§„ ì˜¤ë³´ ë¶„ì„:**")
            if os.path.exists(CONFIG['ANALYSIS_DIR']):
                system_files = [f for f in os.listdir(CONFIG['ANALYSIS_DIR']) if f.endswith('.csv')]
                st.write(f"âœ… {len(system_files)}ê°œ íŒŒì¼")
            else:
                st.write("âŒ í´ë” ì—†ìŒ")
        
        with col3:
            st.write("**ğŸš¨ ì§€ì§„ ê²½ë³´:**")
            if os.path.exists(CONFIG['ALERTS_DIR']):
                alert_files = [f for f in os.listdir(CONFIG['ALERTS_DIR']) if f.endswith('.json')]
                st.write(f"âœ… {len(alert_files)}ê°œ íŒŒì¼")
            else:
                st.write("âŒ í´ë” ì—†ìŒ")
        
        # ì´ë²¤íŠ¸ ê¸°ë°˜ ìë™ ìƒˆë¡œê³ ì¹¨
        if should_auto_refresh():
            st.cache_data.clear()
            safe_rerun()
        elif st.session_state.get('auto_refresh', True):
            # ë³€ê²½ì´ ì—†ìœ¼ë©´ ì§§ì€ ëŒ€ê¸° í›„ ë‹¤ì‹œ í™•ì¸
            time.sleep(2)
            safe_rerun()
        return
    
    # =================== ì„±ëŠ¥ í†µê³„ ì‚­ì œë¨ ==================="
    
    # í†µê³„ ê³„ì‚° - ì‚­ì œë¨
    # total_events = len(files)
#     new2_processed = len([f for f in files if f['type'] == 'NEW2_ANALYSIS'])
#     legacy_processed = len([f for f in files if f['type'] == 'LEGACY_AI'])
#     raw_only = len([f for f in files if f['type'] == 'RAW_DATA'])
#     
#     class_counts = {name: 0 for name in NEW2_CLASS_NAMES.values()}
#     earthquake_alerts = 0
#     total_confidence = 0
#     confidence_count = 0
#     
#     for file_info in files:
#         if file_info['type'] in ['NEW2_ANALYSIS', 'LEGACY_AI']:
#             try:
#                 df = pd.read_csv(file_info['filepath'])
#                 
#                 # NEW2 ê²°ê³¼ í™•ì¸
#                 if file_info['type'] == 'NEW2_ANALYSIS':
#                     if 'ai_predicted_class' in df.columns:
#                         pred_class = int(df['ai_predicted_class'].iloc[0])
#                         if pred_class in NEW2_CLASS_NAMES:
#                             class_counts[NEW2_CLASS_NAMES[pred_class]] += 1
#                         
#                         if 'ai_final_confidence' in df.columns:
#                             confidence = float(df['ai_final_confidence'].iloc[0])
#                             total_confidence += confidence
#                             confidence_count += 1
#                         
#                         if 'ai_is_earthquake' in df.columns:
#                             is_earthquake = df['ai_is_earthquake'].iloc[0]
#                             if str(is_earthquake).lower() == 'true':
#                                 earthquake_alerts += 1
#                 
#                 # ë ˆê±°ì‹œ ê²°ê³¼ í™•ì¸ (í˜¸í™˜ì„±)
#                 elif 'predicted_class' in df.columns:
#                     pred_class = int(df['predicted_class'].iloc[0])
#                     if pred_class in NEW2_CLASS_NAMES:
#                         class_counts[NEW2_CLASS_NAMES[pred_class]] += 1
#                     
#                     if pred_class == 0:  # ì§€ì§„
#                         earthquake_alerts += 1
#                         
#             except:
#                 continue
#     
#     # ì„±ëŠ¥ ì§€í‘œ í‘œì‹œ
#     col_perf1, col_perf2, col_perf3, col_perf4 = st.columns(4)
#     
#     with col_perf1:
#         st.metric(
#             label="ğŸ“Š ì´ ì´ë²¤íŠ¸",
#             value=f"{total_events:,}",
#             delta=f"NEW2: {new2_processed}"
#         )
#     
#     with col_perf2:
#         processing_rate = (new2_processed / total_events * 100) if total_events > 0 else 0
#         st.metric(
#             label="ğŸ§  NEW2 ì²˜ë¦¬ìœ¨",
#             value=f"{processing_rate:.1f}%",
#             delta=f"{new2_processed}/{total_events}"
#         )
#     
#     with col_perf3:
#         avg_confidence = (total_confidence / confidence_count * 100) if confidence_count > 0 else 0
#         st.metric(
#             label="ğŸ“ˆ í‰ê·  ì‹ ë¢°ë„",
#             value=f"{avg_confidence:.1f}%",
#             delta="NEW2 AI ë¶„ì„"
#         )
#     
#     with col_perf4:
#         alert_rate = (earthquake_alerts / (new2_processed + legacy_processed) * 100) if (new2_processed + legacy_processed) > 0 else 0
#         st.metric(
#             label="ğŸš¨ ì§€ì§„ ê²½ë³´ìœ¨",
#             value=f"{alert_rate:.1f}%",
#             delta=f"{earthquake_alerts}ê±´ ë°œë ¹"
#         )
#     
    # =================== í´ë˜ìŠ¤ ë¶„í¬ ì‹œê°í™” ===================
    
    # í´ë˜ìŠ¤ë³„ ì¹´ìš´íŠ¸ ê³„ì‚°
    class_counts = {'ì§€ì§„': 0, 'ê·œì¹™ì ì‚°ì—…ì§„ë™': 0, 'ë¶ˆê·œì¹™ìƒí™œì§„ë™': 0}
    processed_count = 0
    
    for file_info in files:
        if file_info['type'] in ['SYSTEM_ANALYSIS', 'LEGACY_AI']:
            try:
                df = pd.read_csv(file_info['filepath'])
                processed_count += 1
                
                # ì „ë¬¸ê°€ ìˆ˜ì •ì´ ìˆìœ¼ë©´ ìˆ˜ì •ëœ í´ë˜ìŠ¤ ì‚¬ìš©
                if 'expert_corrected' in df.columns and df['expert_corrected'].iloc[0]:
                    corrected_class_name = df['expert_corrected_class_name'].iloc[0]
                    if corrected_class_name in class_counts:
                        class_counts[corrected_class_name] += 1
                # ì•„ë‹ˆë©´ AI ë¶„ì„ ê²°ê³¼ ì‚¬ìš©
                elif 'ai_predicted_class' in df.columns:
                    # NEW2 ë¶„ì„ ê²°ê³¼: ìˆ˜ì¹˜ í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©
                    pred_class = int(float(df['ai_predicted_class'].iloc[0]))
                    if pred_class in SYSTEM_CLASS_NAMES:
                        class_counts[SYSTEM_CLASS_NAMES[pred_class]] += 1
                elif 'predicted_class_name' in df.columns:
                    # ê¸°ì¡´ processed ê²°ê³¼: í´ë˜ìŠ¤ëª…ì„ ì§ì ‘ ì‚¬ìš©
                    class_name = df['predicted_class_name'].iloc[0]
                    # ê¸°ì¡´ í´ë˜ìŠ¤ëª…ì„ ì‹ ê·œ ì²´ê³„ë¡œ ë§¤í•‘
                    if class_name == 'ì§€ì§„':
                        class_counts['ì§€ì§„'] += 1
                    elif class_name == 'ë¶ˆê·œì¹™ìƒí™œ' or class_name == 'ë¶ˆê·œì¹™ìƒí™œì§„ë™':
                        class_counts['ë¶ˆê·œì¹™ìƒí™œì§„ë™'] += 1
                    elif class_name == 'ëª¨í„°ì§„ë™' or class_name == 'ê·œì¹™ì ì‚°ì—…ì§„ë™':
                        class_counts['ê·œì¹™ì ì‚°ì—…ì§„ë™'] += 1
                elif 'ai_final_class' in df.columns:
                    pred_class = int(float(df['ai_final_class'].iloc[0]))
                    if pred_class in SYSTEM_CLASS_NAMES:
                        class_counts[SYSTEM_CLASS_NAMES[pred_class]] += 1
                elif 'predicted_class' in df.columns:
                    pred_class = int(float(df['predicted_class'].iloc[0]))
                    if pred_class in SYSTEM_CLASS_NAMES:
                        class_counts[SYSTEM_CLASS_NAMES[pred_class]] += 1
                        
            except:
                continue
    
    if processed_count > 0 and sum(class_counts.values()) > 0:
        st.markdown("### ğŸ“Š í´ë˜ìŠ¤ ë¶„í¬ ì‹œê°í™”")
        
        chart_col1, chart_col2 = st.columns(2)
        
        with chart_col1:
            # ë„ë„› ì°¨íŠ¸
            fig_donut = px.pie(
                values=list(class_counts.values()),
                names=list(class_counts.keys()),
                title="í´ë˜ìŠ¤ ë¶„í¬",
                color=list(class_counts.keys()),
                color_discrete_map={
                    'ì§€ì§„': SYSTEM_CLASS_COLOR_HEX[0],
                    'ê·œì¹™ì ì‚°ì—…ì§„ë™': SYSTEM_CLASS_COLOR_HEX[1], 
                    'ë¶ˆê·œì¹™ìƒí™œì§„ë™': SYSTEM_CLASS_COLOR_HEX[2]
                },
                hole=0.4
            )
            fig_donut.update_traces(textposition='inside', textinfo='percent+label')
            st.plotly_chart(fig_donut, use_container_width=True)
        
        with chart_col2:
            # ë§‰ëŒ€ ì°¨íŠ¸
            fig_bar = px.bar(
                x=list(class_counts.keys()),
                y=list(class_counts.values()),
                title="í´ë˜ìŠ¤ë³„ ì´ë²¤íŠ¸ ìˆ˜",
                color=list(class_counts.keys()),
                color_discrete_map={
                    'ì§€ì§„': SYSTEM_CLASS_COLOR_HEX[0],
                    'ê·œì¹™ì ì‚°ì—…ì§„ë™': SYSTEM_CLASS_COLOR_HEX[1],
                    'ë¶ˆê·œì¹™ìƒí™œì§„ë™': SYSTEM_CLASS_COLOR_HEX[2]
                }
            )
            fig_bar.update_layout(showlegend=False)
            st.plotly_chart(fig_bar, use_container_width=True)
    
    # =================== ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ëª¨ë‹ˆí„°ë§ ë° ì„¼ì„œ 3ì¶• ê°€ì†ë„ íŒŒí˜• ===================
    st.markdown("---")
    st.subheader("ğŸ“ˆ ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ëª¨ë‹ˆí„°ë§ ë° ì„¼ì„œ 3ì¶• ê°€ì†ë„ íŒŒí˜•")
    
    # ìµœê·¼ ì´ë²¤íŠ¸ ë¶„ì„ ë° íŒŒí˜• í‘œì‹œ
    if files:
        # ì„ íƒëœ íŒŒì¼ì´ ì—†ìœ¼ë©´ ìµœì‹  íŒŒì¼ ì„ íƒ
        if st.session_state.selected_file_for_waveform is None:
            st.session_state.selected_file_for_waveform = files[0]
        
        # í˜„ì¬ í‘œì‹œí•  íŒŒì¼ ê²°ì •
        display_file = st.session_state.selected_file_for_waveform
        
        try:
            df_display = pd.read_csv(display_file['filepath'])
            parsed_info = parse_filename_info(display_file['filename'])
            
            # íŒŒì¼ ì •ë³´ ìš”ì•½
            time_diff = datetime.now() - display_file['modified_datetime']
            time_text = f"{int(time_diff.total_seconds())}ì´ˆ ì „" if time_diff.total_seconds() < 60 else f"{int(time_diff.total_seconds()//60)}ë¶„ ì „"
            
            # ë¶„ì„ ê²°ê³¼ ì¶”ì¶œ
            analysis_result = "ì²˜ë¦¬ ëŒ€ê¸°"
            confidence_text = ""
            result_color = "info"
            
            if display_file['type'] == 'SYSTEM_ANALYSIS':
                # ì§€ì§„ ì˜¤ë³´ ë¶„ì„ ì‹œìŠ¤í…œ ê²°ê³¼
                possible_class_cols = ['ai_final_class', 'ai_predicted_class', 'predicted_class']
                possible_conf_cols = ['ai_final_confidence', 'ai_confidence', 'confidence']
                
                pred_class = None
                confidence = 0.0
                
                # í´ë˜ìŠ¤ ì°¾ê¸°
                for col in possible_class_cols:
                    if col in df_display.columns:
                        pred_class = int(df_display[col].iloc[0])
                        break
                
                # ì‹ ë¢°ë„ ì°¾ê¸°
                for col in possible_conf_cols:
                    if col in df_display.columns:
                        confidence = float(df_display[col].iloc[0])
                        break
                
                if pred_class is not None:
                    class_name = SYSTEM_CLASS_NAMES.get(pred_class, 'Unknown')
                    class_icon = SYSTEM_CLASS_COLORS.get(pred_class, 'âšª')
                    analysis_result = f"{class_icon} {class_name}"
                    confidence_text = f"ì‹ ë¢°ë„: {confidence:.1%}"
                    result_color = "error" if pred_class == 0 else "warning" if pred_class == 1 else "success"
            
            # íŒŒì¼ ì •ë³´ í‘œì‹œ (ì‹ ë¢°ë„ ì œê±°, ê°„ê²© ë„“ê²Œ)
            summary_text = f"**ì´ë²¤íŠ¸:** {parsed_info['location']}ã€€ã€€ã€€ã€€**ë°ì´í„°:** {len(df_display):,}í–‰ã€€ã€€ã€€ã€€**ë¶„ì„:** {analysis_result}ã€€ã€€ã€€ã€€**ë°œìƒì‹œê°„:** {parsed_info['datetime_str']}"
            
            if result_color == "error":
                st.error(summary_text)
            elif result_color == "warning":
                st.warning(summary_text)
            elif result_color == "success":
                st.success(summary_text)
            else:
                st.info(summary_text)
            
            # ì„¼ì„œ 3ì¶• ê°€ì†ë„ íŒŒí˜• í‘œì‹œ
            try:
                # ì„¼ì„œ ë°ì´í„° ì°¾ê¸°
                sensor_found = False
                sensor_patterns = [
                    ('sensor_1_x', 'sensor_1_y', 'sensor_1_z'),
                    ('x', 'y', 'z'),
                    ('X', 'Y', 'Z'),
                    ('acc_x', 'acc_y', 'acc_z')
                ]
                
                x_col = y_col = z_col = None
                
                for pattern in sensor_patterns:
                    x_test, y_test, z_test = pattern
                    if all(col in df_display.columns for col in [x_test, y_test, z_test]):
                        x_col, y_col, z_col = x_test, y_test, z_test
                        sensor_found = True
                        break
                
                if sensor_found:
                    # ë°ì´í„° ìƒ˜í”Œë§ (ì„±ëŠ¥ ìµœì í™”)
                    data_length = len(df_display)
                    if data_length > 4000:
                        sample_step = max(1, data_length // 4000)
                        sampled_data = df_display.iloc[::sample_step]
                    else:
                        sampled_data = df_display
                    
                    time_axis = range(len(sampled_data))
                    
                    # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
                    x_data = pd.to_numeric(sampled_data[x_col], errors='coerce').fillna(0)
                    y_data = pd.to_numeric(sampled_data[y_col], errors='coerce').fillna(0)
                    z_data = pd.to_numeric(sampled_data[z_col], errors='coerce').fillna(0)
                    
                    # Magnitude ê³„ì‚°
                    # ê°€ì†ë„ í¬ê¸° ê³„ì‚°
                    acceleration_magnitude = np.sqrt(x_data**2 + y_data**2 + z_data**2)
                    
                    # ì§„ë„ ë³€í™˜ (0.00~10.00 ë²”ìœ„)
                    # ì´ë²¤íŠ¸ì˜ ì‹¤ì œ ì§„ë„ì™€ ë§ì¶”ì–´ ë™ì  ìŠ¤ì¼€ì¼ë§
                    magnitude_data = np.zeros_like(acceleration_magnitude)
                    
                    # ì´ë²¤íŠ¸ì˜ ì‹¤ì œ ì§„ë„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    actual_intensity = 5.0  # ê¸°ë³¸ê°’
                    try:
                        if 'intensity' in df_display.columns:
                            actual_intensity = float(df_display['intensity'].iloc[0])
                    except:
                        pass
                    
                    # ê°€ì†ë„ì˜ ìµœëŒ€ê°’ì— ë§ì¶° ì§„ë„ ìŠ¤ì¼€ì¼ë§
                    max_acc = np.max(acceleration_magnitude) if len(acceleration_magnitude) > 0 else 1.0
                    
                    for i, acc_val in enumerate(acceleration_magnitude):
                        if max_acc > 0:
                            # ì‹¤ì œ ì§„ë„ì— ë§ì¶° ì •ê·œí™”ëœ ì§„ë„ ê³„ì‚°
                            normalized_acc = acc_val / max_acc  # 0~1 ì •ê·œí™”
                            intensity = normalized_acc * actual_intensity  # ì‹¤ì œ ì§„ë„ë¡œ ìŠ¤ì¼€ì¼ë§
                            magnitude_data[i] = np.clip(intensity, 0.0, 10.0)
                        else:
                            magnitude_data[i] = 0.0
                    
                    # ì§„ë„ ì •ë³´
                    intensity_text = ""
                    if 'intensity' in df_display.columns:
                        try:
                            intensity = float(df_display['intensity'].iloc[0])
                            intensity_text = f" | ì§„ë„: {intensity:.2f}"
                        except:
                            pass
                    
                    # 4ê°œ ì°¨íŠ¸ ìƒì„± (2x2 ë ˆì´ì•„ì›ƒ)
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # Xì¶• ì°¨íŠ¸
                        fig_x = go.Figure()
                        fig_x.add_trace(go.Scatter(
                            x=list(time_axis),
                            y=x_data.tolist(),
                            name='Xì¶•',
                            line=dict(color='#FF4B4B', width=2),
                            mode='lines'
                        ))
                        fig_x.update_layout(
                            title=f"ì„¼ì„œ - Xì¶• ê°€ì†ë„{intensity_text}",
                            xaxis_title="ì‹œê°„ (ìƒ˜í”Œ)",
                            yaxis_title="ê°€ì†ë„",
                            height=300,
                            margin=dict(t=60, b=40, l=60, r=40),
                            xaxis=dict(range=[0, 4000])
                        )
                        st.plotly_chart(fig_x, use_container_width=True)
                        
                        # Zì¶• ì°¨íŠ¸
                        fig_z = go.Figure()
                        fig_z.add_trace(go.Scatter(
                            x=list(time_axis),
                            y=z_data.tolist(),
                            name='Zì¶•',
                            line=dict(color='#1E88E5', width=2),
                            mode='lines'
                        ))
                        fig_z.update_layout(
                            title="ì„¼ì„œ - Zì¶• ê°€ì†ë„",
                            xaxis_title="ì‹œê°„ (ìƒ˜í”Œ)",
                            yaxis_title="ê°€ì†ë„",
                            height=300,
                            margin=dict(t=60, b=40, l=60, r=40),
                            xaxis=dict(range=[0, 4000])
                        )
                        st.plotly_chart(fig_z, use_container_width=True)
                    
                    with col2:
                        # Yì¶• ì°¨íŠ¸
                        fig_y = go.Figure()
                        fig_y.add_trace(go.Scatter(
                            x=list(time_axis),
                            y=y_data.tolist(),
                            name='Yì¶•',
                            line=dict(color='#00D084', width=2),
                            mode='lines'
                        ))
                        fig_y.update_layout(
                            title="ì„¼ì„œ - Yì¶• ê°€ì†ë„",
                            xaxis_title="ì‹œê°„ (ìƒ˜í”Œ)",
                            yaxis_title="ê°€ì†ë„",
                            height=300,
                            margin=dict(t=60, b=40, l=60, r=40),
                            xaxis=dict(range=[0, 4000])
                        )
                        st.plotly_chart(fig_y, use_container_width=True)
                        
                        # ì§„ë„ ì°¨íŠ¸
                        fig_mag = go.Figure()
                        fig_mag.add_trace(go.Scatter(
                            x=list(time_axis),
                            y=magnitude_data.tolist(),
                            name='ì§„ë„',
                            line=dict(color='#9C27B0', width=2),
                            mode='lines'
                        ))
                        fig_mag.update_layout(
                            title="ì„¼ì„œ - ì§„ë„ (0.00~10.00)",
                            xaxis_title="ì‹œê°„ (ìƒ˜í”Œ)",
                            yaxis_title="ì§„ë„",
                            yaxis=dict(range=[0, 10]),  # Yì¶• ë²”ìœ„ 0~10 ê³ ì •
                            xaxis=dict(range=[0, 4000]),  # Xì¶• ë²”ìœ„ 0~4000 ê³ ì •
                            height=300,
                            margin=dict(t=60, b=40, l=60, r=40)
                        )
                        st.plotly_chart(fig_mag, use_container_width=True)
                else:
                    st.warning("ğŸ“Š í‘œì‹œí•  ì„¼ì„œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        
            except Exception as sensor_error:
                st.error(f"ì„¼ì„œ íŒŒí˜• í‘œì‹œ ì˜¤ë¥˜: {sensor_error}")
        
        except Exception as e:
            st.error(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        
        # =================== ì´ë²¤íŠ¸ ëª©ë¡ (í…Œì´ë¸” í˜•íƒœ + í˜ì´ì§€ë„¤ì´ì…˜) ===================
        st.markdown("---")
        st.subheader("ğŸ“‹ ìµœê·¼ ì´ë²¤íŠ¸ ëª©ë¡")
        
        # í˜ì´ì§€ë„¤ì´ì…˜ ì„¤ì •
        if 'page_number' not in st.session_state:
            st.session_state.page_number = 0
        
        items_per_page = st.selectbox("í˜ì´ì§€ë‹¹ í‘œì‹œ ê°œìˆ˜", [10, 20, 50, 100], index=0)
        total_pages = max(1, (len(files) + items_per_page - 1) // items_per_page)
        
        # í˜„ì¬ í˜ì´ì§€ ë°ì´í„° ì¶”ì¶œ
        start_idx = st.session_state.page_number * items_per_page
        end_idx = min(start_idx + items_per_page, len(files))
        current_page_files = files[start_idx:end_idx]
        
        
        # í…Œì´ë¸” ë°ì´í„° ì¤€ë¹„
        table_data = []
        
        for i, file_info in enumerate(current_page_files):
            try:
                df = pd.read_csv(file_info['filepath'])
                parsed_info = parse_filename_info(file_info['filename'])
                
                # ì´ë²¤íŠ¸ íƒ€ì…ë³„ ì•„ì´ì½˜
                type_icons = {
                    'SYSTEM_ANALYSIS': 'ğŸ§  ì‹œìŠ¤í…œ',
                    'LEGACY_AI': 'ğŸ”„ Legacy', 
                    'RAW_DATA': 'ğŸ“ Raw'
                }
                
                # ë¶„ì„ ê²°ê³¼ í™•ì¸ (íŒŒì¼ì˜ ì „ë¬¸ê°€ ìˆ˜ì • ìš°ì„  ì ìš©)
                analysis_result = "â³ ì²˜ë¦¬ ëŒ€ê¸°"
                confidence_value = 0.0
                is_earthquake = False
                is_expert_corrected = False
                
                # ì „ë¬¸ê°€ ìˆ˜ì • ì—¬ë¶€ í™•ì¸ (íŒŒì¼ ê¸°ë°˜)
                if 'expert_corrected' in df.columns and df['expert_corrected'].iloc[0]:
                    try:
                        corrected_class = int(df['expert_corrected_class'].iloc[0])
                        corrected_class_name = df['expert_corrected_class_name'].iloc[0]
                        
                        class_icon = SYSTEM_CLASS_COLORS.get(corrected_class, 'âšª')
                        analysis_result = f"{class_icon} {corrected_class_name} âœï¸"  # ìˆ˜ì • í‘œì‹œ
                        is_earthquake = (corrected_class == 0)
                        is_expert_corrected = True
                        confidence_value = 1.0  # ì „ë¬¸ê°€ ìˆ˜ì •ì€ 100% ì‹ ë¢°ë„
                    except:
                        pass
                
                # ì „ë¬¸ê°€ ìˆ˜ì •ì´ ì—†ìœ¼ë©´ ê¸°ì¡´ AI ë¶„ì„ ê²°ê³¼ ì‚¬ìš©
                if not is_expert_corrected and file_info['type'] == 'SYSTEM_ANALYSIS':
                    # ì§€ì§„ ì˜¤ë³´ ë¶„ì„ ì‹œìŠ¤í…œ ê²°ê³¼ í™•ì¸ (ë‹¤ì–‘í•œ ì¹¼ëŸ¼ëª… ì§€ì›)
                    possible_class_cols = ['ai_final_class', 'ai_predicted_class', 'predicted_class']
                    possible_conf_cols = ['ai_final_confidence', 'ai_confidence', 'confidence']
                    possible_name_cols = ['ai_final_class_name', 'ai_class_name', 'class_name']
                    
                    pred_class = None
                    confidence_value = 0.0
                    class_name = "Unknown"
                    
                    # í´ë˜ìŠ¤ ì°¾ê¸°
                    for col in possible_class_cols:
                        if col in df.columns:
                            pred_class = int(df[col].iloc[0])
                            break
                    
                    # ì‹ ë¢°ë„ ì°¾ê¸°
                    for col in possible_conf_cols:
                        if col in df.columns:
                            confidence_value = float(df[col].iloc[0])
                            break
                    
                    # í´ë˜ìŠ¤ëª… ì°¾ê¸°
                    for col in possible_name_cols:
                        if col in df.columns:
                            class_name = df[col].iloc[0]
                            break
                    
                    if pred_class is not None:
                        if class_name == "Unknown" and pred_class in SYSTEM_CLASS_NAMES:
                            class_name = SYSTEM_CLASS_NAMES[pred_class]
                        
                        class_icon = SYSTEM_CLASS_COLORS.get(pred_class, 'âšª')
                        analysis_result = f"{class_icon} {class_name}"
                        is_earthquake = (pred_class == 0)
                    
                elif file_info['type'] == 'LEGACY_AI' and 'predicted_class' in df.columns:
                    pred_class = int(df['predicted_class'].iloc[0])
                    class_name = SYSTEM_CLASS_NAMES.get(pred_class, 'Unknown')
                    analysis_result = f"ğŸ”„ {class_name}"
                    is_earthquake = (pred_class == 0)
                    if 'confidence' in df.columns:
                        confidence_value = float(df['confidence'].iloc[0])
                
                # ì‹œê°„ ì •ë³´
                time_diff = datetime.now() - file_info['modified_datetime']
                if time_diff.total_seconds() < 60:
                    time_text = f"{int(time_diff.total_seconds())}ì´ˆ ì „"
                elif time_diff.total_seconds() < 3600:
                    time_text = f"{int(time_diff.total_seconds()//60)}ë¶„ ì „"
                else:
                    time_text = f"{int(time_diff.total_seconds()//3600)}ì‹œê°„ ì „"
                
                # íŒŒì¼ í¬ê¸°
                try:
                    file_size_kb = os.path.getsize(file_info['filepath']) / 1024
                    size_text = f"{file_size_kb:.1f}KB"
                except:
                    size_text = "Unknown"
                
                # ì§„ë„ (intensity) ì •ë³´ ì¶”ì¶œ - influx_new2_realtime.pyì—ì„œ ì €ì¥ëœ ê°’ ì‚¬ìš©
                magnitude_text = "-"
                try:
                    # 1ìˆœìœ„: influx_new2_realtime.pyì—ì„œ ì €ì¥í•œ intensity ê°’ (íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ)
                    if 'intensity' in df.columns:
                        intensity = float(df['intensity'].iloc[0])
                        magnitude_text = f"{intensity:.2f}"
                    else:
                        # 2ìˆœìœ„: íŒŒì¼ëª…ì—ì„œ intensity íŒŒì‹± ì‹œë„ (event_í¬íŠ¸_ì‹œê°„.csv í˜•íƒœì¼ ê²½ìš° ì›ë³¸ ë°ì´í„°ì—ì„œ)
                        # influx_new2_realtime.pyì˜ event_info['intensity'] ê°’ ì°¾ê¸°
                        possible_intensity_cols = ['intensity', 'magnitude', 'mag']
                        for col in possible_intensity_cols:
                            if col in df.columns:
                                intensity = float(df[col].iloc[0])
                                # 0~10 ë²”ìœ„ë¡œ ì •ê·œí™” (InfluxDB intensity ê°’)
                                if intensity > 100:  # ì„¼ì„œ ì›ì‹œê°’ì¸ ê²½ìš°
                                    intensity = min(10.0, intensity / 100.0)  # ìŠ¤ì¼€ì¼ ì¡°ì •
                                magnitude_text = f"{intensity:.2f}"
                                break
                        
                        # 3ìˆœìœ„: ì„¼ì„œ ë°ì´í„°ê°€ ìˆë‹¤ë©´ ì¶”ì •ê°’ ê³„ì‚° (í•˜ì§€ë§Œ ë§¤ìš° ë‚®ì€ ê°’ìœ¼ë¡œ)
                        if magnitude_text == "-":
                            max_values = []
                            for sensor_num in range(1, 4):
                                for axis in ['x', 'y', 'z']:
                                    col_name = f'sensor_{sensor_num}_{axis}'
                                    if col_name in df.columns:
                                        max_val = abs(df[col_name]).max()
                                        max_values.append(max_val)
                            
                            if max_values:
                                raw_max = max(max_values)
                                # ì„¼ì„œ ì›ì‹œê°’ì„ 0~10 ì§„ë„ ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜ (ì¶”ì •)
                                estimated_intensity = min(10.0, raw_max / 1000.0)  # ë§¤ìš° ë³´ìˆ˜ì  ìŠ¤ì¼€ì¼ë§
                                magnitude_text = f"{estimated_intensity:.2f}"
                except Exception as e:
                    magnitude_text = "-"
                    print(f"ì§„ë„ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
                
                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í‚¤ ìƒì„±
                filename = file_info['filename']
                download_key = f"download_{start_idx + i + 1}_{filename}"
                
                # í…Œì´ë¸” í–‰ ë°ì´í„° ì¶”ê°€ (ë°œìƒì‹œê°„ìˆœ ë²ˆí˜¸)
                table_data.append({
                    'ë²ˆí˜¸': start_idx + i + 1,
                    'ì„¼ì„œìœ„ì¹˜': parsed_info['location'],
                    'ì§„ë„': magnitude_text,
                    'ë¶„ì„ê²°ê³¼': analysis_result,
                    'ì‹ ë¢°ë„': f"{confidence_value:.1%}" if confidence_value > 0 else "-" if not is_expert_corrected else "100% âœï¸",
                    'ë°œìƒì‹œê°„': parsed_info['datetime_str'],
                    'ê²½ê³¼ì‹œê°„': time_text,
                    'ë‹¤ìš´ë¡œë“œ': "ë‹¤ìš´ë¡œë“œ",  # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                    '_filepath': file_info['filepath'],  # ë‹¤ìš´ë¡œë“œìš© ìˆ¨ê¹€ í•„ë“œ
                    '_download_key': download_key,  # ë²„íŠ¼ í‚¤
                    '_filename': filename  # íŒŒì¼ëª…
                })
            
            except Exception as e:
                # ì˜¤ë¥˜ ë°œìƒì‹œì—ë„ ê¸°ë³¸ ì •ë³´ëŠ” í‘œì‹œ
                parsed_info = parse_filename_info(file_info['filename'])
                filename = file_info['filename']
                download_key = f"download_{start_idx + i + 1}_{filename}"
                table_data.append({
                    'ë²ˆí˜¸': start_idx + i + 1,
                    'ì„¼ì„œìœ„ì¹˜': parsed_info['location'],
                    'ì§„ë„': "-",
                    'ë¶„ì„ê²°ê³¼': f"âŒ ì˜¤ë¥˜: {str(e)[:30]}",
                    'ì‹ ë¢°ë„': "-",
                    'ë°œìƒì‹œê°„': parsed_info['datetime_str'],
                    'ê²½ê³¼ì‹œê°„': "-",
                    'ë‹¤ìš´ë¡œë“œ': "ë‹¤ìš´ë¡œë“œ",
                    '_filepath': file_info['filepath'],
                    '_download_key': download_key,
                    '_filename': filename
                })
        
        # í…Œì´ë¸” í‘œì‹œ
        if table_data:
            # ë””ë²„ê¹…: ì²« ë²ˆì§¸ í–‰ì˜ í‚¤ í™•ì¸
            try:
                if len(table_data) > 0:
                    first_row_keys = list(table_data[0].keys())
                    print(f"í…Œì´ë¸” ë°ì´í„° í‚¤ë“¤: {first_row_keys}")
            except Exception as e:
                print(f"ë””ë²„ê¹… ì˜¤ë¥˜: {e}")
            
            df_table = pd.DataFrame(table_data)
            
            # í…Œì´ë¸” ë°ì´í„°ì™€ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì„ í•¨ê»˜ í‘œì‹œ
            # ê° í–‰ì„ ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í¬í•¨
            
            # í…Œì´ë¸” í—¤ë”
            col_header = st.columns([0.6, 1.2, 0.8, 1.8, 1.8, 0.8, 1.0, 0.8, 0.8, 1.0])
            headers = ['ë²ˆí˜¸', 'ì„¼ì„œìœ„ì¹˜', 'ì§„ë„', 'ë°œìƒì‹œê°„', 'ë¶„ì„ê²°ê³¼', 'ì¬í•™ìŠµ', 'íŒŒí˜•ë³´ê¸°', 'ìˆ˜ì •', 'ì‚­ì œ', 'ë‹¤ìš´ë¡œë“œ']
            
            for i, header in enumerate(headers):
                with col_header[i]:
                    st.markdown(f"<div style='text-align: center;'><b>{header}</b></div>", unsafe_allow_html=True)
            
            # í—¤ë”ì™€ ë°ì´í„° ì‚¬ì´ ê°„ê²© ìµœì†Œí™”
            st.markdown("<hr style='margin: 2px 0; opacity: 0.3;'>", unsafe_allow_html=True)
            
            # í…Œì´ë¸” ë²„íŠ¼ ìŠ¤íƒ€ì¼ ìµœì í™”
            st.markdown("""
                <style>
                .stButton > button {
                    width: 100%;
                    height: 32px;
                    font-size: 11px;
                    padding: 3px 6px;
                    margin: 1px 0;
                }
                div[data-testid="column"] {
                    padding: 0px 2px;
                }
                </style>
            """, unsafe_allow_html=True)
            
            # ê° ë°ì´í„° í–‰ í‘œì‹œ
            for idx, row in df_table.iterrows():
                col_data = st.columns([0.6, 1.2, 0.8, 1.8, 1.8, 0.8, 1.0, 0.8, 0.8, 1.0])
                
                # íŒŒì¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                file_info = current_page_files[idx]
                filename = file_info['filename']
                
                # ì¬í•™ìŠµ ìƒíƒœ í™•ì¸
                retraining_status = get_retraining_status_for_file(file_info['filepath'])
                
                # ë°ì´í„° ì¹¼ëŸ¼ë“¤
                data_values = [
                    str(row['ë²ˆí˜¸']),
                    row['ì„¼ì„œìœ„ì¹˜'], 
                    row['ì§„ë„'],
                    row['ë°œìƒì‹œê°„'],
                    row['ë¶„ì„ê²°ê³¼'],
                    retraining_status
                ]
                
                # ë°ì´í„° í‘œì‹œ (ì¤‘ì•™ ì •ë ¬, ê°„ê²© ìµœì†Œí™”)
                for i, value in enumerate(data_values):
                    with col_data[i]:
                        if i == 5:  # ì¬í•™ìŠµ ìƒíƒœ ì¹¼ëŸ¼
                            if value == "ì™„ë£Œ":
                                st.markdown(f"<div style='text-align: center; margin: 0; padding: 2px 0; color: green; font-weight: bold;'>âœ… {value}</div>", unsafe_allow_html=True)
                            else:
                                st.markdown(f"<div style='text-align: center; margin: 0; padding: 2px 0; color: orange; font-weight: bold;'>â³ {value}</div>", unsafe_allow_html=True)
                        else:
                            st.markdown(f"<div style='text-align: center; margin: 0; padding: 2px 0;'>{value}</div>", unsafe_allow_html=True)
                
                # íŒŒí˜• ë³´ê¸° ë²„íŠ¼ (6ë²ˆì§¸ ì»¬ëŸ¼)
                with col_data[6]:
                    waveform_key = f"waveform_{start_idx + idx + 1}_{row['_filename']}"
                    
                    # íŒŒí˜• ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
                    try:
                        df_check = pd.read_csv(row['_filepath'])
                        sensor_patterns = [
                            ('sensor_1_x', 'sensor_1_y', 'sensor_1_z'),
                            ('x', 'y', 'z'),
                            ('X', 'Y', 'Z'),
                            ('acc_x', 'acc_y', 'acc_z')
                        ]
                        
                        has_sensor_data = False
                        for pattern in sensor_patterns:
                            if all(col in df_check.columns for col in pattern):
                                has_sensor_data = True
                                break
                        
                        if has_sensor_data:
                            # í˜„ì¬ ì„ íƒëœ íŒŒì¼ì¸ì§€ í™•ì¸
                            is_selected = (st.session_state.selected_file_for_waveform and 
                                         st.session_state.selected_file_for_waveform['filepath'] == row['_filepath'])
                            
                            button_text = "ğŸ“Š ë³´ëŠ” ì¤‘" if is_selected else "ğŸ“Š íŒŒí˜•"
                            button_type = "secondary" if is_selected else "primary"
                            
                            if st.button(button_text, key=waveform_key, use_container_width=True, 
                                       type=button_type, help="ìœ„ íŒŒí˜• ì„¹ì…˜ì—ì„œ 3ì¶• ê°€ì†ë„ íŒŒí˜• ë³´ê¸°"):
                                # ì„ íƒëœ íŒŒì¼ ì •ë³´ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                                current_file_info = {
                                    'filename': row['_filename'],
                                    'filepath': row['_filepath'],
                                    'modified_datetime': current_page_files[idx]['modified_datetime'],
                                    'type': current_page_files[idx]['type']
                                }
                                st.session_state.selected_file_for_waveform = current_file_info
                                
                                # íŒŒí˜• ì„¹ì…˜ìœ¼ë¡œ ìë™ ìŠ¤í¬ë¡¤
                                safe_rerun()
                        else:
                            st.button("ì„¼ì„œì—†ìŒ", disabled=True, key=f"no_sensor_{waveform_key}", 
                                    use_container_width=True, help="3ì¶• ê°€ì†ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                            
                    except Exception as e:
                        st.button("ì˜¤ë¥˜", disabled=True, key=f"error_wave_{waveform_key}", 
                                use_container_width=True, help=f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)[:30]}")
                
                # ìˆ˜ì • ë²„íŠ¼ (7ë²ˆì§¸ ì»¬ëŸ¼)
                with col_data[7]:
                    modify_key = f"modify_{start_idx + idx + 1}_{row['_filename']}"
                    
                    # AI ë¶„ì„ëœ ê²°ê³¼ë§Œ ìˆ˜ì • ê°€ëŠ¥ (ğŸ”´ğŸŸ ğŸŸ¢ ì´ëª¨ì§€ ë˜ëŠ” ğŸ”„ ì´ëª¨ì§€ê°€ ìˆëŠ” ê²½ìš°)
                    analysis_text = row['ë¶„ì„ê²°ê³¼']
                    has_ai_analysis = any(emoji in analysis_text for emoji in ['ğŸ”´', 'ğŸŸ ', 'ğŸŸ¢', 'ğŸ”„'])
                    is_processing_wait = 'â³' in analysis_text or 'ì²˜ë¦¬ ëŒ€ê¸°' in analysis_text
                    is_error = 'âŒ' in analysis_text or 'ì˜¤ë¥˜' in analysis_text
                    
                    if has_ai_analysis and not is_processing_wait and not is_error:  
                        if st.button("âœï¸ ìˆ˜ì •", key=modify_key, use_container_width=True, help="ë¶„ì„ ê²°ê³¼ ìˆ˜ì •"):
                            st.session_state[f'show_modify_modal_{idx}'] = True
                            st.session_state[f'modify_file_info_{idx}'] = {
                                'filepath': row['_filepath'],
                                'filename': row['_filename'],
                                'current_result': row['ë¶„ì„ê²°ê³¼'],
                                'current_confidence': row['ì‹ ë¢°ë„']
                            }
                            safe_rerun()
                    else:
                        reason = "ì²˜ë¦¬ ëŒ€ê¸° ì¤‘" if is_processing_wait else "ì˜¤ë¥˜ ë°œìƒ" if is_error else "ë¶„ì„ ë¯¸ì™„ë£Œ"
                        st.button("ìˆ˜ì •ë¶ˆê°€", disabled=True, key=f"disabled_modify_{modify_key}", use_container_width=True, help=f"{reason} - ìˆ˜ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                
                # ì‚­ì œ ë²„íŠ¼ (8ë²ˆì§¸ ì»¬ëŸ¼)
                with col_data[8]:
                    delete_key = f"delete_{start_idx + idx + 1}_{row['_filename']}"
                    
                    if st.button("ğŸ—‘ï¸ ì‚­ì œ", key=delete_key, use_container_width=True, type="secondary", help="íŒŒì¼ì„ ì™„ì „íˆ ì‚­ì œí•©ë‹ˆë‹¤"):
                        st.session_state[f'show_delete_modal_{idx}'] = True
                        st.session_state[f'delete_file_info_{idx}'] = {
                            'filepath': row['_filepath'],
                            'filename': row['_filename'],
                            'location': row['ì„¼ì„œìœ„ì¹˜'],
                            'analysis_result': row['ë¶„ì„ê²°ê³¼']
                        }
                        safe_rerun()
                
                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (9ë²ˆì§¸ ì»¬ëŸ¼)
                with col_data[9]:
                    filepath = row['_filepath']
                    filename = row['_filename']
                    
                    try:
                        if os.path.exists(filepath):
                            with open(filepath, 'rb') as file:
                                file_data = file.read()
                            
                            st.download_button(
                                label="ë‹¤ìš´ë¡œë“œ",
                                data=file_data,
                                file_name=filename,
                                mime="text/csv",
                                key=row['_download_key'],
                                use_container_width=True
                            )
                        else:
                            st.button("íŒŒì¼ì—†ìŒ", disabled=True, key=f"disabled_{row['_download_key']}", use_container_width=True)
                    except Exception as e:
                        st.button("ì˜¤ë¥˜", disabled=True, key=f"error_{row['_download_key']}", use_container_width=True)
                
                # í–‰ ê°„ê²© ìµœì†Œí™”
                st.markdown("<div style='margin: 3px 0;'></div>", unsafe_allow_html=True)
            
            # ì „ì²´ ZIP ë‹¤ìš´ë¡œë“œ
            st.markdown("### ğŸ“¦ ì „ì²´ íŒŒì¼ ë‹¤ìš´ë¡œë“œ")
            # st.write("ğŸ” **ë””ë²„ê·¸**: ì´ ì„¹ì…˜ì€ í•œ ë²ˆë§Œ í‘œì‹œë˜ì–´ì•¼ í•©ë‹ˆë‹¤")
            if len(df_table) > 1:
                try:
                    import zipfile
                    import io
                    
                    # ZIP íŒŒì¼ ìƒì„±
                    zip_buffer = io.BytesIO()
                    zip_file_count = 0
                    
                    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                        for _, row in df_table.iterrows():
                            filepath = row['_filepath']
                            if os.path.exists(filepath):
                                zip_file.write(filepath, row['ë‹¤ìš´ë¡œë“œ'])
                                zip_file_count += 1
                    
                    zip_buffer.seek(0)
                    
                    if zip_file_count > 0:
                        st.download_button(
                            label=f"ğŸ“¦ í˜„ì¬ í˜ì´ì§€ ì „ì²´ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ({zip_file_count}ê°œ)",
                            data=zip_buffer.getvalue(),
                            file_name=f"earthquake_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
                            mime="application/zip",
                            use_container_width=True
                        )
                    else:
                        st.warning("ë‹¤ìš´ë¡œë“œí•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                        
                except Exception as e:
                    st.error(f"âŒ ZIP ìƒì„± ì˜¤ë¥˜: {e}")
            
            
            # í˜ì´ì§€ ë„¤ë¹„ê²Œì´ì…˜ (í…Œì´ë¸” ì•„ë˜)
            st.markdown("---")
            col_nav1, col_nav2, col_nav3, col_nav4, col_nav5 = st.columns([1, 1, 2, 1, 1])
            
            with col_nav1:
                if st.button("âª ì²« í˜ì´ì§€", key="nav_first") and st.session_state.page_number > 0:
                    st.session_state.page_number = 0
                    safe_rerun()
            
            with col_nav2:
                if st.button("â—€ ì´ì „", key="nav_prev") and st.session_state.page_number > 0:
                    st.session_state.page_number -= 1
                    safe_rerun()
            
            with col_nav3:
                st.markdown(f"<div style='text-align: center; padding: 8px;'><b>{st.session_state.page_number + 1} / {total_pages} í˜ì´ì§€</b></div>", unsafe_allow_html=True)
            
            with col_nav4:
                if st.button("ë‹¤ìŒ â–¶", key="nav_next") and st.session_state.page_number < total_pages - 1:
                    st.session_state.page_number += 1
                    safe_rerun()
            
            with col_nav5:
                if st.button("ë§ˆì§€ë§‰ í˜ì´ì§€ â©", key="nav_last") and st.session_state.page_number < total_pages - 1:
                    st.session_state.page_number = total_pages - 1
                    safe_rerun()
            
            # =================== ìˆ˜ì • íŒì—… ì²˜ë¦¬ ===================
            # ìˆ˜ì • í™•ì¸ì€ ì‚¬ì´ë“œë°”ì—ì„œ ì²˜ë¦¬ë˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ì•ˆë‚´ë§Œ í‘œì‹œ
            modify_modal_shown = False
            for idx in range(len(df_table)):
                modal_key = f'show_modify_modal_{idx}'
                if st.session_state.get(modal_key, False):
                    modify_modal_shown = True
                    break
            
            # ìˆ˜ì • ëª¨ë‹¬ì´ í™œì„±í™”ë˜ë©´ ì•ˆë‚´ ë©”ì‹œì§€ë§Œ í‘œì‹œ
            if modify_modal_shown:
                st.info("âœï¸ **ë¶„ì„ ê²°ê³¼ ìˆ˜ì •ì°½ì´ ì™¼ìª½ ì‚¬ì´ë“œë°”ì— í‘œì‹œë˜ì—ˆìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”!**")
            
            # =================== ì‚­ì œ í™•ì¸ íŒì—… ì²˜ë¦¬ ===================
            # ì‚­ì œ í™•ì¸ì€ ì‚¬ì´ë“œë°”ì—ì„œ ì²˜ë¦¬ë˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ì•ˆë‚´ë§Œ í‘œì‹œ
            delete_modal_shown = False
            for idx in range(len(df_table)):
                delete_modal_key = f'show_delete_modal_{idx}'
                if st.session_state.get(delete_modal_key, False):
                    delete_modal_shown = True
                    break
            
            # ì‚­ì œ ëª¨ë‹¬ì´ í™œì„±í™”ë˜ë©´ ì•ˆë‚´ ë©”ì‹œì§€ë§Œ í‘œì‹œ
            if delete_modal_shown:
                st.info("ğŸ” **ì‚­ì œ í™•ì¸ì°½ì´ ì™¼ìª½ ì‚¬ì´ë“œë°”ì— í‘œì‹œë˜ì—ˆìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”!**")
            
            # ìˆ˜ì • ì™„ë£Œ ë©”ì‹œì§€ í‘œì‹œ
            for idx in range(len(df_table)):
                success_key = f'correction_success_{idx}'
                if st.session_state.get(success_key):
                    st.success(st.session_state[success_key])
                    # ë©”ì‹œì§€ í‘œì‹œ í›„ ì œê±°
                    del st.session_state[success_key]
            
            # ì‚­ì œ ì™„ë£Œ ë©”ì‹œì§€ í‘œì‹œ
            for idx in range(len(df_table)):
                delete_success_key = f'delete_success_{idx}'
                if st.session_state.get(delete_success_key):
                    st.success(st.session_state[delete_success_key])
                    # ë©”ì‹œì§€ í‘œì‹œ í›„ ì œê±°
                    del st.session_state[delete_success_key]
        
        else:
            st.warning("í‘œì‹œí•  ì´ë²¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    else:
        st.warning("ğŸ” ì²˜ë¦¬ëœ ì´ë²¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘...")
    

# =========================== ë©”ì¸ ì‹¤í–‰ ===========================

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ìºì‹œ í´ë¦¬ì–´ (KeyError ë°©ì§€)
    try:
        st.cache_data.clear()
    except:
        pass
    
    # ê¸°ë³¸ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'initialized' not in st.session_state:
        st.session_state.initialized = True
    
    # ì§€ì§„ ì˜¤ë³´ ë¶„ì„ ì‹œìŠ¤í…œ ëª¨ë¸ ë¡œë”©
    if 'model' not in st.session_state:
        model, model_name = load_new2_model()
        st.session_state.model = model
        st.session_state.model_name = model_name
        st.session_state.model_loaded = model is not None
    
    # UI ë Œë”ë§
    render_system_sidebar()
    render_system_dashboard()

if __name__ == "__main__":
    main()