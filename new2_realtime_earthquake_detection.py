#!/usr/bin/env python3
"""
NEW2 ConvLSTM 3í´ë˜ìŠ¤ ëª¨ë¸ì„ í™œìš©í•œ ì‹¤ì‹œê°„ ì§€ì§„ ì¡°ê¸°ê²½ë³´ ì‹œìŠ¤í…œ
98.46% ì •í™•ë„ ëª¨ë¸ ê¸°ë°˜ ì˜¤ê²½ë³´ ì €ê° ì‹œìŠ¤í…œ
"""

import time
from datetime import datetime, timedelta
import requests
from influxdb_client import InfluxDBClient
from urllib.parse import quote
import os
import csv
import pandas as pd
import numpy as np
import json
import warnings
warnings.filterwarnings('ignore')

# í™˜ê²½ ì„¤ì •
os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# TensorFlow ì•ˆì „í•œ ë¡œë”©
def safe_load_tensorflow():
    """TensorFlowë¥¼ ì•ˆì „í•˜ê²Œ ë¡œë”©"""
    try:
        import tensorflow as tf
        tf.get_logger().setLevel('ERROR')
        from tensorflow.keras.models import load_model
        print(f"âœ… TensorFlow ë²„ì „: {tf.__version__}")
        return tf, load_model, True
    except Exception as e:
        print(f"âŒ TensorFlow ë¡œë”© ì‹¤íŒ¨: {e}")
        return None, None, False

# TensorFlow ë¡œë”©
tf, load_model, tf_available = safe_load_tensorflow()

# =========================== ì‹œìŠ¤í…œ ì„¤ì • ===========================

# NEW2 ConvLSTM 3í´ë˜ìŠ¤ ëª¨ë¸ ì„¤ì •
MODEL_CONFIG = {
    'model_path': 'new2_convlstm_3class_best.h5',  # NEW2 ìµœê³  ì„±ëŠ¥ ëª¨ë¸
    'backup_path': 'new2_convlstm_3class_final.h5',  # ë°±ì—… ëª¨ë¸
    'input_shape': (1, 40, 3, 100, 1),  # NEW2 ëª¨ë¸ ì…ë ¥ í˜•íƒœ
    'accuracy': 0.9846,  # 98.46% ì •í™•ë„
    'classes': {0: 'ì§€ì§„', 1: 'ê·œì¹™ì ì‚°ì—…ì§„ë™', 2: 'ë¶ˆê·œì¹™ìƒí™œì§„ë™'}
}

# ë””ë ‰í† ë¦¬ ì„¤ì •
DIRS = {
    'base': "C:/earthquake_modeling/earthquake_project_v3/influxLogs",
    'raw': "C:/earthquake_modeling/earthquake_project_v3/influxLogs/base",
    'processed': "C:/earthquake_modeling/earthquake_project_v3/influxLogs/processed",
    'alerts': "C:/earthquake_modeling/earthquake_project_v3/influxLogs/alerts"
}

# ë””ë ‰í† ë¦¬ ìƒì„±
for dir_path in DIRS.values():
    os.makedirs(dir_path, exist_ok=True)

# InfluxDB ì„¤ì •
INFLUX_CONFIG = {
    'token': "ZyegXlVhIdA26zFakbWjgVX863_pAtfXJPfsLGlA0wtfTxl7BHZJlMNLT5HHudXk58VzVScGnugA36w_buC4Zg==",
    'org': "kds",
    'bucket': "Lasung_3sensor of Max",
    'url': "http://118.129.145.82:8086",
    'ports': [6060, 7001, 7053, 7060, 7070, 8010, 8080]
}

# Node-RED ì„¤ì •
NODERED_CONFIG = {
    'base_url': "http://118.129.145.82:8081/nodered/1min_event_lasung",
    'timeout': 30
}

# ì¡°ê¸°ê²½ë³´ ì‹œìŠ¤í…œ ì„¤ì • (98.46% ëª¨ë¸ ì„±ëŠ¥ ê¸°ë°˜)
ALERT_CONFIG = {
    'earthquake_threshold': 0.92,  # ì§€ì§„ ì‹ ë¢°ë„ ì„ê³„ê°’ (92%)
    'confidence_gap_min': 0.25,   # ë‹¤ë¥¸ í´ë˜ìŠ¤ì™€ ìµœì†Œ ì‹ ë¢°ë„ ì°¨ì´ (25%)
    'enable_advanced_filter': True,  # ê³ ê¸‰ í•„í„°ë§ í™œì„±í™”
    'enable_multi_check': True,      # ë‹¤ì¤‘ ê²€ì¦ í™œì„±í™”
    'alert_cooldown': 60            # ê²½ë³´ ê°„ ìµœì†Œ ê°„ê²© (ì´ˆ)
}

# ì§„ë™ íŠ¹ì„± ë¶„ì„ ì„ê³„ê°’ (NEW2 ë°ì´í„° ê¸°ë°˜ ìµœì í™”)
VIBRATION_THRESHOLDS = {
    'min_duration_ratio': 0.20,     # ìµœì†Œ ì§„ë™ ì§€ì† ë¹„ìœ¨ (20%)
    'max_frequency': 15.0,          # ìµœëŒ€ í—ˆìš© ì£¼íŒŒìˆ˜ (15Hz)
    'max_energy_imbalance': 0.70,   # ìµœëŒ€ ì—ë„ˆì§€ ë¶ˆê· í˜• (70%)
    'max_change_rate': 12.0,        # ìµœëŒ€ ë³€í™”ìœ¨
    'min_amplitude': 1.5,           # ìµœì†Œ ì§„í­
    'low_freq_dominance_min': 0.35  # ì €ì£¼íŒŒ ìš°ì„¸ì„± ìµœì†Œê°’ (35%)
}

# ì‹œê°ì  í‘œì‹œ
CLASS_DISPLAY = {
    0: {'name': 'ì§€ì§„', 'color': 'ğŸ”´', 'alert': True},
    1: {'name': 'ê·œì¹™ì ì‚°ì—…ì§„ë™', 'color': 'ğŸŸ ', 'alert': False},
    2: {'name': 'ë¶ˆê·œì¹™ìƒí™œì§„ë™', 'color': 'ğŸŸ¢', 'alert': False}
}

# =========================== ëª¨ë¸ ë¡œë”© ===========================

convlstm_model = None
if tf_available:
    print("ğŸ”„ NEW2 ConvLSTM 3í´ë˜ìŠ¤ ëª¨ë¸ ë¡œë”© ì¤‘...")
    try:
        # ë©”ì¸ ëª¨ë¸ ì‹œë„
        if os.path.exists(MODEL_CONFIG['model_path']):
            convlstm_model = load_model(MODEL_CONFIG['model_path'])
            print(f"âœ… ë©”ì¸ ëª¨ë¸ ë¡œë”© ì™„ë£Œ: {MODEL_CONFIG['model_path']}")
        # ë°±ì—… ëª¨ë¸ ì‹œë„
        elif os.path.exists(MODEL_CONFIG['backup_path']):
            convlstm_model = load_model(MODEL_CONFIG['backup_path'])
            print(f"âœ… ë°±ì—… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: {MODEL_CONFIG['backup_path']}")
        else:
            print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:")
            print(f"   ë©”ì¸: {MODEL_CONFIG['model_path']}")
            print(f"   ë°±ì—…: {MODEL_CONFIG['backup_path']}")
            
        if convlstm_model:
            print(f"ğŸ¯ ëª¨ë¸ ì •í™•ë„: {MODEL_CONFIG['accuracy']*100:.2f}%")
            print(f"ğŸ“Š ì…ë ¥ í˜•íƒœ: {convlstm_model.input_shape}")
            print(f"ğŸ“Š ì¶œë ¥ í˜•íƒœ: {convlstm_model.output_shape}")
            
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        convlstm_model = None

# InfluxDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = InfluxDBClient(
    url=INFLUX_CONFIG['url'], 
    token=INFLUX_CONFIG['token'], 
    org=INFLUX_CONFIG['org']
)
query_api = client.query_api()

# =========================== ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜ ===========================

def find_trigger_point_new2(data, threshold=3.0, min_ratio=0.15):
    """NEW2 ë°ì´í„°ì— ìµœì í™”ëœ íŠ¸ë¦¬ê±° í¬ì¸íŠ¸ íƒì§€"""
    # 3ì¶• í•©ì„± ì§„ë„ ê³„ì‚°
    magnitude = np.sqrt(np.sum(data**2, axis=1))
    
    # ë™ì  ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ íŠ¸ë¦¬ê±° íƒì§€
    window_sizes = [100, 150, 200]  # 1ì´ˆ, 1.5ì´ˆ, 2ì´ˆ ìœˆë„ìš°
    
    for window_size in window_sizes:
        for i in range(0, len(magnitude) - window_size, 50):
            window = magnitude[i:i+window_size]
            high_intensity_count = np.sum(window >= threshold)
            
            if high_intensity_count >= (window_size * min_ratio):
                trigger_point = i + window_size // 2
                print(f"ğŸ¯ íŠ¸ë¦¬ê±° ë°œê²¬: {trigger_point}ë²ˆì§¸ ìƒ˜í”Œ (ìœˆë„ìš°: {window_size})")
                return trigger_point
    
    return None

def analyze_vibration_characteristics_new2(raw_data):
    """NEW2 ë°ì´í„°ì— ìµœì í™”ëœ ì§„ë™ íŠ¹ì„± ë¶„ì„"""
    try:
        x_data, y_data, z_data = raw_data[:, 0], raw_data[:, 1], raw_data[:, 2]
        magnitude = np.sqrt(x_data**2 + y_data**2 + z_data**2)
        
        # 1. ì§„ë™ ì§€ì†ì„± ë¶„ì„ (ê°œì„ ëœ ì„ê³„ê°’ ì ìš©)
        high_intensity_mask = magnitude >= 2.5  # ë‚®ì€ ì„ê³„ê°’ìœ¼ë¡œ ë” ë¯¼ê°í•˜ê²Œ
        duration_ratio = np.sum(high_intensity_mask) / len(magnitude)
        
        # 2. ì£¼íŒŒìˆ˜ ë¶„ì„ (FFT)
        fft = np.fft.fft(magnitude)
        freqs = np.fft.fftfreq(len(magnitude), d=0.01)
        power_spectrum = np.abs(fft)**2
        
        # ì£¼íŒŒìˆ˜ë³„ ì—ë„ˆì§€ ë¶„í¬
        low_freq_mask = (freqs >= 0.1) & (freqs <= 5.0)    # ì§€ì§„ ëŒ€ì—­ (0.1-5Hz)
        mid_freq_mask = (freqs > 5.0) & (freqs <= 15.0)    # ì‚°ì—… ëŒ€ì—­ (5-15Hz)
        high_freq_mask = (freqs > 15.0) & (freqs <= 50.0)  # ìƒí™œ ëŒ€ì—­ (15-50Hz)
        
        total_energy = np.sum(power_spectrum[freqs >= 0])
        if total_energy > 0:
            low_freq_energy_ratio = np.sum(power_spectrum[low_freq_mask]) / total_energy
            mid_freq_energy_ratio = np.sum(power_spectrum[mid_freq_mask]) / total_energy
            high_freq_energy_ratio = np.sum(power_spectrum[high_freq_mask]) / total_energy
        else:
            low_freq_energy_ratio = mid_freq_energy_ratio = high_freq_energy_ratio = 0.33
        
        # ì£¼ìš” ì£¼íŒŒìˆ˜ ì°¾ê¸°
        dominant_freq_idx = np.argmax(power_spectrum[1:len(power_spectrum)//2]) + 1
        dominant_freq = abs(freqs[dominant_freq_idx])
        
        # 3. ì¶•ê°„ ì—ë„ˆì§€ ë¶„í¬ ë¶„ì„
        x_energy = np.sum(x_data**2)
        y_energy = np.sum(y_data**2)
        z_energy = np.sum(z_data**2)
        total_axis_energy = x_energy + y_energy + z_energy
        
        if total_axis_energy > 0:
            energy_balance = max(x_energy, y_energy, z_energy) / total_axis_energy
        else:
            energy_balance = 0.33
        
        # 4. ë³€í™”ìœ¨ ë¶„ì„ (ì¶©ê²©ì„± ì§„ë™ ê°ì§€)
        x_diff = np.diff(x_data)
        y_diff = np.diff(y_data)
        z_diff = np.diff(z_data)
        max_change_rate = max(np.max(np.abs(x_diff)), np.max(np.abs(y_diff)), np.max(np.abs(z_diff)))
        
        # 5. ì‹ í˜¸ ë³µì¡ë„ ë¶„ì„
        x_autocorr = np.correlate(x_data, x_data, mode='full')
        if len(x_autocorr) > 200:
            autocorr_peak = np.max(x_autocorr[len(x_autocorr)//2+100:]) / np.max(x_autocorr)
        else:
            autocorr_peak = 0.5
        
        # 6. ì§„ë™ ê°•ë„ í†µê³„
        amplitude_stats = {
            'max': np.max(magnitude),
            'mean': np.mean(magnitude),
            'std': np.std(magnitude),
            'percentile_95': np.percentile(magnitude, 95),
            'percentile_75': np.percentile(magnitude, 75)
        }
        
        # 7. ì§€ì§„ íŠ¹ì„± ì ìˆ˜ ê³„ì‚° (0-1 ìŠ¤ì¼€ì¼)
        earthquake_score = 0.0
        
        # ì €ì£¼íŒŒ ìš°ì„¸ì„± (ì§€ì§„ì˜ íŠ¹ì§•)
        if low_freq_energy_ratio > 0.4:
            earthquake_score += 0.3
        elif low_freq_energy_ratio > 0.3:
            earthquake_score += 0.15
            
        # ì ì ˆí•œ ì§€ì†ì„± (ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸¸ì§€ ì•ŠìŒ)
        if 0.2 <= duration_ratio <= 0.8:
            earthquake_score += 0.2
        elif 0.15 <= duration_ratio <= 0.9:
            earthquake_score += 0.1
            
        # ê· ë“±í•œ ì¶• ë¶„í¬ (ì§€ì§„ì˜ íŠ¹ì§•)
        if energy_balance < 0.6:
            earthquake_score += 0.2
        elif energy_balance < 0.7:
            earthquake_score += 0.1
            
        # ì ì ˆí•œ ì£¼íŒŒìˆ˜ ë²”ìœ„
        if 0.5 <= dominant_freq <= 10.0:
            earthquake_score += 0.2
        elif 0.1 <= dominant_freq <= 15.0:
            earthquake_score += 0.1
            
        # ì ì ˆí•œ ë³€í™”ìœ¨ (ë„ˆë¬´ ê¸‰ê²©í•˜ì§€ ì•ŠìŒ)
        if max_change_rate < 8.0:
            earthquake_score += 0.1
        
        characteristics = {
            'duration_ratio': duration_ratio,
            'dominant_frequency': dominant_freq,
            'energy_balance': energy_balance,
            'max_change_rate': max_change_rate,
            'autocorr_peak': autocorr_peak,
            'amplitude_max': amplitude_stats['max'],
            'amplitude_mean': amplitude_stats['mean'],
            'amplitude_std': amplitude_stats['std'],
            'low_freq_dominance': low_freq_energy_ratio,
            'mid_freq_dominance': mid_freq_energy_ratio,
            'high_freq_dominance': high_freq_energy_ratio,
            'earthquake_score': earthquake_score,
            'x_energy_ratio': x_energy / total_axis_energy if total_axis_energy > 0 else 0.33,
            'y_energy_ratio': y_energy / total_axis_energy if total_axis_energy > 0 else 0.33,
            'z_energy_ratio': z_energy / total_axis_energy if total_axis_energy > 0 else 0.33
        }
        
        return characteristics
        
    except Exception as e:
        print(f"âŒ ì§„ë™ íŠ¹ì„± ë¶„ì„ ì‹¤íŒ¨: {e}")
        return None

def preprocess_for_new2_convlstm(csv_path):
    """NEW2 ConvLSTM ëª¨ë¸ì— ìµœì í™”ëœ ì „ì²˜ë¦¬"""
    try:
        df = pd.read_csv(csv_path)
        print(f"ğŸ“Š ì›ë³¸ ë°ì´í„° ë¡œë“œ: {len(df)}í–‰")
        
        # ì„¼ì„œ ë°ì´í„° ì¶”ì¶œ (sensor_1 ìš°ì„ )
        sensor_cols = None
        for i in range(1, 4):
            x_col, y_col, z_col = f'sensor_{i}_x', f'sensor_{i}_y', f'sensor_{i}_z'
            if all(col in df.columns for col in [x_col, y_col, z_col]):
                sensor_cols = [x_col, y_col, z_col]
                print(f"ğŸ“¡ ì‚¬ìš© ì„¼ì„œ: sensor_{i}")
                break
        
        if not sensor_cols:
            return None, None, "ì„¼ì„œ ë°ì´í„° ì—†ìŒ"
        
        # 3ì¶• ë°ì´í„° ì¶”ì¶œ
        x_data = df[sensor_cols[0]].astype(float).values
        y_data = df[sensor_cols[1]].astype(float).values
        z_data = df[sensor_cols[2]].astype(float).values
        
        raw_data = np.stack([x_data, y_data, z_data], axis=1)
        print(f"ğŸ“Š 3ì¶• ë°ì´í„° ê²°í•©: {raw_data.shape}")
        
        # ì§„ë™ íŠ¹ì„± ë¶„ì„
        characteristics = analyze_vibration_characteristics_new2(raw_data)
        
        # NEW2 ìµœì í™”ëœ íŠ¸ë¦¬ê±° í¬ì¸íŠ¸ íƒì§€
        trigger_idx = find_trigger_point_new2(raw_data)
        if trigger_idx is None:
            print("âš ï¸ íŠ¸ë¦¬ê±° í¬ì¸íŠ¸ ì—†ìŒ - ìµœëŒ€ ì§„í­ ì§€ì  ì‚¬ìš©")
            magnitude = np.sqrt(np.sum(raw_data**2, axis=1))
            trigger_idx = np.argmax(magnitude)
        
        # NEW2 ëª¨ë¸ í˜•ì‹ì— ë§ì¶° 40ì´ˆ ìŠ¬ë¼ì´ì‹±
        PRE_SAMPLES = 1500   # ì „ 15ì´ˆ
        POST_SAMPLES = 2500  # í›„ 25ì´ˆ
        TOTAL_SAMPLES = 4000 # ì´ 40ì´ˆ
        
        start_idx = max(0, trigger_idx - PRE_SAMPLES)
        end_idx = min(len(raw_data), trigger_idx + POST_SAMPLES)
        
        # ë°ì´í„° ì¶”ì¶œ ë° íŒ¨ë”©/íŠ¸ë¦¼
        if end_idx - start_idx >= TOTAL_SAMPLES:
            sliced_data = raw_data[start_idx:start_idx + TOTAL_SAMPLES]
        else:
            available_data = raw_data[start_idx:end_idx]
            pad_length = TOTAL_SAMPLES - len(available_data)
            
            if pad_length > 0:
                # ì•ìª½ì— íŒ¨ë”© (ë°°ê²½ ë…¸ì´ì¦ˆ ì‹œë®¬ë ˆì´ì…˜)
                noise_std = np.std(available_data) * 0.1
                front_pad = np.random.normal(0, noise_std, (pad_length//2, 3))
                back_pad = np.random.normal(0, noise_std, (pad_length - pad_length//2, 3))
                sliced_data = np.vstack([front_pad, available_data, back_pad])
            else:
                sliced_data = available_data
        
        # ì •í™•íˆ 4000 ìƒ˜í”Œë¡œ ë§ì¶”ê¸°
        if len(sliced_data) != TOTAL_SAMPLES:
            if len(sliced_data) > TOTAL_SAMPLES:
                sliced_data = sliced_data[:TOTAL_SAMPLES]
            else:
                pad_length = TOTAL_SAMPLES - len(sliced_data)
                padding = np.zeros((pad_length, 3))
                sliced_data = np.vstack([sliced_data, padding])
        
        print(f"âœ… 40ì´ˆ ìŠ¬ë¼ì´ì‹± ì™„ë£Œ: {sliced_data.shape}")
        
        # NEW2 ConvLSTM ì…ë ¥ í˜•íƒœë¡œ ë³€í™˜
        # (4000, 3) -> (40, 100, 3) -> (40, 3, 100) -> (40, 3, 100, 1) -> (1, 40, 3, 100, 1)
        reshaped = sliced_data.reshape(40, 100, 3)
        reshaped = np.transpose(reshaped, (0, 2, 1))  # (40, 3, 100)
        reshaped = np.expand_dims(reshaped, axis=-1)  # (40, 3, 100, 1)
        reshaped = np.expand_dims(reshaped, axis=0)   # (1, 40, 3, 100, 1)
        
        # NEW2 ëª¨ë¸ì— ë§ëŠ” ì •ê·œí™” (z-score)
        mean = reshaped.mean()
        std = reshaped.std()
        
        if std > 0:
            normalized = (reshaped - mean) / std
            print(f"ğŸ“ ì •ê·œí™” ì™„ë£Œ: í‰ê· ={mean:.6f}, í‘œì¤€í¸ì°¨={std:.6f}")
        else:
            normalized = reshaped
            print("âš ï¸ í‘œì¤€í¸ì°¨ê°€ 0ì´ë¯€ë¡œ ì •ê·œí™” ê±´ë„ˆëœ€")
        
        preprocess_info = {
            'original_length': len(raw_data),
            'trigger_point': trigger_idx,
            'slicing_range': (start_idx, end_idx),
            'final_shape': normalized.shape,
            'normalization': {'mean': float(mean), 'std': float(std)},
            'used_sensor': sensor_cols[0].split('_')[1],
            'characteristics': characteristics
        }
        
        return normalized, df, preprocess_info
        
    except Exception as e:
        print(f"âŒ NEW2 ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None, None, str(e)

# =========================== ì¡°ê¸°ê²½ë³´ ë¡œì§ ===========================

def advanced_earthquake_detection_new2(predictions, characteristics):
    """NEW2 ëª¨ë¸ ê¸°ë°˜ ê³ ë„í™”ëœ ì§€ì§„ ê°ì§€ ë¡œì§"""
    
    # ê¸°ë³¸ ì˜ˆì¸¡ ê²°ê³¼
    predicted_class = int(np.argmax(predictions[0]))
    confidence = float(predictions[0][predicted_class])
    all_probs = predictions[0]
    
    # í´ë˜ìŠ¤ë³„ ì‹ ë¢°ë„
    earthquake_prob = all_probs[0]
    industrial_prob = all_probs[1]
    living_prob = all_probs[2]
    
    detection_info = {
        'original_class': predicted_class,
        'original_confidence': confidence,
        'earthquake_prob': earthquake_prob,
        'industrial_prob': industrial_prob,
        'living_prob': living_prob,
        'filters_applied': [],
        'pass_reasons': [],
        'suppression_reasons': []
    }
    
    print(f"\\nğŸ§  === NEW2 ëª¨ë¸ ì˜ˆì¸¡ ë¶„ì„ ===")
    print(f"   ğŸ”´ ì§€ì§„: {earthquake_prob:.4f} ({earthquake_prob*100:.2f}%)")
    print(f"   ğŸŸ  ê·œì¹™ì ì‚°ì—…ì§„ë™: {industrial_prob:.4f} ({industrial_prob*100:.2f}%)")
    print(f"   ğŸŸ¢ ë¶ˆê·œì¹™ìƒí™œì§„ë™: {living_prob:.4f} ({living_prob*100:.2f}%)")
    print(f"   ğŸ¯ ìµœê³  ì˜ˆì¸¡: {MODEL_CONFIG['classes'][predicted_class]} (ì‹ ë¢°ë„: {confidence:.4f})")
    
    # 1ë‹¨ê³„: ì§€ì§„ ì˜ˆì¸¡ì´ ì•„ë‹Œ ê²½ìš° ë°”ë¡œ í†µê³¼
    if predicted_class != 0:
        detection_info['final_class'] = predicted_class
        detection_info['final_confidence'] = confidence
        detection_info['is_earthquake'] = False
        detection_info['alert_status'] = 'NO_ALERT'
        detection_info['reason'] = f"ë¹„ì§€ì§„ ì˜ˆì¸¡: {MODEL_CONFIG['classes'][predicted_class]}"
        return detection_info
    
    # 2ë‹¨ê³„: ì§€ì§„ìœ¼ë¡œ ì˜ˆì¸¡ëœ ê²½ìš° ë‹¤ì¤‘ ê²€ì¦ ì‹œì‘
    print(f"\\nğŸ” === ì§€ì§„ ì˜ˆì¸¡ ë‹¤ì¤‘ ê²€ì¦ ì‹œì‘ ===")
    
    # 2-1: ì‹ ë¢°ë„ ì„ê³„ê°’ ê²€ì‚¬
    if earthquake_prob < ALERT_CONFIG['earthquake_threshold']:
        detection_info['suppression_reasons'].append(
            f"ì§€ì§„ ì‹ ë¢°ë„ ë¶€ì¡±: {earthquake_prob:.3f} < {ALERT_CONFIG['earthquake_threshold']}"
        )
        detection_info['filters_applied'].append('confidence_threshold')
        print(f"ğŸ›¡ï¸ ì‹ ë¢°ë„ í•„í„°: {detection_info['suppression_reasons'][-1]}")
        
        # ê°€ì¥ ë†’ì€ ë‹¤ë¥¸ í´ë˜ìŠ¤ë¡œ ì¬ë¶„ë¥˜
        other_probs = [industrial_prob, living_prob]
        other_classes = [1, 2]
        max_other_idx = np.argmax(other_probs)
        final_class = other_classes[max_other_idx]
        
        detection_info['final_class'] = final_class
        detection_info['final_confidence'] = other_probs[max_other_idx]
        detection_info['is_earthquake'] = False
        detection_info['alert_status'] = 'FALSE_POSITIVE_SUPPRESSED'
        detection_info['reason'] = f"ì˜¤ê²½ë³´ ì–µì œ: {detection_info['suppression_reasons'][-1]}"
        return detection_info
    
    detection_info['pass_reasons'].append(f"ë†’ì€ ì§€ì§„ ì‹ ë¢°ë„: {earthquake_prob:.3f}")
    
    # 2-2: ì‹ ë¢°ë„ ì°¨ì´ ê²€ì‚¬
    max_other_prob = max(industrial_prob, living_prob)
    confidence_gap = earthquake_prob - max_other_prob
    
    if confidence_gap < ALERT_CONFIG['confidence_gap_min']:
        detection_info['suppression_reasons'].append(
            f"ì‹ ë¢°ë„ ì°¨ì´ ë¶€ì¡±: {confidence_gap:.3f} < {ALERT_CONFIG['confidence_gap_min']}"
        )
        detection_info['filters_applied'].append('confidence_gap')
        print(f"ğŸ›¡ï¸ ì‹ ë¢°ë„ ì°¨ì´ í•„í„°: {detection_info['suppression_reasons'][-1]}")
        
        # ë‘ ë²ˆì§¸ë¡œ ë†’ì€ í´ë˜ìŠ¤ë¡œ ì¬ë¶„ë¥˜
        if industrial_prob > living_prob:
            final_class = 1
            final_confidence = industrial_prob
        else:
            final_class = 2
            final_confidence = living_prob
            
        detection_info['final_class'] = final_class
        detection_info['final_confidence'] = final_confidence
        detection_info['is_earthquake'] = False
        detection_info['alert_status'] = 'FALSE_POSITIVE_SUPPRESSED'
        detection_info['reason'] = f"ì˜¤ê²½ë³´ ì–µì œ: {detection_info['suppression_reasons'][-1]}"
        return detection_info
    
    detection_info['pass_reasons'].append(f"ì¶©ë¶„í•œ ì‹ ë¢°ë„ ì°¨ì´: {confidence_gap:.3f}")
    
    # 2-3: ì§„ë™ íŠ¹ì„± ê¸°ë°˜ ê³ ê¸‰ ê²€ì¦ (í™œì„±í™”ëœ ê²½ìš°)
    if ALERT_CONFIG['enable_advanced_filter'] and characteristics:
        print(f"\\nğŸ”¬ === ì§„ë™ íŠ¹ì„± ê¸°ë°˜ ê³ ê¸‰ ê²€ì¦ ===")
        
        # ì§€ì†ì„± ê²€ì‚¬
        duration_ratio = characteristics.get('duration_ratio', 0.5)
        if duration_ratio < VIBRATION_THRESHOLDS['min_duration_ratio']:
            detection_info['suppression_reasons'].append(
                f"ì§„ë™ ì§€ì†ì„± ë¶€ì¡±: {duration_ratio:.3f}"
            )
            detection_info['filters_applied'].append('duration_filter')
            print(f"ğŸ›¡ï¸ ì§€ì†ì„± í•„í„°: {detection_info['suppression_reasons'][-1]}")
        else:
            detection_info['pass_reasons'].append(f"ì¶©ë¶„í•œ ì§€ì†ì„±: {duration_ratio:.3f}")
        
        # ì£¼íŒŒìˆ˜ ê²€ì‚¬
        dominant_freq = characteristics.get('dominant_frequency', 10.0)
        if dominant_freq > VIBRATION_THRESHOLDS['max_frequency']:
            detection_info['suppression_reasons'].append(
                f"ì£¼íŒŒìˆ˜ê°€ ë†’ìŒ: {dominant_freq:.1f}Hz (ìƒí™œì§„ë™ ì˜ì‹¬)"
            )
            detection_info['filters_applied'].append('frequency_filter')
            print(f"ğŸ›¡ï¸ ì£¼íŒŒìˆ˜ í•„í„°: {detection_info['suppression_reasons'][-1]}")
        else:
            detection_info['pass_reasons'].append(f"ì ì ˆí•œ ì£¼íŒŒìˆ˜: {dominant_freq:.1f}Hz")
        
        # ì—ë„ˆì§€ ê· í˜• ê²€ì‚¬
        energy_balance = characteristics.get('energy_balance', 0.5)
        if energy_balance > VIBRATION_THRESHOLDS['max_energy_imbalance']:
            detection_info['suppression_reasons'].append(
                f"ì—ë„ˆì§€ ë¶ˆê· í˜•: {energy_balance:.3f} (ì¶©ê²©ì„± ì§„ë™ ì˜ì‹¬)"
            )
            detection_info['filters_applied'].append('energy_filter')
            print(f"ğŸ›¡ï¸ ì—ë„ˆì§€ í•„í„°: {detection_info['suppression_reasons'][-1]}")
        else:
            detection_info['pass_reasons'].append(f"ê· ë“±í•œ ì—ë„ˆì§€ ë¶„í¬: {energy_balance:.3f}")
        
        # ë³€í™”ìœ¨ ê²€ì‚¬
        max_change_rate = characteristics.get('max_change_rate', 5.0)
        if max_change_rate > VIBRATION_THRESHOLDS['max_change_rate']:
            detection_info['suppression_reasons'].append(
                f"ê¸‰ê²©í•œ ë³€í™”: {max_change_rate:.3f} (ì¶©ê²©ì„± ì§„ë™ ì˜ì‹¬)"
            )
            detection_info['filters_applied'].append('change_rate_filter')
            print(f"ğŸ›¡ï¸ ë³€í™”ìœ¨ í•„í„°: {detection_info['suppression_reasons'][-1]}")
        else:
            detection_info['pass_reasons'].append(f"ì™„ë§Œí•œ ë³€í™”: {max_change_rate:.3f}")
        
        # ì €ì£¼íŒŒ ìš°ì„¸ì„± ê²€ì‚¬
        low_freq_dominance = characteristics.get('low_freq_dominance', 0.5)
        if low_freq_dominance < VIBRATION_THRESHOLDS['low_freq_dominance_min']:
            detection_info['suppression_reasons'].append(
                f"ê³ ì£¼íŒŒ ìš°ì„¸: {low_freq_dominance:.3f} (ìƒí™œì§„ë™ ì˜ì‹¬)"
            )
            detection_info['filters_applied'].append('freq_dominance_filter')
            print(f"ğŸ›¡ï¸ ì£¼íŒŒìˆ˜ ìš°ì„¸ì„± í•„í„°: {detection_info['suppression_reasons'][-1]}")
        else:
            detection_info['pass_reasons'].append(f"ì €ì£¼íŒŒ ìš°ì„¸: {low_freq_dominance:.3f}")
        
        # ì§€ì§„ íŠ¹ì„± ì ìˆ˜ ê²€ì‚¬
        earthquake_score = characteristics.get('earthquake_score', 0.5)
        if earthquake_score < 0.4:  # 40% ë¯¸ë§Œì´ë©´ ì˜ì‹¬
            detection_info['suppression_reasons'].append(
                f"ì§€ì§„ íŠ¹ì„± ì ìˆ˜ ë‚®ìŒ: {earthquake_score:.3f}"
            )
            detection_info['filters_applied'].append('earthquake_score_filter')
            print(f"ğŸ›¡ï¸ ì§€ì§„ íŠ¹ì„± í•„í„°: {detection_info['suppression_reasons'][-1]}")
        else:
            detection_info['pass_reasons'].append(f"ë†’ì€ ì§€ì§„ íŠ¹ì„± ì ìˆ˜: {earthquake_score:.3f}")
        
        # ì–µì œ ì¡°ê±´ì´ 3ê°œ ì´ìƒì´ë©´ ì˜¤ê²½ë³´ë¡œ íŒë‹¨
        if len(detection_info['suppression_reasons']) >= 3:
            print(f"ğŸ›¡ï¸ ë‹¤ì¤‘ í•„í„° ì–µì œ: {len(detection_info['suppression_reasons'])}ê°œ ì¡°ê±´ ìœ„ë°˜")
            
            # íŠ¹ì„± ê¸°ë°˜ìœ¼ë¡œ ì ì ˆí•œ í´ë˜ìŠ¤ ì„ íƒ
            if dominant_freq > 10 and max_change_rate > 8:
                final_class = 2  # ë¶ˆê·œì¹™ìƒí™œì§„ë™
                final_confidence = living_prob
            else:
                final_class = 1  # ê·œì¹™ì ì‚°ì—…ì§„ë™
                final_confidence = industrial_prob
            
            detection_info['final_class'] = final_class
            detection_info['final_confidence'] = final_confidence
            detection_info['is_earthquake'] = False
            detection_info['alert_status'] = 'FALSE_POSITIVE_SUPPRESSED'
            detection_info['reason'] = f"ë‹¤ì¤‘ í•„í„° ì–µì œ: {', '.join(detection_info['suppression_reasons'][:2])} ë“±"
            return detection_info
    
    # 3ë‹¨ê³„: ëª¨ë“  ê²€ì¦ í†µê³¼ - ì§€ì§„ìœ¼ë¡œ í™•ì •
    print(f"\\nâœ… === ëª¨ë“  ê²€ì¦ í†µê³¼: ì§€ì§„ í™•ì • ===")
    for reason in detection_info['pass_reasons']:
        print(f"   âœ“ {reason}")
    
    detection_info['final_class'] = 0
    detection_info['final_confidence'] = earthquake_prob
    detection_info['is_earthquake'] = True
    detection_info['alert_status'] = 'EARTHQUAKE_ALERT'
    detection_info['reason'] = f"ì§€ì§„ í™•ì •: {len(detection_info['pass_reasons'])}ê°œ ì¡°ê±´ ë§Œì¡±"
    
    return detection_info

def predict_and_analyze_new2(raw_csv_path, processed_csv_path):
    """NEW2 ëª¨ë¸ì„ ì‚¬ìš©í•œ ì˜ˆì¸¡ ë° ë¶„ì„"""
    if convlstm_model is None:
        print("âš ï¸ NEW2 ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•„ ì˜ˆì¸¡ì„ ê±´ë„ˆëœë‹ˆë‹¤")
        return None
    
    try:
        print(f"\\nğŸ”„ === NEW2 AI ë¶„ì„ ì‹œì‘: {os.path.basename(raw_csv_path)} ===")
        
        # NEW2 ì „ì²˜ë¦¬
        start_time = time.time()
        X, df, preprocess_info = preprocess_for_new2_convlstm(raw_csv_path)
        preprocess_time = time.time() - start_time
        
        if X is None:
            print(f"âŒ NEW2 ì „ì²˜ë¦¬ ì‹¤íŒ¨: {preprocess_info}")
            return None
        
        characteristics = preprocess_info.get('characteristics')
        
        # ì§„ë™ íŠ¹ì„± ì¶œë ¥
        if characteristics:
            print(f"\\nğŸ” === ì§„ë™ íŠ¹ì„± ë¶„ì„ ê²°ê³¼ ===")
            print(f"   ğŸ“ ì§€ì†ì„±: {characteristics['duration_ratio']:.3f}")
            print(f"   ğŸµ ì£¼ìš” ì£¼íŒŒìˆ˜: {characteristics['dominant_frequency']:.1f}Hz")
            print(f"   âš–ï¸ ì—ë„ˆì§€ ê· í˜•: {characteristics['energy_balance']:.3f}")
            print(f"   ğŸ“ˆ ìµœëŒ€ ë³€í™”ìœ¨: {characteristics['max_change_rate']:.2f}")
            print(f"   ğŸ¯ ì§€ì§„ íŠ¹ì„± ì ìˆ˜: {characteristics['earthquake_score']:.3f}")
            print(f"   ğŸ”Š ì €ì£¼íŒŒ ìš°ì„¸ì„±: {characteristics['low_freq_dominance']:.3f}")
        
        # NEW2 ëª¨ë¸ ì˜ˆì¸¡
        prediction_start = time.time()
        predictions = convlstm_model.predict(X, verbose=0)
        prediction_time = time.time() - prediction_start
        
        # ê³ ë„í™”ëœ ì§€ì§„ ê°ì§€ ë¡œì§ ì ìš©
        detection_result = advanced_earthquake_detection_new2(predictions, characteristics)
        
        total_time = time.time() - start_time
        
        # ê²°ê³¼ ì¶œë ¥
        final_class = detection_result['final_class']
        final_confidence = detection_result['final_confidence']
        is_earthquake = detection_result['is_earthquake']
        alert_status = detection_result['alert_status']
        
        print(f"\\nğŸ¯ === NEW2 ìµœì¢… ë¶„ì„ ê²°ê³¼ ===")
        print(f"ì›ë³¸ ì˜ˆì¸¡: {MODEL_CONFIG['classes'][detection_result['original_class']]} ({detection_result['original_confidence']:.4f})")
        print(f"ìµœì¢… ë¶„ë¥˜: {MODEL_CONFIG['classes'][final_class]} ({final_confidence:.4f})")
        print(f"ë¶„ì„ ê·¼ê±°: {detection_result['reason']}")
        
        # ê²½ë³´ ìƒíƒœ ì¶œë ¥
        if is_earthquake:
            print(f"\\nğŸš¨ === ì§€ì§„ ê²½ë³´ ë°œë ¹! ===")
            print(f"ğŸ”´ ì§€ì§„ ê°ì§€ í™•ì •")
            print(f"ğŸ“Š ì‹ ë¢°ë„: {final_confidence:.4f} ({final_confidence*100:.2f}%)")
            print(f"âš¡ ë¶„ì„ ì‹œê°„: {total_time:.2f}ì´ˆ")
            
            # ê²½ë³´ ì •ë³´ ì €ì¥
            alert_info = {
                'timestamp': datetime.now().isoformat(),
                'detection_confidence': final_confidence,
                'alert_type': 'EARTHQUAKE_ALERT',
                'model_accuracy': MODEL_CONFIG['accuracy'],
                'processing_time': total_time,
                'characteristics': characteristics
            }
            
            alert_file = os.path.join(DIRS['alerts'], f"earthquake_alert_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
            with open(alert_file, 'w', encoding='utf-8') as f:
                json.dump(alert_info, f, ensure_ascii=False, indent=2)
            print(f"ğŸš¨ ê²½ë³´ ì •ë³´ ì €ì¥: {os.path.basename(alert_file)}")
            
        else:
            if alert_status == 'FALSE_POSITIVE_SUPPRESSED':
                print(f"\\nğŸ›¡ï¸ === ì˜¤ê²½ë³´ ì–µì œë¨ ===")
                print(f"ğŸŸ¡ ì ì¬ì  ì˜¤ê²½ë³´ ì°¨ë‹¨")
            else:
                print(f"\\nâœ… === ì •ìƒ ìƒíƒœ ===")
                print(f"ğŸŸ¢ ë¹„ì§€ì§„ ì§„ë™ ê°ì§€")
            
            print(f"ğŸ“Š ë¶„ë¥˜: {MODEL_CONFIG['classes'][final_class]}")
            print(f"ğŸ“Š ì‹ ë¢°ë„: {final_confidence:.4f} ({final_confidence*100:.2f}%)")
            print(f"âš¡ ë¶„ì„ ì‹œê°„: {total_time:.2f}ì´ˆ")
        
        # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€
        if df is not None:
            # ê¸°ë³¸ ì˜ˆì¸¡ ì •ë³´
            df['original_predicted_class'] = detection_result['original_class']
            df['original_predicted_class_name'] = MODEL_CONFIG['classes'][detection_result['original_class']]
            df['original_confidence'] = detection_result['original_confidence']
            
            # ìµœì¢… ë¶„ë¥˜ ì •ë³´
            df['final_predicted_class'] = final_class
            df['final_predicted_class_name'] = MODEL_CONFIG['classes'][final_class]
            df['final_confidence'] = final_confidence
            df['is_earthquake'] = is_earthquake
            df['alert_status'] = alert_status
            
            # ëª¨ë“  í´ë˜ìŠ¤ í™•ë¥ 
            df['prob_earthquake'] = detection_result['earthquake_prob']
            df['prob_industrial'] = detection_result['industrial_prob']
            df['prob_living'] = detection_result['living_prob']
            
            # ë¶„ì„ ì •ë³´
            df['model_name'] = 'NEW2_ConvLSTM_3Class'
            df['model_accuracy'] = MODEL_CONFIG['accuracy']
            df['preprocess_time'] = preprocess_time
            df['prediction_time'] = prediction_time
            df['total_analysis_time'] = total_time
            
            # ì „ì²˜ë¦¬ ì •ë³´
            df['trigger_point'] = preprocess_info['trigger_point']
            df['original_data_length'] = preprocess_info['original_length']
            df['used_sensor'] = preprocess_info['used_sensor']
            df['normalization_mean'] = preprocess_info['normalization']['mean']
            df['normalization_std'] = preprocess_info['normalization']['std']
            
            # ì§„ë™ íŠ¹ì„± ì •ë³´
            if characteristics:
                for key, value in characteristics.items():
                    df[f'vibration_{key}'] = value
            
            # ê²€ì¦ ì •ë³´
            df['filters_applied'] = '|'.join(detection_result['filters_applied'])
            df['suppression_reasons'] = '|'.join(detection_result['suppression_reasons'])
            df['pass_reasons'] = '|'.join(detection_result['pass_reasons'])
            
            # ì‹œìŠ¤í…œ ì„¤ì • ì •ë³´
            df['earthquake_threshold'] = ALERT_CONFIG['earthquake_threshold']
            df['confidence_gap_min'] = ALERT_CONFIG['confidence_gap_min']
            df['advanced_filter_enabled'] = ALERT_CONFIG['enable_advanced_filter']
            
            # ì²˜ë¦¬ëœ ê²°ê³¼ ì €ì¥
            df.to_csv(processed_csv_path, index=False, encoding='utf-8-sig')
            print(f"ğŸ’¾ NEW2 ë¶„ì„ ê²°ê³¼ ì €ì¥: {os.path.basename(processed_csv_path)}")
        
        return {
            'is_earthquake': is_earthquake,
            'final_class': final_class,
            'final_class_name': MODEL_CONFIG['classes'][final_class],
            'final_confidence': final_confidence,
            'alert_status': alert_status,
            'detection_result': detection_result,
            'preprocess_info': preprocess_info,
            'processing_time': total_time
        }
        
    except Exception as e:
        print(f"âŒ NEW2 ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None

# =========================== ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ===========================

def is_file_already_processed(raw_filename):
    """íŒŒì¼ ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€"""
    ai_filename = raw_filename.replace("event_", "new2_ai_")
    processed_path = os.path.join(DIRS['processed'], ai_filename)
    return os.path.exists(processed_path)

def system_health_check_new2():
    """NEW2 ì‹œìŠ¤í…œ ê±´ê°•ì„± ì²´í¬"""
    health = {
        'tensorflow_available': tf_available,
        'new2_model_loaded': convlstm_model is not None,
        'directories_ready': all(os.path.exists(path) for path in DIRS.values()),
        'influxdb_connected': False,
        'model_info': None
    }
    
    # InfluxDB ì—°ê²° í…ŒìŠ¤íŠ¸
    try:
        test_query = f'from(bucket: "{INFLUX_CONFIG["bucket"]}") |> range(start: -1m) |> limit(n:1)'
        result = query_api.query(org=INFLUX_CONFIG['org'], query=test_query)
        health['influxdb_connected'] = True
    except:
        health['influxdb_connected'] = False
    
    # ëª¨ë¸ ì •ë³´
    if convlstm_model:
        health['model_info'] = {
            'input_shape': convlstm_model.input_shape,
            'output_shape': convlstm_model.output_shape,
            'accuracy': MODEL_CONFIG['accuracy'],
            'classes': MODEL_CONFIG['classes']
        }
    
    return health

# =========================== í†µê³„ ë° ëª¨ë‹ˆí„°ë§ ===========================

# NEW2 ì„±ëŠ¥ í†µê³„
new2_stats = {
    'total_events': 0,
    'earthquake_alerts': 0,
    'false_positive_suppressed': 0,
    'normal_detections': 0,
    'class_distribution': {name: 0 for name in MODEL_CONFIG['classes'].values()},
    'processing_times': [],
    'alert_history': [],
    'suppression_effectiveness': {
        'confidence_threshold': 0,
        'confidence_gap': 0,
        'duration_filter': 0,
        'frequency_filter': 0,
        'energy_filter': 0,
        'change_rate_filter': 0,
        'freq_dominance_filter': 0,
        'earthquake_score_filter': 0,
        'multi_filter': 0
    },
    'start_time': datetime.now()
}

def update_new2_stats(analysis_result):
    """NEW2 í†µê³„ ì—…ë°ì´íŠ¸"""
    if not analysis_result:
        return
    
    new2_stats['total_events'] += 1
    new2_stats['processing_times'].append(analysis_result['processing_time'])
    
    # í´ë˜ìŠ¤ë³„ ë¶„í¬
    class_name = analysis_result['final_class_name']
    new2_stats['class_distribution'][class_name] += 1
    
    # ê²½ë³´ ìƒíƒœë³„ í†µê³„
    if analysis_result['is_earthquake']:
        new2_stats['earthquake_alerts'] += 1
        new2_stats['alert_history'].append({
            'timestamp': datetime.now().isoformat(),
            'confidence': analysis_result['final_confidence'],
            'class': class_name
        })
    elif analysis_result['alert_status'] == 'FALSE_POSITIVE_SUPPRESSED':
        new2_stats['false_positive_suppressed'] += 1
    else:
        new2_stats['normal_detections'] += 1
    
    # í•„í„° íš¨ê³¼ í†µê³„
    detection_result = analysis_result.get('detection_result', {})
    filters_applied = detection_result.get('filters_applied', [])
    
    for filter_name in filters_applied:
        if filter_name in new2_stats['suppression_effectiveness']:
            new2_stats['suppression_effectiveness'][filter_name] += 1
    
    if len(filters_applied) >= 3:
        new2_stats['suppression_effectiveness']['multi_filter'] += 1

def print_new2_stats():
    """NEW2 í†µê³„ ì¶œë ¥"""
    if new2_stats['total_events'] == 0:
        return
    
    runtime = datetime.now() - new2_stats['start_time']
    avg_processing_time = np.mean(new2_stats['processing_times'])
    
    print(f"\\nğŸ“ˆ === NEW2 ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¦¬í¬íŠ¸ ===")
    print(f"ğŸ•’ ì‹¤í–‰ ì‹œê°„: {runtime}")
    print(f"ğŸ“Š ì´ ì´ë²¤íŠ¸: {new2_stats['total_events']}ê±´")
    print(f"ğŸš¨ ì§€ì§„ ê²½ë³´: {new2_stats['earthquake_alerts']}ê±´")
    print(f"ğŸ›¡ï¸ ì˜¤ê²½ë³´ ì–µì œ: {new2_stats['false_positive_suppressed']}ê±´")
    print(f"âœ… ì •ìƒ ê°ì§€: {new2_stats['normal_detections']}ê±´")
    print(f"âš¡ í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_processing_time:.2f}ì´ˆ")
    
    # ë¹„ìœ¨ ê³„ì‚°
    alert_rate = new2_stats['earthquake_alerts'] / new2_stats['total_events'] * 100
    suppression_rate = new2_stats['false_positive_suppressed'] / new2_stats['total_events'] * 100
    
    print(f"ğŸ“ˆ ì§€ì§„ ê²½ë³´ìœ¨: {alert_rate:.1f}%")
    print(f"ğŸ›¡ï¸ ì˜¤ê²½ë³´ ì–µì œìœ¨: {suppression_rate:.1f}%")
    
    # ì˜¤ê²½ë³´ ì €ê° íš¨ê³¼
    if new2_stats['false_positive_suppressed'] > 0:
        potential_false_alarms = new2_stats['earthquake_alerts'] + new2_stats['false_positive_suppressed']
        reduction_effectiveness = (new2_stats['false_positive_suppressed'] / potential_false_alarms) * 100
        print(f"ğŸ¯ ì˜¤ê²½ë³´ ì €ê° íš¨ê³¼: {reduction_effectiveness:.1f}%")
    
    # í´ë˜ìŠ¤ë³„ ë¶„í¬
    print(f"\\nğŸ“Š í´ë˜ìŠ¤ë³„ ë¶„í¬:")
    for class_name, count in new2_stats['class_distribution'].items():
        if count > 0:
            percentage = count / new2_stats['total_events'] * 100
            icon = 'ğŸ”´' if class_name == 'ì§€ì§„' else 'ğŸŸ ' if class_name == 'ê·œì¹™ì ì‚°ì—…ì§„ë™' else 'ğŸŸ¢'
            print(f"   {icon} {class_name}: {count}ê±´ ({percentage:.1f}%)")
    
    # í•„í„° íš¨ê³¼
    print(f"\\nğŸ›¡ï¸ í•„í„°ë³„ ì–µì œ íšŸìˆ˜:")
    for filter_name, count in new2_stats['suppression_effectiveness'].items():
        if count > 0:
            print(f"   ğŸ“Œ {filter_name}: {count}ê±´")

# =========================== ë©”ì¸ ì‹œìŠ¤í…œ ì‹œì‘ ===========================

def main():
    """NEW2 ì‹¤ì‹œê°„ ì§€ì§„ ì¡°ê¸°ê²½ë³´ ì‹œìŠ¤í…œ ë©”ì¸"""
    
    print("\\nğŸš€ === NEW2 ConvLSTM ì‹¤ì‹œê°„ ì§€ì§„ ì¡°ê¸°ê²½ë³´ ì‹œìŠ¤í…œ ì‹œì‘! ===")
    print(f"ğŸ§  ëª¨ë¸: NEW2 ConvLSTM 3í´ë˜ìŠ¤ (ì •í™•ë„: {MODEL_CONFIG['accuracy']*100:.2f}%)")
    print(f"ğŸ“Š ë¶„ë¥˜: {list(MODEL_CONFIG['classes'].values())}")
    print(f"ğŸ” ê°ì‹œ í¬íŠ¸: {INFLUX_CONFIG['ports']}")
    print(f"â±ï¸ ì²´í¬ ì£¼ê¸°: 1ì´ˆ")
    print(f"ğŸŒ Node-RED: {NODERED_CONFIG['base_url']}")
    print(f"ğŸ’¾ ì €ì¥ ìœ„ì¹˜:")
    for name, path in DIRS.items():
        print(f"   {name}: {path}")
    
    print(f"\\nğŸ›¡ï¸ ì¡°ê¸°ê²½ë³´ ì„¤ì •:")
    print(f"   ğŸ“Š ì§€ì§„ ì‹ ë¢°ë„ ì„ê³„ê°’: {ALERT_CONFIG['earthquake_threshold']*100:.0f}%")
    print(f"   ğŸ“ ì‹ ë¢°ë„ ì°¨ì´ ìµœì†Œê°’: {ALERT_CONFIG['confidence_gap_min']*100:.0f}%")
    print(f"   ğŸ”¬ ê³ ê¸‰ í•„í„°ë§: {'í™œì„±í™”' if ALERT_CONFIG['enable_advanced_filter'] else 'ë¹„í™œì„±í™”'}")
    print(f"   ğŸ”„ ë‹¤ì¤‘ ê²€ì¦: {'í™œì„±í™”' if ALERT_CONFIG['enable_multi_check'] else 'ë¹„í™œì„±í™”'}")
    
    # ì‹œìŠ¤í…œ ê±´ê°•ì„± ì²´í¬
    health = system_health_check_new2()
    print(f"\\nğŸ¥ ì‹œìŠ¤í…œ ìƒíƒœ:")
    print(f"   âœ… TensorFlow: {'ì •ìƒ' if health['tensorflow_available'] else 'âŒ ì˜¤ë¥˜'}")
    print(f"   âœ… NEW2 ëª¨ë¸: {'ë¡œë”©ë¨' if health['new2_model_loaded'] else 'âŒ ì‹¤íŒ¨'}")
    print(f"   âœ… ë””ë ‰í† ë¦¬: {'ì¤€ë¹„ë¨' if health['directories_ready'] else 'âŒ ì˜¤ë¥˜'}")
    print(f"   âœ… InfluxDB: {'ì—°ê²°ë¨' if health['influxdb_connected'] else 'âŒ ì—°ê²° ì‹¤íŒ¨'}")
    
    if health['model_info']:
        print(f"\\nğŸ§  ëª¨ë¸ ì •ë³´:")
        print(f"   ì…ë ¥ í˜•íƒœ: {health['model_info']['input_shape']}")
        print(f"   ì¶œë ¥ í˜•íƒœ: {health['model_info']['output_shape']}")
    
    print("="*80)
    
    # ì‹¤ì‹œê°„ ê°ì‹œ ë£¨í”„
    consecutive_no_data = 0
    last_alert_time = 0
    
    try:
        while True:
            now = datetime.utcnow()
            start = now - timedelta(seconds=1)
            data_found = False
            
            for port in INFLUX_CONFIG['ports']:
                query = f'''
                from(bucket: "{INFLUX_CONFIG["bucket"]}")
                  |> range(start: {start.isoformat()}Z, stop: {now.isoformat()}Z)
                  |> filter(fn: (r) => r._field == "intensity" and r._measurement == "{port}")
                  |> sort(columns: ["_time"], desc: true)
                  |> limit(n:1)
                '''
                
                result = query_api.query(org=INFLUX_CONFIG['org'], query=query)
                
                for table in result:
                    for record in table.records:
                        data_found = True
                        intensity = record.get_value()
                        
                        if not isinstance(intensity, (int, float)) or intensity < 3.0:
                            continue
                        
                        event_time = record.get_time().astimezone()
                        kst_time = event_time.strftime("%Y-%m-%d %H:%M:%S")
                        
                        # ê²½ë³´ ì¿¨ë‹¤ìš´ ì²´í¬
                        current_time = time.time()
                        if current_time - last_alert_time < ALERT_CONFIG['alert_cooldown']:
                            print(f"â° ê²½ë³´ ì¿¨ë‹¤ìš´ ì¤‘... ({current_time - last_alert_time:.0f}ì´ˆ)")
                            continue
                        
                        print(f"\\nğŸ”¥ === ì§„ë„ {intensity:.2f} ê°ì§€ ===")
                        print(f"ğŸ“… ì‹œê°„: {kst_time}")
                        print(f"ğŸŒ í¬íŠ¸: {port}")
                        
                        # íŒŒì¼ëª… ìƒì„±
                        safe_time = kst_time.replace(':', '-').replace(' ', '_')
                        raw_filename = f"event_{port}_{safe_time}.csv"
                        
                        # ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€
                        if is_file_already_processed(raw_filename):
                            print(f"âš ï¸ ì´ë¯¸ ì²˜ë¦¬ëœ ì´ë²¤íŠ¸: {raw_filename}")
                            continue
                        
                        print("â³ 40ì´ˆ ë°ì´í„° ìˆ˜ì§‘ ëŒ€ê¸°...")
                        
                        # ëŒ€ê¸° ì¤‘ ì§„í–‰ ìƒí™© í‘œì‹œ
                        for i in range(8):
                            remaining = 40 - (i * 5)
                            print(f"   ğŸ• {remaining}ì´ˆ ë‚¨ìŒ...")
                            time.sleep(5)
                        
                        # Node-RED ë°ì´í„° ìš”ì²­
                        encoded_time = quote(kst_time)
                        url = f"{NODERED_CONFIG['base_url']}/{encoded_time}/{port}"
                        
                        try:
                            print(f"ğŸ”— Node-RED ë°ì´í„° ìš”ì²­: {url}")
                            response = requests.get(url, timeout=NODERED_CONFIG['timeout'])
                            
                            if response.status_code != 200:
                                print(f"âŒ Node-RED ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
                                continue
                            
                            # íŒŒì¼ ê²½ë¡œ
                            raw_csv_path = os.path.join(DIRS['raw'], raw_filename)
                            ai_filename = raw_filename.replace("event_", "new2_ai_")
                            processed_csv_path = os.path.join(DIRS['processed'], ai_filename)
                            
                            # íŒŒì¼ ìƒì„± ëŒ€ê¸°
                            max_wait = 20
                            for wait_count in range(max_wait):
                                if os.path.exists(raw_csv_path):
                                    file_size = os.path.getsize(raw_csv_path)
                                    print(f"âœ… ë°ì´í„° íŒŒì¼ í™•ì¸: {file_size} bytes")
                                    break
                                print(f"â³ íŒŒì¼ ìƒì„± ëŒ€ê¸°... ({wait_count + 1}/{max_wait})")
                                time.sleep(1)
                            else:
                                print(f"âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {raw_csv_path}")
                                continue
                            
                            # NEW2 AI ë¶„ì„ ìˆ˜í–‰
                            analysis_result = predict_and_analyze_new2(raw_csv_path, processed_csv_path)
                            
                            if analysis_result:
                                # í†µê³„ ì—…ë°ì´íŠ¸
                                update_new2_stats(analysis_result)
                                
                                # ì§€ì§„ ê²½ë³´ ì²˜ë¦¬
                                if analysis_result['is_earthquake']:
                                    last_alert_time = current_time
                                    print(f"\\nğŸš¨ğŸš¨ğŸš¨ ì§€ì§„ ê²½ë³´ ë°œë ¹! ğŸš¨ğŸš¨ğŸš¨")
                                    print(f"ğŸ”´ ì‹ ë¢°ë„: {analysis_result['final_confidence']*100:.2f}%")
                                    print(f"âš¡ ì²˜ë¦¬ ì‹œê°„: {analysis_result['processing_time']:.2f}ì´ˆ")
                                
                                # ì£¼ê¸°ì  í†µê³„ ì¶œë ¥
                                if new2_stats['total_events'] % 5 == 0:
                                    print_new2_stats()
                            
                        except requests.exceptions.Timeout:
                            print(f"âŒ Node-RED ìš”ì²­ íƒ€ì„ì•„ì›ƒ")
                        except Exception as e:
                            print(f"âŒ Node-RED ìš”ì²­ ì‹¤íŒ¨: {e}")
            
            # ë¬´ë°ì´í„° ëª¨ë‹ˆí„°ë§
            if not data_found:
                consecutive_no_data += 1
                if consecutive_no_data % 300 == 0:  # 5ë¶„ë§ˆë‹¤
                    print(f"â° ë°ì´í„° ì—†ìŒ ({consecutive_no_data}ì´ˆ ì§€ì†)")
            else:
                consecutive_no_data = 0
            
            time.sleep(1)
    
    except KeyboardInterrupt:
        print(f"\\n\\nğŸ›‘ === ì‚¬ìš©ì ì¤‘ë‹¨ ===")
        print_new2_stats()
        print(f"\\nğŸ‰ NEW2 ì‹œìŠ¤í…œì´ ì•ˆì „í•˜ê²Œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        print_new2_stats()

if __name__ == "__main__":
    main()